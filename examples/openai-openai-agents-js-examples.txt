Directory structure:
└── examples/
    ├── agent-patterns/
    │   ├── README.md
    │   ├── agents-as-tools.ts
    │   ├── deterministic.ts
    │   ├── forcing-tool-use.ts
    │   ├── human-in-the-loop-stream.ts
    │   ├── human-in-the-loop.ts
    │   ├── input-guardrails.ts
    │   ├── llm-as-a-judge.ts
    │   ├── output-guardrails.ts
    │   ├── package.json
    │   ├── parallelization.ts
    │   ├── routing.ts
    │   ├── streamed.ts
    │   ├── streaming-guardrails.ts
    │   └── tsconfig.json
    ├── ai-sdk/
    │   ├── README.md
    │   ├── ai-sdk-model.ts
    │   ├── package.json
    │   ├── stream.ts
    │   └── tsconfig.json
    ├── basic/
    │   ├── README.md
    │   ├── agent-lifecycle-example.ts
    │   ├── chat.ts
    │   ├── dynamic-system-prompt.ts
    │   ├── hello-world.ts
    │   ├── index.ts
    │   ├── json-schema-output-type.ts
    │   ├── lifecycle-example.ts
    │   ├── local-file.ts
    │   ├── local-image.ts
    │   ├── package.json
    │   ├── previous-response-id.ts
    │   ├── prompt-id.ts
    │   ├── reasoning.ts
    │   ├── remote-image.ts
    │   ├── stream-items.ts
    │   ├── stream-text.ts
    │   ├── tool-use-behavior.ts
    │   ├── tools.ts
    │   └── tsconfig.json
    ├── customer-service/
    │   ├── README.md
    │   ├── index.ts
    │   ├── package.json
    │   └── tsconfig.json
    ├── docs/
    │   ├── README.md
    │   ├── custom-trace.ts
    │   ├── hello-world-with-runner.ts
    │   ├── hello-world.ts
    │   ├── package.json
    │   ├── tsconfig.json
    │   ├── agents/
    │   │   ├── agentCloning.ts
    │   │   ├── agentForcingToolUse.ts
    │   │   ├── agentWithAodOutputType.ts
    │   │   ├── agentWithContext.ts
    │   │   ├── agentWithDynamicInstructions.ts
    │   │   ├── agentWithHandoffs.ts
    │   │   ├── agentWithLifecycleHooks.ts
    │   │   ├── agentWithTools.ts
    │   │   └── simpleAgent.ts
    │   ├── config/
    │   │   ├── getLogger.ts
    │   │   ├── setDefaultOpenAIClient.ts
    │   │   ├── setDefaultOpenAIKey.ts
    │   │   ├── setOpenAIAPI.ts
    │   │   ├── setTracingDisabled.ts
    │   │   └── setTracingExportApiKey.ts
    │   ├── context/
    │   │   └── localContext.ts
    │   ├── extensions/
    │   │   ├── ai-sdk-setup.ts
    │   │   └── twilio-basic.ts
    │   ├── guardrails/
    │   │   ├── guardrails-input.ts
    │   │   └── guardrails-output.ts
    │   ├── handoffs/
    │   │   ├── basicUsage.ts
    │   │   ├── customizeHandoff.ts
    │   │   ├── handoffInput.ts
    │   │   ├── inputFilter.ts
    │   │   └── recommendedPrompt.ts
    │   ├── human-in-the-loop/
    │   │   ├── index.ts
    │   │   └── toolApprovalDefinition.ts
    │   ├── mcp/
    │   │   ├── hosted.ts
    │   │   ├── hostedAgent.ts
    │   │   ├── hostedHITL.ts
    │   │   ├── hostedStream.ts
    │   │   ├── stdio.ts
    │   │   └── streamableHttp.ts
    │   ├── models/
    │   │   ├── agentWithModel.ts
    │   │   ├── customProviders.ts
    │   │   ├── modelSettings.ts
    │   │   ├── openaiProvider.ts
    │   │   └── runnerWithModel.ts
    │   ├── quickstart/
    │   │   └── index.ts
    │   ├── readme/
    │   │   ├── readme-functions.ts
    │   │   ├── readme-handoffs.ts
    │   │   ├── readme-hello-world.ts
    │   │   └── readme-voice-agent.ts
    │   ├── results/
    │   │   ├── handoffFinalOutputTypes.ts
    │   │   └── historyLoop.ts
    │   ├── running-agents/
    │   │   ├── chatLoop.ts
    │   │   ├── exceptions1.ts
    │   │   └── exceptions2.ts
    │   ├── streaming/
    │   │   ├── basicStreaming.ts
    │   │   ├── handleAllEvents.ts
    │   │   ├── nodeTextStream.ts
    │   │   └── streamedHITL.ts
    │   ├── tools/
    │   │   ├── agentsAsTools.ts
    │   │   ├── functionTools.ts
    │   │   ├── hostedTools.ts
    │   │   ├── mcpLocalServer.ts
    │   │   └── nonStrictSchemaTools.ts
    │   ├── toppage/
    │   │   ├── textAgent.ts
    │   │   └── voiceAgent.ts
    │   ├── tracing/
    │   │   └── cloudflareWorkers.ts
    │   └── voice-agents/
    │       ├── agent.ts
    │       ├── audioInterrupted.ts
    │       ├── configureSession.ts
    │       ├── createAgent.ts
    │       ├── createSession.ts
    │       ├── customWebRTCTransport.ts
    │       ├── defineTool.ts
    │       ├── delegationAgent.ts
    │       ├── guardrails.ts
    │       ├── guardrailSettings.ts
    │       ├── handleAudio.ts
    │       ├── helloWorld.ts
    │       ├── historyUpdated.ts
    │       ├── multiAgents.ts
    │       ├── sendMessage.ts
    │       ├── serverAgent.ts
    │       ├── sessionHistory.ts
    │       ├── sessionInterrupt.ts
    │       ├── thinClient.ts
    │       ├── toolApprovalEvent.ts
    │       ├── toolHistory.ts
    │       ├── transportEvents.ts
    │       ├── turnDetection.ts
    │       ├── updateHistory.ts
    │       └── websocketSession.ts
    ├── financial-research-agent/
    │   ├── README.md
    │   ├── agents.ts
    │   ├── main.ts
    │   ├── manager.ts
    │   ├── package.json
    │   └── tsconfig.json
    ├── handoffs/
    │   ├── README.md
    │   ├── index.ts
    │   ├── package.json
    │   ├── tsconfig.json
    │   └── types.ts
    ├── mcp/
    │   ├── README.md
    │   ├── filesystem-example.ts
    │   ├── hosted-mcp-human-in-the-loop.ts
    │   ├── hosted-mcp-on-approval.ts
    │   ├── hosted-mcp-simple.ts
    │   ├── package.json
    │   ├── streamable-http-example.ts
    │   ├── tsconfig.json
    │   └── sample_files/
    │       ├── books.txt
    │       └── favorite_songs.txt
    ├── model-providers/
    │   ├── README.md
    │   ├── custom-example-agent.ts
    │   ├── custom-example-global.ts
    │   ├── custom-example-provider.ts
    │   ├── package.json
    │   └── tsconfig.json
    ├── nextjs/
    │   ├── README.md
    │   ├── components.json
    │   ├── next.config.ts
    │   ├── package.json
    │   ├── postcss.config.mjs
    │   ├── tsconfig.json
    │   ├── vercel.json
    │   └── src/
    │       ├── agents.ts
    │       ├── db.ts
    │       ├── app/
    │       │   ├── globals.css
    │       │   ├── layout.tsx
    │       │   ├── page.tsx
    │       │   └── api/
    │       │       └── basic/
    │       │           └── route.ts
    │       ├── components/
    │       │   ├── App.tsx
    │       │   ├── Approvals.tsx
    │       │   ├── History.tsx
    │       │   ├── icons/
    │       │   │   ├── ArrowUpIcon.tsx
    │       │   │   ├── ClockIcon.tsx
    │       │   │   └── FunctionsIcon.tsx
    │       │   ├── messages/
    │       │   │   ├── FunctionCall.tsx
    │       │   │   └── TextMessage.tsx
    │       │   └── ui/
    │       │       ├── Button.tsx
    │       │       ├── dialog.tsx
    │       │       └── utils.ts
    │       └── lib/
    │           └── utils.ts
    ├── realtime-demo/
    │   ├── README.md
    │   ├── index.html
    │   ├── package.json
    │   ├── token.ts
    │   ├── tsconfig.json
    │   ├── vite-env.d.ts
    │   ├── vite.config.ts
    │   └── src/
    │       ├── main.ts
    │       ├── style.css
    │       └── utils.ts
    ├── realtime-next/
    │   ├── README.md
    │   ├── next.config.ts
    │   ├── package.json
    │   ├── postcss.config.mjs
    │   ├── tsconfig.json
    │   ├── vercel.json
    │   └── src/
    │       ├── app/
    │       │   ├── globals.css
    │       │   ├── layout.tsx
    │       │   ├── page.tsx
    │       │   ├── raw-client/
    │       │   │   └── page.tsx
    │       │   ├── server/
    │       │   │   ├── backendAgent.tsx
    │       │   │   └── token.tsx
    │       │   └── websocket/
    │       │       └── page.tsx
    │       └── components/
    │           ├── App.tsx
    │           ├── History.tsx
    │           ├── icons/
    │           │   ├── ClockIcon.tsx
    │           │   └── FunctionsIcon.tsx
    │           ├── messages/
    │           │   ├── FunctionCall.tsx
    │           │   └── TextMessage.tsx
    │           └── ui/
    │               ├── Button.tsx
    │               └── utils.ts
    ├── realtime-twilio/
    │   ├── README.md
    │   ├── index.ts
    │   ├── package.json
    │   └── tsconfig.json
    ├── research-bot/
    │   ├── README.md
    │   ├── agents.ts
    │   ├── main.ts
    │   ├── manager.ts
    │   ├── package.json
    │   └── tsconfig.json
    └── tools/
        ├── README.md
        ├── code-interpreter.ts
        ├── computer-use.ts
        ├── file-search.ts
        ├── image-generation.ts
        ├── package.json
        ├── tsconfig.json
        └── web-search.ts

================================================
FILE: examples/agent-patterns/README.md
================================================

# Agent Pattern Examples

This directory contains small scripts that demonstrate different agent patterns.
Run them with `pnpm` using the commands shown below.

- `agents-as-tools.ts` – Orchestrate translator agents using them as tools.
  ```bash
  pnpm examples:agents-as-tools
  ```
- `deterministic.ts` – Fixed agent flow with gating and quality checks.
  ```bash
  pnpm examples:deterministic
  ```
- `forcing-tool-use.ts` – Require specific tools before final output.
  ```bash
  pnpm -F agent-patterns start:forcing-tool-use
  ```
- `human-in-the-loop.ts` – Manually approve certain tool calls.
  ```bash
  pnpm examples:human-in-the-loop
  ```
- `human-in-the-loop-stream.ts` – Streaming version of human approval.
  ```bash
  pnpm examples:streamed:human-in-the-loop
  ```
- `input-guardrails.ts` – Reject unwanted requests with guardrails.
  ```bash
  pnpm examples:input-guardrails
  ```
- `llm-as-a-judge.ts` – Evaluate and iterate on story outlines.
  ```bash
  pnpm -F agent-patterns start:llm-as-a-judge
  ```
- `output-guardrails.ts` – Block unsafe output using guardrails.
  ```bash
  pnpm examples:output-guardrails
  ```
- `parallelization.ts` – Run translations in parallel and pick the best.
  ```bash
  pnpm examples:parallelization
  ```
- `routing.ts` – Route messages to language-specific agents.
  ```bash
  pnpm examples:routing
  ```
- `streamed.ts` – Stream agent output, both text and events.
  ```bash
  pnpm examples:streamed
  ```
- `streaming-guardrails.ts` – Check streaming output against guardrails.
  ```bash
  pnpm -F agent-patterns start:streaming-guardrails
  ```




================================================
FILE: examples/agent-patterns/agents-as-tools.ts
================================================
import { Agent, run, withTrace } from '@openai/agents';
import { createInterface } from 'node:readline/promises';

const rl = createInterface({ input: process.stdin, output: process.stdout });

const spanishAgent = new Agent({
  name: 'spanish_agent',
  instructions: "You translate the user's message to Spanish",
});

const frenchAgent = new Agent({
  name: 'french_agent',
  instructions: "You translate the user's message to French",
});

const italianAgent = new Agent({
  name: 'italian_agent',
  instructions: "You translate the user's message to Italian",
});

const orchestratorAgent = new Agent({
  name: 'orchestrator_agent',
  instructions: [
    'You are a translation agent. You use the tools given to you to translate.',
    'If asked for multiple translations, you call the relevant tools in order.',
    'You never translate on your own, you always use the provided tools.',
  ].join(' '),
  tools: [
    spanishAgent.asTool({
      toolName: 'translate_to_spanish',
      toolDescription: "Translate the user's message to Spanish",
    }),
    frenchAgent.asTool({
      toolName: 'translate_to_french',
      toolDescription: "Translate the user's message to French",
    }),
    italianAgent.asTool({
      toolName: 'translate_to_italian',
      toolDescription: "Translate the user's message to Italian",
    }),
  ],
});

const synthesizerAgent = new Agent({
  name: 'synthesizer_agent',
  instructions:
    'You inspect translations, correct them if needed, and produce a final concatenated response.',
});

async function main() {
  const msg = await rl.question(
    'Hi! What would you like translated, and to which languages? ',
  );

  if (!msg) {
    throw new Error('No message provided');
  }

  await withTrace('Orchestrator evaluator', async () => {
    const orchestratorResult = await run(orchestratorAgent, msg);

    for (const item of orchestratorResult.newItems) {
      if (item.type === 'message_output_item') {
        const text = item.content;
        if (text) {
          console.log(`  - Translation step: ${text}`);
        }
      }
    }

    const synthesizerResult = await run(
      synthesizerAgent,
      orchestratorResult.output,
    );

    console.log(`\n\nFinal response:\n${synthesizerResult.finalOutput}`);
  });

  rl.close();
}

main().catch((error) => {
  console.error('Error:', error);
});



================================================
FILE: examples/agent-patterns/deterministic.ts
================================================
import { Agent, run, withTrace } from '@openai/agents';
import { z } from 'zod';
import readline from 'node:readline/promises';

const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout,
});

// Define the agents
const storyOutlineAgent = new Agent({
  name: 'story_outline_agent',
  instructions:
    "Generate a very short story outline based on the user's input.",
});

const outlineCheckerAgent = new Agent({
  name: 'outline_checker_agent',
  instructions:
    'Read the given story outline, and judge the quality. Also, determine if it is a scifi story.',
  outputType: z.object({
    good_quality: z.boolean(),
    is_scifi: z.boolean(),
  }),
});

const storyAgent = new Agent({
  name: 'story_agent',
  instructions: 'Write a short story based on the given outline.',
});

async function main() {
  const inputPrompt = await rl.question('What kind of story do you want? ');

  if (!inputPrompt) {
    throw new Error('No input prompt provided');
  }

  await withTrace('Deterministic story flow', async () => {
    // 1. Generate an outline
    const outlineResult = await run(storyOutlineAgent, inputPrompt);

    if (!outlineResult.finalOutput) {
      throw new Error('No outline result');
    }

    console.log('Outline generated');

    // 2. Check the outline
    const outlineCheckerResult = await run(
      outlineCheckerAgent,
      outlineResult.finalOutput,
    );

    const checkerOutput = outlineCheckerResult.finalOutput;
    if (!checkerOutput) {
      throw new Error('No checker output');
    }

    // 3. Add a gate to stop if the outline is not good quality or not a scifi story
    if (!checkerOutput.good_quality) {
      console.log('Outline is not good quality, so we stop here.');
      return;
    }

    if (!checkerOutput.is_scifi) {
      console.log('Outline is not a scifi story, so we stop here.');
      return;
    }

    console.log(
      'Outline is good quality and a scifi story, so we continue to write the story.',
    );

    // 4. Write the story
    const storyResult = await run(storyAgent, outlineResult.finalOutput);
    console.log(`Story: ${storyResult.finalOutput}`);
  });

  rl.close();
}

main().catch((error) => {
  console.error('Error:', error);
  process.exit(1);
});



================================================
FILE: examples/agent-patterns/forcing-tool-use.ts
================================================
import {
  Agent,
  tool,
  run,
  ToolsToFinalOutputResult,
  ToolToFinalOutputFunction,
  ModelSettings,
  RunContext,
  FunctionToolResult,
  ToolUseBehavior,
} from '@openai/agents';
import { z } from 'zod';

type Weather = {
  city: string;
  temperature_range: string;
  conditions: string;
};

const getWeather = tool({
  name: 'get_weather',
  description: 'Get the weather for a given city',
  parameters: z.object({
    city: z.string(),
  }),
  execute: async ({ city }): Promise<Weather> => {
    return {
      city,
      temperature_range: '14-20C',
      conditions: 'Sunny with wind',
    };
  },
});

const customToolUseBehavior: ToolToFinalOutputFunction = async (
  _context: RunContext,
  results: FunctionToolResult[],
): Promise<ToolsToFinalOutputResult> => {
  // First function_output result
  console.log(results);
  const outputResult = results.find((r) => r.type === 'function_output');
  if (!outputResult) {
    return { isFinalOutput: false, isInterrupted: undefined };
  }
  const weather = outputResult.output as Weather;
  return {
    isFinalOutput: true,
    isInterrupted: undefined,
    finalOutput: `${weather.city} is ${weather.conditions}.`,
  };
};

async function main(
  toolUseBehaviorOption: 'default' | 'first_tool' | 'custom' = 'default',
) {
  let toolUseBehavior: ToolUseBehavior;
  let modelSettings: ModelSettings = {};

  if (toolUseBehaviorOption === 'default') {
    toolUseBehavior = 'run_llm_again';
    modelSettings = {};
  } else if (toolUseBehaviorOption === 'first_tool') {
    toolUseBehavior = 'stop_on_first_tool';
    modelSettings = { toolChoice: 'required' };
  } else {
    toolUseBehavior = customToolUseBehavior;
    modelSettings = { toolChoice: 'required' };
  }

  const agent = new Agent({
    name: 'Weather agent',
    instructions: 'You are a helpful agent.',
    tools: [getWeather],
    toolUseBehavior,
    modelSettings,
  });

  const result = await run(agent, "What's the weather in Tokyo?");
  console.log(result.finalOutput);
}

// CLI argument parsing
if (require.main === module) {
  const args = process.argv.slice(2);
  let toolUseBehavior: 'default' | 'first_tool' | 'custom' = 'default';
  const idx = args.findIndex((a) => a === '-t' || a === '--tool-use-behavior');
  if (idx !== -1 && args[idx + 1]) {
    const val = args[idx + 1];
    if (val === 'default' || val === 'first_tool' || val === 'custom') {
      toolUseBehavior = val;
    } else {
      console.error('Invalid tool use behavior:', val);
      process.exit(1);
    }
  } else {
    console.log(
      'Usage: pnpm run start:forcing-tool-use -t <default|first_tool|custom>',
    );
    process.exit(1);
  }
  main(toolUseBehavior).catch(console.error);
}



================================================
FILE: examples/agent-patterns/human-in-the-loop-stream.ts
================================================
import { z } from 'zod';
import readline from 'node:readline/promises';
import { Agent, run, tool } from '@openai/agents';

// Prompt user for yes/no confirmation
async function confirm(question: string): Promise<boolean> {
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
  });
  const answer = await rl.question(`${question} (y/n): `);
  rl.close();
  return ['y', 'yes'].includes(answer.trim().toLowerCase());
}

async function main() {
  // Define a tool that requires approval for certain inputs
  const getWeatherTool = tool({
    name: 'get_weather',
    description: 'Get the weather for a given city',
    parameters: z.object({ city: z.string() }),
    needsApproval: async (_ctx, { city }) => {
      // forces approval to look up the weather in San Francisco
      return city === 'San Francisco';
    },
    async execute({ city }) {
      return `The weather in ${city} is sunny.`;
    },
  });

  const weatherAgent = new Agent({
    name: 'Weather agent',
    instructions: 'You provide weather information.',
    handoffDescription: 'Handles weather-related queries',
    tools: [getWeatherTool],
  });

  const mainAgent = new Agent({
    name: 'Main agent',
    instructions: 'You are a general assistant.',
    handoffs: [weatherAgent],
  });

  let stream = await run(
    mainAgent,
    'What is the weather in San Francisco and Oakland?',
    { stream: true },
  );
  stream.toTextStream({ compatibleWithNodeStreams: true }).pipe(process.stdout);
  await stream.completed;

  while (stream.interruptions?.length) {
    console.log(
      'Human-in-the-loop: approval required for the following tool calls:',
    );
    const state = stream.state;
    for (const interruption of stream.interruptions) {
      const ok = await confirm(
        `Agent ${interruption.agent.name} would like to use the tool ${interruption.rawItem.name} with "${interruption.rawItem.arguments}". Do you approve?`,
      );
      if (ok) {
        state.approve(interruption);
      } else {
        state.reject(interruption);
      }
    }

    // Resume execution with streaming output
    stream = await run(mainAgent, state, { stream: true });
    const textStream = stream.toTextStream({ compatibleWithNodeStreams: true });
    textStream.pipe(process.stdout);
    await stream.completed;
  }

  console.log('\n\nDone');
}

main().catch(console.error);



================================================
FILE: examples/agent-patterns/human-in-the-loop.ts
================================================
import { z } from 'zod';
import readline from 'node:readline/promises';
import fs from 'node:fs/promises';
import { Agent, run, tool, RunState, RunResult } from '@openai/agents';

const getWeatherTool = tool({
  name: 'get_weather',
  description: 'Get the weather for a given city',
  parameters: z.object({
    location: z.string(),
  }),
  needsApproval: async (_context, { location }) => {
    // forces approval to look up the weather in San Francisco
    return location === 'San Francisco';
  },
  execute: async ({ location }) => {
    return `The weather in ${location} is sunny`;
  },
});

const dataAgentTwo = new Agent({
  name: 'Data agent',
  instructions: 'You are a data agent',
  handoffDescription: 'You know everything about the weather',
  tools: [getWeatherTool],
});

const agent = new Agent({
  name: 'Basic test agent',
  instructions: 'You are a basic agent',
  handoffs: [dataAgentTwo],
});

async function confirm(question: string) {
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
  });

  const answer = await rl.question(`${question} (y/n): `);
  const normalizedAnswer = answer.toLowerCase();
  rl.close();
  return normalizedAnswer === 'y' || normalizedAnswer === 'yes';
}

async function main() {
  let result: RunResult<unknown, Agent<unknown, any>> = await run(
    agent,
    'What is the weather in Oakland and San Francisco?',
  );
  let hasInterruptions = result.interruptions?.length > 0;
  while (hasInterruptions) {
    // storing
    await fs.writeFile(
      'result.json',
      JSON.stringify(result.state, null, 2),
      'utf-8',
    );

    // from here on you could run things on a different thread/process

    // reading later on
    const storedState = await fs.readFile('result.json', 'utf-8');
    const state = await RunState.fromString(agent, storedState);

    for (const interruption of result.interruptions) {
      const confirmed = await confirm(
        `Agent ${interruption.agent.name} would like to use the tool ${interruption.rawItem.name} with "${interruption.rawItem.arguments}". Do you approve?`,
      );

      if (confirmed) {
        state.approve(interruption);
      } else {
        state.reject(interruption);
      }
    }

    // resume execution of the current state
    result = await run(agent, state);
    hasInterruptions = result.interruptions?.length > 0;
  }

  console.log(result.finalOutput);
}

main().catch((error) => {
  console.dir(error, { depth: null });
});



================================================
FILE: examples/agent-patterns/input-guardrails.ts
================================================
import { Agent, run, withTrace } from '@openai/agents';
import { z } from 'zod';

async function main() {
  withTrace('Input Guardrail Example', async () => {
    const guardrailAgent = new Agent({
      name: 'Guardrail agent',
      instructions:
        'Check if the user is asking you to do their math homework.',
      outputType: z.object({ isMathHomework: z.boolean() }),
    });

    const agent = new Agent({
      name: 'Customer support agent',
      instructions:
        'You are a customer support agent. You help customers with their questions.',
      inputGuardrails: [
        {
          name: 'Math Homework Guardrail',
          execute: async ({ input, context }) => {
            const result = await run(guardrailAgent, input, { context });
            return {
              tripwireTriggered: result.finalOutput?.isMathHomework ?? false,
              outputInfo: result.finalOutput,
            };
          },
        },
      ],
    });

    const inputs = [
      'What is the capital of California?',
      'Can you help me solve for x: 2x + 5 = 11?',
    ];
    for (const input of inputs) {
      try {
        const result = await run(agent, input);
        console.log(result.finalOutput);
      } catch (e: unknown) {
        console.log(
          `Sorry, I can't help you with your math homework. (error: ${e})`,
        );
      }
    }
  });
}

main().catch(console.error);



================================================
FILE: examples/agent-patterns/llm-as-a-judge.ts
================================================
import { Agent, AgentInputItem, run, withTrace } from '@openai/agents';
import { z } from 'zod';
import readline from 'node:readline/promises';

const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout,
});

// Define the agents
const storyOutlineGenerator = new Agent({
  name: 'story_outline_generator',
  instructions:
    "You generate a very short story outline based on the user's input. If there is any feedback provided, use it to improve the outline.",
});

const EvaluationFeedback = z.object({
  feedback: z.string(),
  score: z.enum(['pass', 'needs_improvement', 'fail']),
});

const evaluator = new Agent({
  name: 'evaluator',
  instructions:
    "You evaluate a story outline and decide if it's good enough to start writing the story. If it's not good enough, you provide feedback on what needs to be improved. Never give it a pass on the first try.",
  outputType: EvaluationFeedback,
});

async function main() {
  const inputPrompt = await rl.question(
    'What kind of story would you like to hear? ',
  );

  if (!inputPrompt) {
    throw new Error('No input prompt provided');
  }

  let inputItems: AgentInputItem[] = [{ content: inputPrompt, role: 'user' }];
  let latestOutline: string | undefined = undefined;

  await withTrace('LLM as a judge', async () => {
    let turns = 0;
    while (turns < 5) {
      const storyOutlineResult = await run(storyOutlineGenerator, inputItems);
      if (!storyOutlineResult.finalOutput) {
        throw new Error('No story outline');
      }
      inputItems = storyOutlineResult.history;
      latestOutline = storyOutlineResult.finalOutput;
      console.log('Story outline generated');

      const evaluatorResult = await run(evaluator, inputItems);
      const result = evaluatorResult.finalOutput;
      console.log(`Evaluator score: ${result?.score}`);

      if (result?.score === 'pass') {
        console.log('Story outline is good enough, exiting.');
        return;
      }
      console.log('Re-running with feedback');

      inputItems.push({
        content: `Feedback: ${result?.feedback}`,
        role: 'user',
      });
      turns++;
    }
  });
  console.log(`Final story outline: ${latestOutline}`);

  rl.close();
}

main().catch((error) => {
  console.error('Error:', error);
  process.exit(1);
});



================================================
FILE: examples/agent-patterns/output-guardrails.ts
================================================
import { Agent, run, withTrace } from '@openai/agents';
import { z } from 'zod';

async function main() {
  withTrace('Output Guardrail Example', async () => {
    const inputs = [
      'Hi, there! My name is John.',
      'My phone number is 650-123-4567. Where do you think I live?',
    ];

    const textAgent = new Agent({
      name: 'Assistnt',
      instructions: 'You are a helpful assistant.',
      outputGuardrails: [
        {
          name: 'Phone Number Guardrail',
          execute: async ({ agentOutput }) => {
            const hasPhoneNumber = agentOutput.includes('650');
            return {
              tripwireTriggered: hasPhoneNumber,
              outputInfo: 'Phone number found',
            };
          },
        },
      ],
    });
    for (const input of inputs) {
      try {
        const result = await run(textAgent, input);
        console.log(result.finalOutput);
      } catch (e: unknown) {
        console.log(`Guardrail tripped. Info: ${e}`);
      }
    }

    const messageOutput = z.object({
      reasoning: z.string(),
      response: z.string(),
      userName: z.string().nullable(),
    });

    const agent = new Agent({
      name: 'Assistnt',
      instructions: 'You are a helpful assistant.',
      outputType: messageOutput,
      outputGuardrails: [
        {
          name: 'Phone Number Guardrail',
          execute: async ({ agentOutput }) => {
            const phoneNumberInResponse = agentOutput.response.includes('650');
            const phoneNumberInReasoning =
              agentOutput.reasoning.includes('650');
            return {
              tripwireTriggered:
                phoneNumberInResponse || phoneNumberInReasoning,
              outputInfo: {
                phone_number_in_response: phoneNumberInResponse,
                phone_number_in_reasoning: phoneNumberInReasoning,
              },
            };
          },
        },
      ],
    });
    for (const input of inputs) {
      try {
        const result = await run(agent, input);
        console.log(result.finalOutput!.response);
      } catch (e: unknown) {
        console.log(`Guardrail tripped. Info: ${e}`);
        // console.trace(e);
      }
    }
  });
}

main();



================================================
FILE: examples/agent-patterns/package.json
================================================
{
  "private": true,
  "name": "agent-patterns",
  "dependencies": {
    "@openai/agents": "workspace:*",
    "chalk": "^5.4.1",
    "zod": "~3.25.40"
  },
  "scripts": {
    "build-check": "tsc --noEmit",
    "start:agents-as-tools": "tsx agents-as-tools.ts",
    "start:deterministic": "tsx deterministic.ts",
    "start:forcing-tool-use": "tsx forcing-tool-use.ts -t default",
    "start:human-in-the-loop-stream": "tsx human-in-the-loop-stream.ts",
    "start:human-in-the-loop": "tsx human-in-the-loop.ts",
    "start:input-guardrails": "tsx input-guardrails.ts",
    "start:llm-as-a-judge": "tsx llm-as-a-judge.ts",
    "start:output-guardrails": "tsx output-guardrails.ts",
    "start:parallelization": "tsx parallelization.ts",
    "start:routing": "tsx routing.ts",
    "start:streamed": "tsx streamed.ts",
    "start:streaming-guardrails": "tsx streaming-guardrails.ts"
  }
}



================================================
FILE: examples/agent-patterns/parallelization.ts
================================================
import { Agent, run, withTrace, extractAllTextOutput } from '@openai/agents';
import readline from 'node:readline/promises';

const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout,
});

const spanishAgent = new Agent({
  name: 'spanish_agent',
  instructions: "You translate the user's message to Spanish",
});

const translationPicker = new Agent({
  name: 'translation_picker',
  instructions: 'You pick the best Spanish translation from the given options.',
});

async function main() {
  const msg = await rl.question(
    "Hi! Enter a message, and we'll translate it to Spanish.\n\n",
  );

  if (!msg) {
    throw new Error('No message provided');
  }

  await withTrace('Parallel translation', async () => {
    const [res1, res2, res3] = await Promise.all([
      run(spanishAgent, msg),
      run(spanishAgent, msg),
      run(spanishAgent, msg),
    ]);

    const outputs = [
      extractAllTextOutput(res1.newItems),
      extractAllTextOutput(res2.newItems),
      extractAllTextOutput(res3.newItems),
    ];

    const translations = outputs.join('\n\n');
    console.log(`\n\nTranslations:\n\n${translations}`);

    const bestTranslationResult = await run(
      translationPicker,
      `Input: ${msg}\n\nTranslations:\n${translations}`,
    );

    console.log('\n\n-----');
    console.log(`Best translation: ${bestTranslationResult.finalOutput}`);
  });

  rl.close();
}

main().catch((error) => {
  console.error('Error:', error);
  process.exit(1);
});



================================================
FILE: examples/agent-patterns/routing.ts
================================================
import {
  Agent,
  run,
  withTrace,
  AgentInputItem,
  StreamedRunResult,
} from '@openai/agents';
import readline from 'node:readline/promises';
import { randomUUID } from 'node:crypto';

const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout,
});

const frenchAgent = new Agent({
  name: 'french_agent',
  instructions: 'You only speak French',
});

const spanishAgent = new Agent({
  name: 'spanish_agent',
  instructions: 'You only speak Spanish',
});

const englishAgent = new Agent({
  name: 'english_agent',
  instructions: 'You only speak English',
});

const triageAgent = new Agent({
  name: 'triage_agent',
  instructions:
    'Handoff to the appropriate agent based on the language of the request.',
  handoffs: [frenchAgent, spanishAgent, englishAgent],
});

async function main() {
  const conversationId = randomUUID().replace(/-/g, '').slice(0, 16);

  let userMsg = await rl.question(
    'Hi! We speak French, Spanish and English. How can I help?\n',
  );

  let agent: Agent<any, any> = triageAgent;
  let inputs: AgentInputItem[] = [{ role: 'user', content: userMsg }];

  while (true) {
    let result: StreamedRunResult<any, Agent<any, any>> | undefined;
    await withTrace(
      'Routing example',
      async () => {
        result = await run(agent, inputs, { stream: true });

        result
          .toTextStream({ compatibleWithNodeStreams: true })
          .pipe(process.stdout);

        await result.completed;
      },
      { groupId: conversationId },
    );

    if (!result) {
      throw new Error('No result');
    }

    inputs = result.history;
    process.stdout.write('\n');

    userMsg = await rl.question('Enter a message:\n');
    inputs.push({ role: 'user', content: userMsg });
    agent = result.currentAgent ?? agent;
  }
}

main().catch((error) => {
  console.error('Error:', error);
  process.exit(1);
});



================================================
FILE: examples/agent-patterns/streamed.ts
================================================
import { Agent, Runner, tool } from '@openai/agents';
import chalk from 'chalk';
import { z } from 'zod';

const storyTellerAgent = new Agent({
  name: 'Storyteller',
  instructions:
    'You are a talented story teller that can tell an engaging 3-4 paragraph story on any topic.',
});

const getWeatherTool = tool({
  name: 'get_weather',
  description: 'Get the weather for a given city',
  parameters: z.object({
    city: z.string(),
  }),
  execute: async (input) => {
    return `The weather in ${input.city} is sunny`;
  },
});

const weatherAgent = new Agent({
  name: 'Weather Agent',
  tools: [getWeatherTool],
});

const runner = new Runner({
  model: 'gpt-4.1-mini',
});

async function main() {
  console.log(chalk.bgCyan('  ● Text only stream  \n'));

  const storyStream = await runner.run(
    storyTellerAgent,
    'Tell me a story about corgis',
    {
      // enable streaming
      stream: true,
    },
  );

  // If you only care about the text you can use the transformed textStream
  storyStream
    .toTextStream({ compatibleWithNodeStreams: true })
    .pipe(process.stdout);

  // waiting to make sure that we are done with handling the stream
  await storyStream.completed;

  console.log(chalk.bgCyan('\n\n  ● All event stream  \n'));

  const weatherStream = await runner.run(
    weatherAgent,
    'What is the weather in San Francisco and Seattle?',
    {
      stream: true,
    },
  );

  for await (const event of weatherStream) {
    // these are the raw events from the model
    if (event.type === 'raw_model_stream_event') {
      console.log(`${chalk.bgWhite(event.type)} %o`, event.data);
    }

    // agent updated events
    if (event.type == 'agent_updated_stream_event') {
      console.log(
        `${chalk.bgGreen(event.type)} New agent: %s`,
        event.agent.name,
      );
    }

    // Agent SDK specific events
    if (event.type === 'run_item_stream_event') {
      console.log(`${chalk.bgYellow(event.type)} %o`, event.item);
    }
  }
}

main().catch(console.error);



================================================
FILE: examples/agent-patterns/streaming-guardrails.ts
================================================
import { Agent, run } from '@openai/agents';
import { z } from 'zod';

async function main() {
  const agent = new Agent({
    name: 'Assistnt',
    instructions:
      'You are a helpful assistant. You ALWAYS write long responses, making sure to be verbose and detailed.',
  });

  const GuardrailOutput = z.object({
    reasoning: z.string(),
    isReadableByTenYearOld: z.boolean(),
  });

  const guardrailAgent = new Agent({
    name: 'Checker',
    model: 'gpt-4o-mini',
    instructions:
      'You will be given a question and a response. Your goal is to judge whether the response is simple enough to be understood by a ten year old.',
    outputType: GuardrailOutput,
  });

  async function runGuardrail(text: string) {
    const result = await run(guardrailAgent, text);
    return result.finalOutput;
  }

  let currentText = '';
  let nextGuardrailCheckLen = 300;
  const result = await run(
    agent,
    'What is a black hole, and how does it behave?',
    { stream: true },
  );
  for await (const event of result) {
    if (
      event.type === 'raw_model_stream_event' &&
      event.data.type === 'output_text_delta'
    ) {
      process.stdout.write(event.data.delta);
      currentText += event.data.delta;
      if (currentText.length > nextGuardrailCheckLen) {
        const guardrailResult = await runGuardrail(currentText);
        if (guardrailResult && !guardrailResult.isReadableByTenYearOld) {
          console.log(
            `\n\nGuardrail tripped. Reasoning: ${guardrailResult.reasoning}`,
          );
          return;
        }
        nextGuardrailCheckLen += 300;
      }
    }
  }
  const guardrailResult = await runGuardrail(currentText);
  if (guardrailResult && !guardrailResult.isReadableByTenYearOld) {
    console.log(
      `\n\nGuardrail tripped. Reasoning: ${guardrailResult.reasoning}`,
    );
    return;
  }
  console.log(`\n\n${result.finalOutput}`);
}

main();



================================================
FILE: examples/agent-patterns/tsconfig.json
================================================
{
  "extends": "../../tsconfig.examples.json"
}



================================================
FILE: examples/ai-sdk/README.md
================================================
# AI SDK Example

This example shows how to run the Agents SDK with a model provided by the [AI SDK](https://www.npmjs.com/package/@ai-sdk/openai).

The [ai-sdk-model.ts](./ai-sdk-model.ts) script:

- Wraps the AI SDK `openai` provider with `aisdk` from `@openai/agents-extensions`.
- Creates a simple `get_weather` tool that returns a mock weather string.
- Defines a data agent that uses this model and tool.
- Runs a parent agent that hands off to the data agent to answer a weather question.

## Running the script

From the repository root, execute:

```bash
pnpm -F ai-sdk start:sdk-model
```

The script prints the final output produced by the runner.




================================================
FILE: examples/ai-sdk/ai-sdk-model.ts
================================================
import { z } from 'zod';
import { Agent, run, tool } from '@openai/agents';
import { openai } from '@ai-sdk/openai';
import { aisdk } from '@openai/agents-extensions';

const model = aisdk(openai('gpt-4.1-nano'));

const sleep = (ms: number) => new Promise((resolve) => setTimeout(resolve, ms));

const getWeatherTool = tool({
  name: 'get_weather',
  description: 'Get the weather for a given city',
  parameters: z.object({ city: z.string() }),
  execute: async (input) => {
    await sleep(300);
    return `The weather in ${input.city} is sunny`;
  },
});

const dataAgent = new Agent({
  name: 'Weather Data Agent',
  instructions: 'You are a weather data agent.',
  handoffDescription:
    'When you are asked about the weather, you will use tools to get the weather.',
  tools: [getWeatherTool],
  model, // Using the AI SDK model for this agent
});

const agent = new Agent({
  name: 'Helpful Assistant',
  instructions:
    'You are a helpful assistant. When you need to get the weather, you can hand off the task to the Weather Data Agent.',
  handoffs: [dataAgent],
});

async function main() {
  const result = await run(
    agent,
    'Hello what is the weather in San Francisco and oakland?',
  );
  console.log(result.finalOutput);
}

main();



================================================
FILE: examples/ai-sdk/package.json
================================================
{
  "private": true,
  "name": "ai-sdk",
  "dependencies": {
    "@openai/agents": "workspace:*",
    "@openai/agents-extensions": "workspace:*",
    "@ai-sdk/openai": "^1.1.3",
    "zod": "~3.25.40"
  },
  "scripts": {
    "build-check": "tsc --noEmit",
    "start:sdk-model": "tsx ai-sdk-model.ts",
    "start:stream": "tsx stream.ts"
  }
}



================================================
FILE: examples/ai-sdk/stream.ts
================================================
import { z } from 'zod';
import { Agent, run, tool } from '@openai/agents';
import { openai } from '@ai-sdk/openai';
import { aisdk } from '@openai/agents-extensions';

const model = aisdk(openai('gpt-4.1-nano'));

const getWeatherTool = tool({
  name: 'get_weather',
  description: 'Get the weather for a given city',
  parameters: z.object({ city: z.string() }),
  async execute({ city }) {
    return `The weather in ${city} is sunny`;
  },
});

const agent = new Agent({
  name: 'Weather agent',
  instructions: 'You provide weather information.',
  tools: [getWeatherTool],
  model,
});

async function main() {
  const stream = await run(agent, 'What is the weather in San Francisco?', {
    stream: true,
  });

  for await (const text of stream.toTextStream()) {
    process.stdout.write(text);
  }
  console.log();
}

if (require.main === module) {
  main().catch(console.error);
}



================================================
FILE: examples/ai-sdk/tsconfig.json
================================================
{
  "extends": "../../tsconfig.examples.json"
}



================================================
FILE: examples/basic/README.md
================================================
# Basic Examples

This directory contains small scripts that demonstrate features of the Agents SDK.
Run them with `pnpm` using the commands shown below.

- `hello-world.ts` – Basic agent that responds in haiku.
  ```bash
  pnpm -F basic start:hello-world
  ```
- `chat.ts` – Interactive CLI chat with a weather handoff.
  ```bash
  pnpm -F basic start:chat
  ```
- `stream-text.ts` – Stream plain text responses.
  ```bash
  pnpm -F basic start:stream-text
  ```
- `stream-items.ts` – Stream events including tool usage.
  ```bash
  pnpm -F basic start:stream-items
  ```
- `dynamic-system-prompt.ts` – Instructions picked dynamically per run.
  ```bash
  pnpm -F basic start:dynamic-system-prompt
  ```
- `lifecycle-example.ts` – Logs detailed lifecycle events and usage.
  ```bash
  pnpm -F basic start:lifecycle-example
  ```
- `agent-lifecycle-example.ts` – Minimal lifecycle hooks demo.
  ```bash
  pnpm -F basic start:agent-lifecycle-example
  ```
- `local-image.ts` – Send a local image to the agent.
  ```bash
  pnpm -F basic start:local-image
  ```
- `remote-image.ts` – Send an image URL to the agent.
  ```bash
  pnpm -F basic start:remote-image
  ```
- `previous-response-id.ts` – Continue a conversation using
  `previousResponseId`.
  ```bash
  pnpm -F basic start:previous-response-id
  ```
- `json-schema-output-type.ts` – Structured output with JSON Schema.
  ```bash
  pnpm -F basic start:json-schema-output-type
  ```
- `tool-use-behavior.ts` – Require specific tools before final output.
  ```bash
  pnpm -F basic start:tool-use-behavior
  ```
- `tools.ts` – Simple tool calling example.
  ```bash
  pnpm -F basic start:tools
  ```
- `index.ts` – Basic handoff between two agents.
  ```bash
  pnpm -F basic start
  ```



================================================
FILE: examples/basic/agent-lifecycle-example.ts
================================================
import { Agent, run, tool } from '@openai/agents';
import { z } from 'zod';

const randomNumberTool = tool({
  name: 'random_number',
  description: 'Generate a random number up to the provided maximum.',
  parameters: z.object({ max: z.number() }),
  execute: async ({ max }: { max: number }) => {
    return Math.floor(Math.random() * (max + 1)).toString();
  },
});

const multiplyByTwoTool = tool({
  name: 'multiply_by_two',
  description: 'Simple multiplication by two.',
  parameters: z.object({ x: z.number() }),
  execute: async ({ x }: { x: number }) => {
    return (x * 2).toString();
  },
});

const multiplyAgent = new Agent({
  name: 'Multiply Agent',
  instructions: 'Multiply the number by 2 and then return the final result.',
  tools: [multiplyByTwoTool],
  outputType: z.object({ number: z.number() }),
});

const startAgent = new Agent({
  name: 'Start Agent',
  instructions:
    "Generate a random number. If it's even, stop. If it's odd, hand off to the multiply agent.",
  tools: [randomNumberTool],
  outputType: z.object({ number: z.number() }),
  handoffs: [multiplyAgent],
});

function attachHooks(agent: Agent<any, any>) {
  agent.on('agent_start', (_ctx, agent) => {
    console.log(`${agent.name} started`);
  });
  agent.on('agent_end', (_ctx, output) => {
    console.log(`${agent.name} ended with output ${output}`);
  });
  agent.on('agent_handoff', (_ctx, nextAgent) => {
    console.log(`${agent.name} handed off to ${nextAgent.name}`);
  });
  agent.on('agent_tool_start', (_ctx, tool) => {
    console.log(`${agent.name} started tool ${tool.name}`);
  });
  agent.on('agent_tool_end', (_ctx, tool, output) => {
    console.log(`${agent.name} tool ${tool.name} ended with output ${output}`);
  });
}

attachHooks(startAgent);
attachHooks(multiplyAgent);

async function main() {
  const result = await run(startAgent, 'Generate a random number up to 10');
  console.log(result.finalOutput);
}

if (require.main === module) {
  main().catch(console.error);
}



================================================
FILE: examples/basic/chat.ts
================================================
import {
  Agent,
  AgentInputItem,
  run,
  tool,
  user,
  withTrace,
} from '@openai/agents';
import { createInterface } from 'node:readline/promises';
import { z } from 'zod';

async function ask(prompt: string) {
  const rl = createInterface({ input: process.stdin, output: process.stdout });
  const message = await rl.question(prompt);
  rl.close();
  return message;
}

const getWeatherTool = tool({
  name: 'get_weather',
  description: 'Get the weather for a given city',
  parameters: z.object({
    demo: z.string(),
  }),
  execute: async (input) => {
    return `The weather in ${input.demo} is sunny`;
  },
});

const weatherAgent = new Agent({
  name: 'Weather Agent',
  handoffDescription: 'Knows everything about the weather but nothing else.',
  tools: [getWeatherTool],
});

const agent = new Agent({
  name: 'Basic test agent',
  instructions: 'You are a basic agent',
  handoffDescription: 'An expert on everything but the weather.',
  handoffs: [weatherAgent],
});

weatherAgent.handoffs.push(agent);

let history: AgentInputItem[] = [];
let latestAgent: Agent = agent;

async function main() {
  console.log('Type exit() to leave');
  await withTrace('Chat Session', async () => {
    while (true) {
      const message = await ask('> ');
      if (message === 'exit()') {
        return;
      }
      history.push(user(message));
      const result = await run(latestAgent, history);

      console.log(`[${latestAgent.name}] ${result.finalOutput}`);

      if (result.lastAgent) {
        latestAgent = result.lastAgent;
      }
      history = result.history;
    }
  });
}

main().catch(console.error);



================================================
FILE: examples/basic/dynamic-system-prompt.ts
================================================
import { Agent, RunContext, run } from '@openai/agents';

type Style = 'haiku' | 'pirate' | 'robot';

interface CustomContext {
  style: Style;
}

function customInstructions(
  runContext: RunContext<CustomContext>,
  _agent: Agent<CustomContext>,
): string {
  const context = runContext.context;
  if (context.style === 'haiku') {
    return 'Only respond in haikus.';
  } else if (context.style === 'pirate') {
    return 'Respond as a pirate.';
  } else {
    return "Respond as a robot and say 'beep boop' a lot.";
  }
}

const agent = new Agent<CustomContext>({
  name: 'Chat agent',
  instructions: customInstructions,
});

async function main() {
  const choices: Style[] = ['haiku', 'pirate', 'robot'];
  const choice = choices[Math.floor(Math.random() * choices.length)];
  const context: CustomContext = { style: choice };
  console.log(`Using style: ${choice}\n`);

  const userMessage = 'Tell me a joke.';
  console.log(`User: ${userMessage}`);
  const result = await run(agent, userMessage, { context });

  console.log(`Assistant: ${result.finalOutput}`);
}

if (require.main === module) {
  main().catch(console.error);
}



================================================
FILE: examples/basic/hello-world.ts
================================================
import { Agent, run } from '@openai/agents';

async function main() {
  const agent = new Agent({
    name: 'Assistant',
    instructions: 'You only respond in haikus.',
  });

  const result = await run(agent, 'Tell me about recursion in programming.');
  console.log(result.finalOutput);
  // Example output:
  // Function calls itself,
  // Looping in smaller pieces,
  // Endless by design.
}

if (require.main === module) {
  main().catch(console.error);
}



================================================
FILE: examples/basic/index.ts
================================================
import { z } from 'zod';
import { Agent, Runner, tool } from '@openai/agents';

const getWeatherTool = tool({
  name: 'get_weather',
  description: 'Get the weather for a given city',
  parameters: z.object({ city: z.string() }),
  execute: async (input) => {
    return `The weather in ${input.city} is sunny`;
  },
});

const dataAgentTwo = new Agent({
  name: 'Data agent',
  instructions: 'You are a data agent',
  handoffDescription: 'You know everything about the weather',
  tools: [getWeatherTool],
});

const agent = new Agent({
  name: 'Basic test agent',
  instructions: 'You are a basic agent',
  handoffs: [dataAgentTwo],
});

async function main() {
  const runner = new Runner({
    groupId: 'My group',
    traceMetadata: { user_id: '123' },
  });
  const result = await runner.run(
    agent,
    'What is the weather in San Francisco?',
  );

  console.log(result.finalOutput);
}

main();



================================================
FILE: examples/basic/json-schema-output-type.ts
================================================
import { Agent, run, JsonSchemaDefinition } from '@openai/agents';

const WeatherSchema: JsonSchemaDefinition = {
  type: 'json_schema',
  name: 'Weather',
  strict: true,
  schema: {
    type: 'object',
    properties: { city: { type: 'string' }, forecast: { type: 'string' } },
    required: ['city', 'forecast'],
    additionalProperties: false,
  },
};

async function main() {
  const agent = new Agent({
    name: 'Weather reporter',
    instructions: 'Return the city and a short weather forecast.',
    outputType: WeatherSchema,
  });

  const result = await run(agent, 'What is the weather in London?');
  console.log(result.finalOutput);
  // { city: 'London', forecast: '...'}
}

main().catch(console.error);



================================================
FILE: examples/basic/lifecycle-example.ts
================================================
import { Agent, run, tool, Usage } from '@openai/agents';
import { z } from 'zod';

const randomNumberTool = tool({
  name: 'random_number',
  description: 'Generate a random number up to the provided maximum.',
  parameters: z.object({ max: z.number() }),
  execute: async ({ max }: { max: number }) => {
    return Math.floor(Math.random() * (max + 1)).toString();
  },
});

const multiplyByTwoTool = tool({
  name: 'multiply_by_two',
  description: 'Simple multiplication by two.',
  parameters: z.object({ x: z.number() }),
  execute: async ({ x }: { x: number }) => {
    return (x * 2).toString();
  },
});

const multiplyAgent = new Agent({
  name: 'Multiply Agent',
  instructions: 'Multiply the number by 2 and then return the final result.',
  tools: [multiplyByTwoTool],
  outputType: z.object({ number: z.number() }),
});

const startAgent = new Agent({
  name: 'Start Agent',
  instructions:
    "Generate a random number. If it's even, stop. If it's odd, hand off to the multiply agent.",
  tools: [randomNumberTool],
  outputType: z.object({ number: z.number() }),
  handoffs: [multiplyAgent],
});

function attachHooks(agent: Agent<any, any>) {
  let eventCounter = 0;
  function toPrintableUsage(usage: Usage): string {
    if (!usage) return 'No usage info';
    return (
      `${usage.requests ?? 0} requests, ` +
      `${usage.inputTokens ?? 0} input tokens, ` +
      `${usage.outputTokens ?? 0} output tokens, ` +
      `${usage.totalTokens ?? 0} total tokens`
    );
  }

  agent.on('agent_start', (ctx, agent) => {
    eventCounter++;
    console.log(
      `### ${eventCounter}: ${agent.name} started. Usage: ${toPrintableUsage(ctx?.usage)}`,
    );
  });
  agent.on('agent_end', (ctx, output) => {
    eventCounter++;
    console.log(
      `### ${eventCounter}: ${agent.name} ended with output ${JSON.stringify(output)}. Usage: ${toPrintableUsage(ctx?.usage)}`,
    );
  });
  agent.on('agent_tool_start', (ctx, tool) => {
    eventCounter++;
    console.log(
      `### ${eventCounter}: Tool ${tool.name} started. Usage: ${toPrintableUsage(ctx?.usage)}`,
    );
  });
  agent.on('agent_tool_end', (ctx, tool, result) => {
    eventCounter++;
    console.log(
      `### ${eventCounter}: Tool ${tool.name} ended with result ${JSON.stringify(result)}. Usage: ${toPrintableUsage(ctx?.usage)}`,
    );
  });
  agent.on('agent_handoff', (ctx, nextAgent) => {
    eventCounter++;
    console.log(
      `### ${eventCounter}: Handoff from ${agent.name} to ${nextAgent.name}. Usage: ${toPrintableUsage(ctx?.usage)}`,
    );
  });
}

attachHooks(startAgent);
attachHooks(multiplyAgent);

async function main() {
  const result = await run(startAgent, 'Generate a random number up to 10');
  console.log(result.finalOutput);
}

if (require.main === module) {
  main().catch(console.error);
}



================================================
FILE: examples/basic/local-file.ts
================================================
import fs from 'node:fs';
import path from 'node:path';
import { Agent, run } from '@openai/agents';

const filePath = path.join(
  __dirname,
  'media/partial_o3-and-o4-mini-system-card.pdf',
);

function fileToBase64(filePath: string): string {
  const fileBuffer = fs.readFileSync(filePath);
  return fileBuffer.toString('base64');
}

async function main() {
  const agent = new Agent({
    name: 'Assistant',
    instructions: 'You are a helpful assistant.',
  });

  const b64File = fileToBase64(filePath);
  const result = await run(agent, [
    {
      role: 'user',
      content: [
        {
          type: 'input_file',
          file: `data:application/pdf;base64,${b64File}`,
          providerData: {
            filename: 'partial_o3-and-o4-mini-system-card.pdf',
          },
        },
      ],
    },
    {
      role: 'user',
      content: 'What is the first sentence of the introduction?',
    },
  ]);

  console.log(result.finalOutput);
  // OpenAI o3 and OpenAI o4-mini combine state-of-the-art reasoning with full tool capabilities — web browsing, Python, image and file analysis, image generation, canvas, automations, file search, and memory.
}

if (require.main === module) {
  main().catch(console.error);
}



================================================
FILE: examples/basic/local-image.ts
================================================
import fs from 'node:fs';
import path from 'node:path';
import { Agent, run } from '@openai/agents';

const bisonImagePath = path.join(__dirname, 'media/image_bison.jpg');

function imageToBase64(imagePath: string): string {
  const imageBuffer = fs.readFileSync(imagePath);
  return imageBuffer.toString('base64');
}

async function main() {
  const agent = new Agent({
    name: 'Assistant',
    instructions: 'You are a helpful assistant.',
  });

  const b64Image = imageToBase64(bisonImagePath);
  const result = await run(agent, [
    {
      role: 'user',
      content: [
        {
          type: 'input_image',
          image: `data:image/jpeg;base64,${b64Image}`,
          providerData: {
            detail: 'auto',
          },
        },
      ],
    },
    {
      role: 'user',
      content: 'What do you see in this image?',
    },
  ]);

  console.log(result.finalOutput);
  // This image shows a large American bison standing on a grassy hill. The bison has a shaggy brown coat, with parts of its fur shedding, and prominent curved horns. The background is mostly a light, overcast sky, which makes the bison stand out prominently in the image. There is green grass and some small wild plants in the foreground. The overall scene appears natural and serene, likely in a prairie or grassland environment.
}

if (require.main === module) {
  main().catch(console.error);
}



================================================
FILE: examples/basic/package.json
================================================
{
  "private": true,
  "name": "basic",
  "dependencies": {
    "@openai/agents": "workspace:*",
    "zod": "~3.25.40"
  },
  "scripts": {
    "build-check": "tsc --noEmit",
    "start": "tsx index.ts",
    "start:agent-lifecycle-example": "tsx agent-lifecycle-example.ts",
    "start:chat": "tsx chat.ts",
    "start:dynamic-system-prompt": "tsx dynamic-system-prompt.ts",
    "start:hello-world": "tsx hello-world.ts",
    "start:lifecycle-example": "tsx lifecycle-example.ts",
    "start:local-image": "tsx local-image.ts",
    "start:previous-response-id": "tsx previous-response-id.ts",
    "start:prompt": "tsx prompt-id.ts",
    "start:remote-image": "tsx remote-image.ts",
    "start:stream-items": "tsx stream-items.ts",
    "start:stream-text": "tsx stream-text.ts",
    "start:json-schema-output-type": "tsx json-schema-output-type.ts",
    "start:tool-use-behavior": "tsx tool-use-behavior.ts",
    "start:tools": "tsx tools.ts",
    "start:reasoning": "tsx reasoning.ts",
    "start:local-file": "tsx local-file.ts"
  }
}



================================================
FILE: examples/basic/previous-response-id.ts
================================================
import { Agent, run } from '@openai/agents';

async function main() {
  const agent = new Agent({
    name: 'Assistant',
    instructions: 'You are a helpful assistant. be VERY concise.',
  });

  let result = await run(
    agent,
    'What is the largest country in South America?',
  );
  console.log(result.finalOutput); // e.g., Brazil

  result = await run(agent, 'What is the capital of that country?', {
    previousResponseId: result.lastResponseId,
  });
  console.log(result.finalOutput); // e.g., Brasilia
}

async function mainStream() {
  const agent = new Agent({
    name: 'Assistant',
    instructions: 'You are a helpful assistant. be VERY concise.',
  });

  let result = await run(
    agent,
    'What is the largest country in South America?',
    {
      stream: true,
    },
  );

  for await (const event of result) {
    if (
      event.type === 'raw_model_stream_event' &&
      event.data.type === 'output_text_delta'
    )
      process.stdout.write(event.data.delta);
  }
  console.log();

  result = await run(agent, 'What is the capital of that country?', {
    stream: true,
    previousResponseId: result.lastResponseId,
  });

  // toTextStream() automatically returns a readable stream of strings intended to be displayed
  // to the user
  for await (const event of result.toTextStream()) {
    process.stdout.write(event);
  }
  console.log();
}

async function promptAndRun() {
  const readline = await import('node:readline/promises');
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
  });
  const isStream = await rl.question('Run in stream mode? (y/n): ');
  rl.close();
  if (isStream.trim().toLowerCase() === 'y') {
    await mainStream();
  } else {
    await main();
  }
}

if (require.main === module) {
  promptAndRun().catch(console.error);
}



================================================
FILE: examples/basic/prompt-id.ts
================================================
import { Agent, run } from '@openai/agents';

async function main() {
  const agent = new Agent({
    name: 'Assistant',
    prompt: {
      promptId: 'pmpt_684b3b772e648193b92404d7d0101d8a07f7a7903e519946',
      version: '1',
      variables: {
        poem_style: 'limerick',
      },
    },
  });

  const result = await run(agent, 'Write about unrequited love.');
  console.log(result.finalOutput);
}

if (require.main === module) {
  main().catch(console.error);
}



================================================
FILE: examples/basic/reasoning.ts
================================================
import { styleText } from 'node:util';
import { Agent, run } from '@openai/agents';

const ASSISTANT_PREFIX = styleText(['bgGreen', 'black'], 'Assistant');
const THINKING_PREFIX = styleText(['bgGray', 'black'], 'Thought');

async function main() {
  const agent = new Agent({
    name: 'Agent',
    model: 'o3',
    modelSettings: {
      providerData: {
        reasoning: {
          effort: 'high',
          summary: 'auto',
        },
      },
    },
  });

  const result = await run(agent, 'How many r are in strawberry?');

  for (const item of result.newItems) {
    if (item.type === 'reasoning_item') {
      for (const entry of item.rawItem.content) {
        if (entry.type === 'input_text') {
          console.log(`${THINKING_PREFIX}: ${entry.text}`);
        }
      }
    }
  }

  console.log(`${ASSISTANT_PREFIX}: ${result.finalOutput}`);
}

main().catch(console.error);



================================================
FILE: examples/basic/remote-image.ts
================================================
import { Agent, run } from '@openai/agents';

const URL =
  'https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg';

async function main() {
  const agent = new Agent({
    name: 'Assistant',
    instructions: 'You are a helpful assistant.',
  });

  const result = await run(agent, [
    {
      role: 'user',
      content: [
        {
          type: 'input_image',
          image: URL,
          providerData: {
            detail: 'auto',
          },
        },
      ],
    },
    {
      role: 'user',
      content: 'What do you see in this image?',
    },
  ]);

  console.log(result.finalOutput);
  // This image shows the Golden Gate Bridge, a famous suspension bridge located in San Francisco, California. The bridge is painted in its signature "International Orange" color and spans the Golden Gate Strait, connecting San Francisco to Marin County. The photo is taken during daylight, with the city and hills visible in the background and water beneath the bridge. The bridge is an iconic landmark and a symbol of San Francisco.
}

if (require.main === module) {
  main().catch(console.error);
}



================================================
FILE: examples/basic/stream-items.ts
================================================
import { Agent, run, tool } from '@openai/agents';
import { z } from 'zod';

// Tool that returns a random integer between 1 and 10
const howManyJokesTool = tool({
  name: 'how_many_jokes',
  description: 'Return a random integer between 1 and 10.',
  parameters: z.object({}),
  execute: async () => String(Math.floor(Math.random() * 10) + 1),
});

async function main() {
  const agent = new Agent({
    name: 'Joker',
    instructions:
      'First call the `how_many_jokes` tool, then tell that many jokes.',
    tools: [howManyJokesTool],
  });

  const stream = await run(agent, 'Hello', { stream: true });
  console.log('=== Run starting ===');
  for await (const event of stream.toStream()) {
    // We'll ignore the raw responses event deltas
    if (event.type === 'raw_model_stream_event') {
      continue;
    } else if (event.type === 'agent_updated_stream_event') {
      console.log(`Agent updated: ${event.agent.name}`);
      continue;
    } else if (event.type === 'run_item_stream_event') {
      if (event.item.type === 'tool_call_item') {
        console.log('-- Tool was called');
      } else if (event.item.type === 'tool_call_output_item') {
        console.log(`-- Tool output: ${event.item.output}`);
      } else if (event.item.type === 'message_output_item') {
        console.log(`-- Message output:\n ${event.item.content}`);
      }
    }
  }
  console.log('=== Run complete ===');
  //   === Run starting ===
  //   -- Tool was called
  //   -- Tool output: 7
  //   -- Message output:
  //    Hi! I’m about to tell you 7 jokes. Ready? Here we go:
  //
  //   1. Why don't skeletons fight each other? They don't have the guts!
  //
  //   2. Parallel lines have so much in common. It's a shame they'll never meet.
  //
  //   3. Why did the scarecrow win an award? Because he was outstanding in his field!
  //
  //   4. Why can't you give Elsa a balloon? Because she will let it go!
  //
  //   5. Why did the golfer bring two pairs of pants? In case he got a hole in one!
  //
  //   6. I told my wife she was drawing her eyebrows too high. She looked surprised.
  //
  //   7. Why are elevator jokes so classic and good? They work on many levels!
  //
  //   Hope that made you smile! Would you like a few more, or is there anything else I can do for you?
  //   === Run complete ===
}

if (require.main === module) {
  main().catch(console.error);
}



================================================
FILE: examples/basic/stream-text.ts
================================================
import { Agent, run } from '@openai/agents';

async function main() {
  const agent = new Agent({
    name: 'Joker',
    instructions: 'You are a helpful assistant.',
  });

  const stream = await run(agent, 'Please tell me 5 jokes.', {
    stream: true,
  });
  for await (const event of stream.toTextStream()) {
    process.stdout.write(event);
  }
  console.log();
}

if (require.main === module) {
  main().catch(console.error);
}



================================================
FILE: examples/basic/tool-use-behavior.ts
================================================
import { z } from 'zod';
import { Agent, run, tool } from '@openai/agents';

const Weather = z.object({
  city: z.string(),
  result: z.string(),
});
type Weather = z.infer<typeof Weather>;

const getWeatherTool = tool({
  name: 'get_weather',
  description: 'Get the weather for a given city',
  parameters: z.object({ city: z.string() }),
  execute: async ({ city }): Promise<Weather> => ({ city, result: 'sunny' }),
});

const saySomethingTool = tool({
  name: 'say_something',
  description: 'Say something',
  parameters: z.object({}),
  execute: async () => 'Thanks for asking!',
});

const instructions =
  'You know everything about the weather. Call get_weather to get the weather first. You must call say_something before final output.';

const agent = new Agent({
  name: 'Data agent',
  instructions,
  toolUseBehavior: { stopAtToolNames: ['get_weather'] },
  outputType: Weather,
  tools: [getWeatherTool, saySomethingTool],
});

const agent2 = new Agent({
  name: 'Data agent',
  instructions,
  outputType: Weather,
  tools: [getWeatherTool, saySomethingTool],
});

const agent3 = new Agent({
  name: 'Data agent',
  instructions,
  outputType: 'text',
  tools: [getWeatherTool, saySomethingTool],
});

async function main() {
  const input = 'What is the weather in San Francisco?';
  const result = await run(agent, input);
  const finalOutput = result.finalOutput;
  // { city: 'San Francisco', result: 'sunny' }
  console.log(finalOutput);

  const result2 = await run(agent2, input);
  const finalOutput2 = result2.finalOutput;
  // {
  //   city: 'San Francisco',
  //   result: 'The weather in San Francisco is sunny. Thanks for asking!'
  // }
  console.log(finalOutput2);

  const result3 = await run(agent3, input);
  const finalOutput3 = result3.finalOutput;
  // The weather in San Francisco is sunny. Thanks for asking!
  console.log(finalOutput3);
}

main();



================================================
FILE: examples/basic/tools.ts
================================================
import { Agent, run, tool } from '@openai/agents';
import { z } from 'zod';

type Weather = {
  city: string;
  temperatureRange: string;
  conditions: string;
};

const getWeather = tool({
  name: 'get_weather',
  description: 'Get the weather for a city.',
  parameters: z.object({ city: z.string() }),
  execute: async ({ city }): Promise<Weather> => {
    return {
      city,
      temperatureRange: '14-20C',
      conditions: 'Sunny with wind.',
    };
  },
});

const agent = new Agent({
  name: 'Hello world',
  instructions: 'You are a helpful agent.',
  tools: [getWeather],
});

async function main() {
  const result = await run(agent, "What's the weather in Tokyo?");
  console.log(result.finalOutput);
  // The weather in Tokyo is sunny with some wind, and the temperature ranges between 14°C and 20°C.
}

if (require.main === module) {
  main();
}



================================================
FILE: examples/basic/tsconfig.json
================================================
{
  "extends": "../../tsconfig.examples.json"
}



================================================
FILE: examples/customer-service/README.md
================================================
# Customer Service Agent

This example demonstrates a multi-agent customer service workflow for an airline. The `index.ts` script sets up a triage agent that can delegate to specialized FAQ and seat booking agents. Tools are used to look up common questions and to update a passenger's seat. Interaction occurs through a simple CLI loop, showing how agents can hand off between each other and call tools.

Run the demo with:

```bash
pnpm examples:customer-service
```




================================================
FILE: examples/customer-service/index.ts
================================================
import { z } from 'zod';
import readline from 'node:readline';
import { Agent, withTrace, tool, run, RunContext } from '@openai/agents';
import { RECOMMENDED_PROMPT_PREFIX } from '@openai/agents-core/extensions';

// ------------------------------------------------
// Context

interface AirlineAgentContext {
  passengerName?: string;
  confirmationNumber?: string;
  seatNumber?: string;
  flightNumber?: string;
}

// ------------------------------------------------
// Tools

// FAQ lookup tool
const faqLookupTool = tool({
  name: 'faq_lookup_tool',
  description: 'Lookup frequently asked questions.',
  parameters: z.object({
    question: z.string(),
  }),
  async execute(input: { question: string }) {
    const q = input.question.toLowerCase();
    if (q.includes('bag') || q.includes('baggage')) {
      return (
        'You are allowed to bring one bag on the plane. ' +
        'It must be under 50 pounds and 22 inches x 14 inches x 9 inches.'
      );
    } else if (q.includes('seats') || q.includes('plane')) {
      return (
        'There are 120 seats on the plane. ' +
        'There are 22 business class seats and 98 economy seats. ' +
        'Exit rows are rows 4 and 16. ' +
        'Rows 5-8 are Economy Plus, with extra legroom. '
      );
    } else if (q.includes('wifi')) {
      return 'We have free wifi on the plane, join Airline-Wifi';
    }
    return "I'm sorry, I don't know the answer to that question.";
  },
});

// Mock update_seat tool
const updateSeat = tool({
  name: 'update_seat',
  description: 'Update a seat on a flight',
  parameters: z.object({
    confirmationNumber: z.string(),
    seatNumber: z.string(),
  }),
  async execute(
    input: { confirmationNumber: string; seatNumber: string },
    context?: RunContext<AirlineAgentContext>,
  ) {
    if (context && context.context) {
      context.context.seatNumber = input.seatNumber;
      context.context.confirmationNumber = input.confirmationNumber;
    }
    return `Seat updated to ${input.seatNumber} for confirmation ${input.confirmationNumber}`;
  },
});

// ------------------------------------------------
// Agents

// FAQ Agent
const faqAgent = new Agent({
  name: 'FAQ Agent',
  handoffDescription:
    'A helpful agent that can answer questions about the airline.',
  instructions: `${RECOMMENDED_PROMPT_PREFIX}
You are an FAQ agent. If you are speaking to a customer, you probably were transferred to from the triage agent.
Use the following routine to support the customer.

# Routine
1. Identify the last question asked by the customer.
2. Use the faq lookup tool to answer the question. Do not rely on your own knowledge.
3. If you cannot answer the question, transfer back to the triage agent
`,
  tools: [faqLookupTool],
});

// Seat Booking Agent
const seatBookingAgent = new Agent<AirlineAgentContext>({
  name: 'Seat Booking Agent',
  handoffDescription: 'A helpful agent that can update a seat on a flight.',
  instructions: `${RECOMMENDED_PROMPT_PREFIX}
You are a seat booking agent. If you are speaking to a customer, you probably were transferred to from the triage agent.
Use the following routine to support the customer.

# Routine
1. Ask for their confirmation number.
2. Ask the customer what their desired seat number is.
3. Use the update seat tool to update the seat on the flight.
If the customer asks a question that is not related to the routine, transfer back to the triage agent.`,
  tools: [updateSeat],
});

// Triage Agent
const triageAgent = Agent.create({
  name: 'Triage Agent',
  handoffDescription:
    "A triage agent that can delegate a customer's request to the appropriate agent.",
  instructions: `${RECOMMENDED_PROMPT_PREFIX}
  You are a helpful triaging agent. You can use your tools to delegate questions to other appropriate agents.`,
  handoffs: [faqAgent, seatBookingAgent],
});

// Make sure agents can handoff to each other
faqAgent.handoffs = [triageAgent];
seatBookingAgent.handoffs = [triageAgent];

// ------------------------------------------------
// Main function

// CLI runner loop
const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout,
});

async function promptUser(query: string): Promise<string> {
  return new Promise((resolve) => rl.question(query, resolve));
}

async function main() {
  let currentAgent = triageAgent;
  const context: AirlineAgentContext = {};
  let inputItems: any[] = [];
  while (true) {
    const userInput = await promptUser('Enter your message: ');
    await withTrace('Customer service', async () => {
      inputItems.push({ content: userInput, role: 'user' });
      const result = await run(currentAgent, inputItems, { context });

      console.log(
        '-----------------------------------------------------------',
      );
      console.log(`result.output: ${JSON.stringify(result.output, null, 2)}`);
      console.log(`context: ${JSON.stringify(context, null, 2)}`);
      console.log(
        '-----------------------------------------------------------',
      );

      for (const newItem of result.newItems) {
        // Type guards for RunItem discriminated union
        if (newItem.type === 'message_output_item') {
          const agentName = (newItem as any).agent?.name || 'Agent';
          console.log(`${agentName}: ${newItem.content}`);
        } else if (newItem.type === 'handoff_output_item') {
          const handoffItem = newItem as any;
          console.log(
            `Handed off from ${handoffItem.sourceAgent.name} to ${handoffItem.targetAgent.name}`,
          );
        } else if (newItem.type === 'tool_call_item') {
          const agentName = (newItem as any).agent?.name || 'Agent';
          console.log(`${agentName}: Calling a tool`);
        } else if (newItem.type === 'tool_call_output_item') {
          const agentName = (newItem as any).agent?.name || 'Agent';
          console.log(
            `${agentName}: Tool call output: ${(newItem as any).output}`,
          );
        } else {
          const agentName = (newItem as any).agent?.name || 'Agent';
          console.log(`${agentName}: Skipping item: ${newItem.type}`);
        }
      }
      // Defensive: check if history and lastAgent exist
      if ((result as any).history) {
        inputItems = (result as any).history;
      }
      if ((result as any).lastAgent) {
        currentAgent = (result as any).lastAgent;
      }
    });
  }
}

main().catch((error) => {
  console.error('Error:', error);
  process.exit(1);
});



================================================
FILE: examples/customer-service/package.json
================================================
{
  "private": true,
  "name": "customer-service",
  "dependencies": {
    "@openai/agents": "workspace:*",
    "@openai/agents-core": "workspace:*",
    "zod": "~3.25.40"
  },
  "scripts": {
    "build-check": "tsc --noEmit",
    "start": "tsx index.ts"
  }
}


================================================
FILE: examples/customer-service/tsconfig.json
================================================
{
  "extends": "../../tsconfig.examples.json"
}



================================================
FILE: examples/docs/README.md
================================================
# Documentation Snippets

This directory contains small scripts used throughout the documentation. Run them with `pnpm` using the commands shown below.

- `agents-basic-configuration.ts` – Configure a weather agent with a tool and model.
  ```bash
  pnpm -F docs start:agents-basic-configuration
  ```
- `agents-cloning.ts` – Clone an agent and reuse its configuration.
  ```bash
  pnpm -F docs start:agents-cloning
  ```
- `agents-context.ts` – Access user context from tools during execution.
  ```bash
  pnpm -F docs start:agents-context
  ```
- `agents-dynamic-instructions.ts` – Build instructions dynamically from context.
  ```bash
  pnpm -F docs start:agents-dynamic-instructions
  ```
- `agents-forcing-tool-use.ts` – Require specific tools before producing output.
  ```bash
  pnpm -F docs start:agents-forcing-tool-use
  ```
- `agents-handoffs.ts` – Route requests to specialized agents using handoffs.
  ```bash
  pnpm -F docs start:agents-handoffs
  ```
- `agents-lifecycle-hooks.ts` – Log agent lifecycle events as they run.
  ```bash
  pnpm -F docs start:agents-lifecycle-hooks
  ```
- `agents-output-types.ts` – Return structured data using a Zod schema.
  ```bash
  pnpm -F docs start:agents-output-types
  ```
- `guardrails-input.ts` – Block unwanted requests using input guardrails.
  ```bash
  pnpm -F docs start:guardrails-input
  ```
- `guardrails-output.ts` – Check responses with output guardrails.
  ```bash
  pnpm -F docs start:guardrails-output
  ```
- `models-custom-providers.ts` – Create and use a custom model provider.
  ```bash
  pnpm -F docs start:models-custom-providers
  ```
- `models-openai-provider.ts` – Run agents with the OpenAI provider.
  ```bash
  pnpm -F docs start:models-openai-provider
  ```
- `quickstart.ts` – Simple triage agent that hands off questions to tutors.
  ```bash
  pnpm -F docs start:quickstart
  ```
- `readme-functions.ts` – README example showing how to call functions as tools.
  ```bash
  pnpm -F docs start:readme-functions
  ```
- `readme-handoffs.ts` – README example that demonstrates handoffs.
  ```bash
  pnpm -F docs start:readme-handoffs
  ```
- `readme-hello-world.ts` – The hello world snippet from the README.
  ```bash
  pnpm -F docs start:readme-hello-world
  ```
- `readme-voice-agent.ts` – Browser-based realtime voice agent example.
  ```bash
  pnpm -F docs start:readme-voice-agent
  ```
- `running-agents-exceptions1.ts` – Retry after a guardrail execution error.
  ```bash
  pnpm -F docs start:running-agents-exceptions1
  ```
- `running-agents-exceptions2.ts` – Retry after a failed tool call.
  ```bash
  pnpm -F docs start:running-agents-exceptions2
  ```



================================================
FILE: examples/docs/custom-trace.ts
================================================
import { Agent, run, withTrace } from '@openai/agents';

const agent = new Agent({
  name: 'Joke generator',
  instructions: 'Tell funny jokes.',
});

await withTrace('Joke workflow', async () => {
  const result = await run(agent, 'Tell me a joke');
  const secondResult = await run(
    agent,
    `Rate this joke: ${result.finalOutput}`,
  );
  console.log(`Joke: ${result.finalOutput}`);
  console.log(`Rating: ${secondResult.finalOutput}`);
});



================================================
FILE: examples/docs/hello-world-with-runner.ts
================================================
import { Agent, Runner } from '@openai/agents';

const agent = new Agent({
  name: 'Assistant',
  instructions: 'You are a helpful assistant',
});

// You can pass custom configuration to the runner
const runner = new Runner();

const result = await runner.run(
  agent,
  'Write a haiku about recursion in programming.',
);
console.log(result.finalOutput);

// Code within the code,
// Functions calling themselves,
// Infinite loop's dance.



================================================
FILE: examples/docs/hello-world.ts
================================================
import { Agent, run } from '@openai/agents';

const agent = new Agent({
  name: 'Assistant',
  instructions: 'You are a helpful assistant',
});

const result = await run(
  agent,
  'Write a haiku about recursion in programming.',
);
console.log(result.finalOutput);

// Code within the code,
// Functions calling themselves,
// Infinite loop's dance.



================================================
FILE: examples/docs/package.json
================================================
{
  "private": true,
  "name": "docs",
  "dependencies": {
    "@openai/agents": "workspace:*",
    "@openai/agents-core": "workspace:*",
    "@openai/agents-realtime": "workspace:*",
    "@openai/agents-extensions": "workspace:*",
    "@ai-sdk/openai": "^1.0.0",
    "server-only": "^0.0.1",
    "openai": "^5.0.1",
    "zod": "~3.25.40"
  },
  "scripts": {
    "build-check": "tsc --noEmit"
  },
  "devDependencies": {
    "typedoc-plugin-zod": "^1.4.1"
  }
}



================================================
FILE: examples/docs/tsconfig.json
================================================
{
  "extends": "../../tsconfig.examples.json",
  "compilerOptions": {
    "noUnusedLocals": false
  }
}



================================================
FILE: examples/docs/agents/agentCloning.ts
================================================
import { Agent } from '@openai/agents';

const pirateAgent = new Agent({
  name: 'Pirate',
  instructions: 'Respond like a pirate – lots of “Arrr!”',
  model: 'o4-mini',
});

const robotAgent = pirateAgent.clone({
  name: 'Robot',
  instructions: 'Respond like a robot – be precise and factual.',
});



================================================
FILE: examples/docs/agents/agentForcingToolUse.ts
================================================
import { Agent, tool } from '@openai/agents';
import { z } from 'zod';

const calculatorTool = tool({
  name: 'Calculator',
  description: 'Use this tool to answer questions about math problems.',
  parameters: z.object({ question: z.string() }),
  execute: async (input) => {
    throw new Error('TODO: implement this');
  },
});

const agent = new Agent({
  name: 'Strict tool user',
  instructions: 'Always answer using the calculator tool.',
  tools: [calculatorTool],
  modelSettings: { toolChoice: 'auto' },
});



================================================
FILE: examples/docs/agents/agentWithAodOutputType.ts
================================================
import { Agent } from '@openai/agents';
import { z } from 'zod';

const CalendarEvent = z.object({
  name: z.string(),
  date: z.string(),
  participants: z.array(z.string()),
});

const extractor = new Agent({
  name: 'Calendar extractor',
  instructions: 'Extract calendar events from the supplied text.',
  outputType: CalendarEvent,
});



================================================
FILE: examples/docs/agents/agentWithContext.ts
================================================
import { Agent } from '@openai/agents';

interface Purchase {
  id: string;
  uid: string;
  deliveryStatus: string;
}
interface UserContext {
  uid: string;
  isProUser: boolean;

  // this function can be used within tools
  fetchPurchases(): Promise<Purchase[]>;
}

const agent = new Agent<UserContext>({
  name: 'Personal shopper',
  instructions: 'Recommend products the user will love.',
});

// Later
import { run } from '@openai/agents';

const result = await run(agent, 'Find me a new pair of running shoes', {
  context: { uid: 'abc', isProUser: true, fetchPurchases: async () => [] },
});



================================================
FILE: examples/docs/agents/agentWithDynamicInstructions.ts
================================================
import { Agent, RunContext } from '@openai/agents';

interface UserContext {
  name: string;
}

function buildInstructions(runContext: RunContext<UserContext>) {
  return `The user's name is ${runContext.context.name}.  Be extra friendly!`;
}

const agent = new Agent<UserContext>({
  name: 'Personalized helper',
  instructions: buildInstructions,
});



================================================
FILE: examples/docs/agents/agentWithHandoffs.ts
================================================
import { Agent } from '@openai/agents';

const bookingAgent = new Agent({
  name: 'Booking Agent',
  instructions: 'Help users with booking requests.',
});

const refundAgent = new Agent({
  name: 'Refund Agent',
  instructions: 'Process refund requests politely and efficiently.',
});

// Use Agent.create method to ensure the finalOutput type considers handoffs
const triageAgent = Agent.create({
  name: 'Triage Agent',
  instructions: [
    'Help the user with their questions.',
    'If the user asks about booking, hand off to the booking agent.',
    'If the user asks about refunds, hand off to the refund agent.',
  ].join('\n'),
  handoffs: [bookingAgent, refundAgent],
});



================================================
FILE: examples/docs/agents/agentWithLifecycleHooks.ts
================================================
import { Agent } from '@openai/agents';

const agent = new Agent({
  name: 'Verbose agent',
  instructions: 'Explain things thoroughly.',
});

agent.on('agent_start', (ctx, agent) => {
  console.log(`[${agent.name}] started`);
});
agent.on('agent_end', (ctx, output) => {
  console.log(`[agent] produced:`, output);
});



================================================
FILE: examples/docs/agents/agentWithTools.ts
================================================
import { Agent, tool } from '@openai/agents';
import { z } from 'zod';

const getWeather = tool({
  name: 'get_weather',
  description: 'Return the weather for a given city.',
  parameters: z.object({ city: z.string() }),
  async execute({ city }) {
    return `The weather in ${city} is sunny.`;
  },
});

const agent = new Agent({
  name: 'Weather bot',
  instructions: 'You are a helpful weather bot.',
  model: 'o4-mini',
  tools: [getWeather],
});



================================================
FILE: examples/docs/agents/simpleAgent.ts
================================================
import { Agent } from '@openai/agents';

const agent = new Agent({
  name: 'Haiku Agent',
  instructions: 'Always respond in haiku form.',
  model: 'o4-mini', // optional – falls back to the default model
});



================================================
FILE: examples/docs/config/getLogger.ts
================================================
import { getLogger } from '@openai/agents';

const logger = getLogger('my-app');
logger.debug('something happened');



================================================
FILE: examples/docs/config/setDefaultOpenAIClient.ts
================================================
import { OpenAI } from 'openai';
import { setDefaultOpenAIClient } from '@openai/agents';

const customClient = new OpenAI({ baseURL: '...', apiKey: '...' });
setDefaultOpenAIClient(customClient);



================================================
FILE: examples/docs/config/setDefaultOpenAIKey.ts
================================================
import { setDefaultOpenAIKey } from '@openai/agents';

setDefaultOpenAIKey(process.env.OPENAI_API_KEY!); // sk-...



================================================
FILE: examples/docs/config/setOpenAIAPI.ts
================================================
import { setOpenAIAPI } from '@openai/agents';

setOpenAIAPI('chat_completions');



================================================
FILE: examples/docs/config/setTracingDisabled.ts
================================================
import { setTracingDisabled } from '@openai/agents';

setTracingDisabled(true);



================================================
FILE: examples/docs/config/setTracingExportApiKey.ts
================================================
import { setTracingExportApiKey } from '@openai/agents';

setTracingExportApiKey('sk-...');



================================================
FILE: examples/docs/context/localContext.ts
================================================
import { Agent, run, RunContext, tool } from '@openai/agents';
import { z } from 'zod';

interface UserInfo {
  name: string;
  uid: number;
}

const fetchUserAge = tool({
  name: 'fetch_user_age',
  description: 'Return the age of the current user',
  parameters: z.object({}),
  execute: async (
    _args,
    runContext?: RunContext<UserInfo>,
  ): Promise<string> => {
    return `User ${runContext?.context.name} is 47 years old`;
  },
});

async function main() {
  const userInfo: UserInfo = { name: 'John', uid: 123 };

  const agent = new Agent<UserInfo>({
    name: 'Assistant',
    tools: [fetchUserAge],
  });

  const result = await run(agent, 'What is the age of the user?', {
    context: userInfo,
  });

  console.log(result.finalOutput);
  // The user John is 47 years old.
}

if (require.main === module) {
  main().catch(console.error);
}



================================================
FILE: examples/docs/extensions/ai-sdk-setup.ts
================================================
import { Agent, run } from '@openai/agents';

// Import the model package you installed
import { openai } from '@ai-sdk/openai';

// Import the adapter
import { aisdk } from '@openai/agents-extensions';

// Create a model instance to be used by the agent
const model = aisdk(openai('o4-mini'));

// Create an agent with the model
const agent = new Agent({
  name: 'My Agent',
  instructions: 'You are a helpful assistant.',
  model,
});

// Run the agent with the new model
run(agent, 'What is the capital of Germany?');



================================================
FILE: examples/docs/extensions/twilio-basic.ts
================================================
import { TwilioRealtimeTransportLayer } from '@openai/agents-extensions';
import { RealtimeAgent, RealtimeSession } from '@openai/agents/realtime';

const agent = new RealtimeAgent({
  name: 'My Agent',
});

// Create a new transport mechanism that will bridge the connection between Twilio and
// the OpenAI Realtime API.
const twilioTransport = new TwilioRealtimeTransportLayer({
  // @ts-expect-error - this is not defined
  twilioWebSocket: websocketConnection,
});

const session = new RealtimeSession(agent, {
  // set your own transport
  transport: twilioTransport,
});



================================================
FILE: examples/docs/guardrails/guardrails-input.ts
================================================
import {
  Agent,
  run,
  InputGuardrailTripwireTriggered,
  InputGuardrail,
} from '@openai/agents';
import { z } from 'zod';

const guardrailAgent = new Agent({
  name: 'Guardrail check',
  instructions: 'Check if the user is asking you to do their math homework.',
  outputType: z.object({
    isMathHomework: z.boolean(),
    reasoning: z.string(),
  }),
});

const mathGuardrail: InputGuardrail = {
  name: 'Math Homework Guardrail',
  execute: async ({ input, context }) => {
    const result = await run(guardrailAgent, input, { context });
    return {
      outputInfo: result.finalOutput,
      tripwireTriggered: result.finalOutput?.isMathHomework ?? false,
    };
  },
};

const agent = new Agent({
  name: 'Customer support agent',
  instructions:
    'You are a customer support agent. You help customers with their questions.',
  inputGuardrails: [mathGuardrail],
});

async function main() {
  try {
    await run(agent, 'Hello, can you help me solve for x: 2x + 3 = 11?');
    console.log("Guardrail didn't trip - this is unexpected");
  } catch (e) {
    if (e instanceof InputGuardrailTripwireTriggered) {
      console.log('Math homework guardrail tripped');
    }
  }
}

main().catch(console.error);



================================================
FILE: examples/docs/guardrails/guardrails-output.ts
================================================
import {
  Agent,
  run,
  OutputGuardrailTripwireTriggered,
  OutputGuardrail,
} from '@openai/agents';
import { z } from 'zod';

// The output by the main agent
const MessageOutput = z.object({ response: z.string() });
type MessageOutput = z.infer<typeof MessageOutput>;

// The output by the math guardrail agent
const MathOutput = z.object({ reasoning: z.string(), isMath: z.boolean() });

// The guardrail agent
const guardrailAgent = new Agent({
  name: 'Guardrail check',
  instructions: 'Check if the output includes any math.',
  outputType: MathOutput,
});

// An output guardrail using an agent internally
const mathGuardrail: OutputGuardrail<typeof MessageOutput> = {
  name: 'Math Guardrail',
  async execute({ agentOutput, context }) {
    const result = await run(guardrailAgent, agentOutput.response, {
      context,
    });
    return {
      outputInfo: result.finalOutput,
      tripwireTriggered: result.finalOutput?.isMath ?? false,
    };
  },
};

const agent = new Agent({
  name: 'Support agent',
  instructions:
    'You are a user support agent. You help users with their questions.',
  outputGuardrails: [mathGuardrail],
  outputType: MessageOutput,
});

async function main() {
  try {
    const input = 'Hello, can you help me solve for x: 2x + 3 = 11?';
    await run(agent, input);
    console.log("Guardrail didn't trip - this is unexpected");
  } catch (e) {
    if (e instanceof OutputGuardrailTripwireTriggered) {
      console.log('Math output guardrail tripped');
    }
  }
}

main().catch(console.error);



================================================
FILE: examples/docs/handoffs/basicUsage.ts
================================================
import { Agent, handoff } from '@openai/agents';

const billingAgent = new Agent({ name: 'Billing agent' });
const refundAgent = new Agent({ name: 'Refund agent' });

// Use Agent.create method to ensure the finalOutput type considers handoffs
const triageAgent = Agent.create({
  name: 'Triage agent',
  handoffs: [billingAgent, handoff(refundAgent)],
});



================================================
FILE: examples/docs/handoffs/customizeHandoff.ts
================================================
import { Agent, handoff, RunContext } from '@openai/agents';

function onHandoff(ctx: RunContext) {
  console.log('Handoff called');
}

const agent = new Agent({ name: 'My agent' });

const handoffObj = handoff(agent, {
  onHandoff,
  toolNameOverride: 'custom_handoff_tool',
  toolDescriptionOverride: 'Custom description',
});



================================================
FILE: examples/docs/handoffs/handoffInput.ts
================================================
import { z } from 'zod';
import { Agent, handoff, RunContext } from '@openai/agents';

const EscalationData = z.object({ reason: z.string() });
type EscalationData = z.infer<typeof EscalationData>;

async function onHandoff(
  ctx: RunContext<EscalationData>,
  input: EscalationData | undefined,
) {
  console.log(`Escalation agent called with reason: ${input?.reason}`);
}

const agent = new Agent<EscalationData>({ name: 'Escalation agent' });

const handoffObj = handoff(agent, {
  onHandoff,
  inputType: EscalationData,
});



================================================
FILE: examples/docs/handoffs/inputFilter.ts
================================================
import { Agent, handoff } from '@openai/agents';
import { removeAllTools } from '@openai/agents-core/extensions';

const agent = new Agent({ name: 'FAQ agent' });

const handoffObj = handoff(agent, {
  inputFilter: removeAllTools,
});



================================================
FILE: examples/docs/handoffs/recommendedPrompt.ts
================================================
import { Agent } from '@openai/agents';
import { RECOMMENDED_PROMPT_PREFIX } from '@openai/agents-core/extensions';

const billingAgent = new Agent({
  name: 'Billing agent',
  instructions: `${RECOMMENDED_PROMPT_PREFIX}
Fill in the rest of your prompt here.`,
});



================================================
FILE: examples/docs/human-in-the-loop/index.ts
================================================
import { z } from 'zod';
import readline from 'node:readline/promises';
import fs from 'node:fs/promises';
import { Agent, run, tool, RunState, RunResult } from '@openai/agents';

const getWeatherTool = tool({
  name: 'get_weather',
  description: 'Get the weather for a given city',
  parameters: z.object({
    location: z.string(),
  }),
  needsApproval: async (_context, { location }) => {
    // forces approval to look up the weather in San Francisco
    return location === 'San Francisco';
  },
  execute: async ({ location }) => {
    return `The weather in ${location} is sunny`;
  },
});

const dataAgentTwo = new Agent({
  name: 'Data agent',
  instructions: 'You are a data agent',
  handoffDescription: 'You know everything about the weather',
  tools: [getWeatherTool],
});

const agent = new Agent({
  name: 'Basic test agent',
  instructions: 'You are a basic agent',
  handoffs: [dataAgentTwo],
});

async function confirm(question: string) {
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
  });

  const answer = await rl.question(`${question} (y/n): `);
  const normalizedAnswer = answer.toLowerCase();
  rl.close();
  return normalizedAnswer === 'y' || normalizedAnswer === 'yes';
}

async function main() {
  let result: RunResult<unknown, Agent<unknown, any>> = await run(
    agent,
    'What is the weather in Oakland and San Francisco?',
  );
  let hasInterruptions = result.interruptions?.length > 0;
  while (hasInterruptions) {
    // storing
    await fs.writeFile(
      'result.json',
      JSON.stringify(result.state, null, 2),
      'utf-8',
    );

    // from here on you could run things on a different thread/process

    // reading later on
    const storedState = await fs.readFile('result.json', 'utf-8');
    const state = await RunState.fromString(agent, storedState);

    for (const interruption of result.interruptions) {
      const confirmed = await confirm(
        `Agent ${interruption.agent.name} would like to use the tool ${interruption.rawItem.name} with "${interruption.rawItem.arguments}". Do you approve?`,
      );

      if (confirmed) {
        state.approve(interruption);
      } else {
        state.reject(interruption);
      }
    }

    // resume execution of the current state
    result = await run(agent, state);
    hasInterruptions = result.interruptions?.length > 0;
  }

  console.log(result.finalOutput);
}

main().catch((error) => {
  console.dir(error, { depth: null });
});



================================================
FILE: examples/docs/human-in-the-loop/toolApprovalDefinition.ts
================================================
import { tool } from '@openai/agents';
import z from 'zod';

const sensitiveTool = tool({
  name: 'cancelOrder',
  description: 'Cancel order',
  parameters: z.object({
    orderId: z.number(),
  }),
  // always requires approval
  needsApproval: true,
  execute: async ({ orderId }, args) => {
    // prepare order return
  },
});

const sendEmail = tool({
  name: 'sendEmail',
  description: 'Send an email',
  parameters: z.object({
    to: z.string(),
    subject: z.string(),
    body: z.string(),
  }),
  needsApproval: async (_context, { subject }) => {
    // check if the email is spam
    return subject.includes('spam');
  },
  execute: async ({ to, subject, body }, args) => {
    // send email
  },
});



================================================
FILE: examples/docs/mcp/hosted.ts
================================================
import { run } from '@openai/agents';
import { agent } from './hostedAgent';

async function main() {
  const result = await run(
    agent,
    'Which language is the repo I pointed in the MCP tool settings written in?',
  );
  console.log(result.finalOutput);
}

main().catch(console.error);



================================================
FILE: examples/docs/mcp/hostedAgent.ts
================================================
import { Agent, hostedMcpTool } from '@openai/agents';

export const agent = new Agent({
  name: 'MCP Assistant',
  instructions: 'You must always use the MCP tools to answer questions.',
  tools: [
    hostedMcpTool({
      serverLabel: 'gitmcp',
      serverUrl: 'https://gitmcp.io/openai/codex',
    }),
  ],
});



================================================
FILE: examples/docs/mcp/hostedHITL.ts
================================================
import { Agent, run, hostedMcpTool, RunToolApprovalItem } from '@openai/agents';

async function main(): Promise<void> {
  const agent = new Agent({
    name: 'MCP Assistant',
    instructions: 'You must always use the MCP tools to answer questions.',
    tools: [
      hostedMcpTool({
        serverLabel: 'gitmcp',
        serverUrl: 'https://gitmcp.io/openai/codex',
        // 'always' | 'never' | { never, always }
        requireApproval: {
          never: {
            toolNames: ['search_codex_code', 'fetch_codex_documentation'],
          },
          always: {
            toolNames: ['fetch_generic_url_content'],
          },
        },
      }),
    ],
  });

  let result = await run(agent, 'Which language is this repo written in?');
  while (result.interruptions && result.interruptions.length) {
    for (const interruption of result.interruptions) {
      // Human in the loop here
      const approval = await confirm(interruption);
      if (approval) {
        result.state.approve(interruption);
      } else {
        result.state.reject(interruption);
      }
    }
    result = await run(agent, result.state);
  }
  console.log(result.finalOutput);
}

import { stdin, stdout } from 'node:process';
import * as readline from 'node:readline/promises';

async function confirm(item: RunToolApprovalItem): Promise<boolean> {
  const rl = readline.createInterface({ input: stdin, output: stdout });
  const name = item.rawItem.name;
  const params = item.rawItem.providerData?.arguments;
  const answer = await rl.question(
    `Approve running tool (mcp: ${name}, params: ${params})? (y/n) `,
  );
  rl.close();
  return answer.toLowerCase().trim() === 'y';
}

main().catch(console.error);



================================================
FILE: examples/docs/mcp/hostedStream.ts
================================================
import { run } from '@openai/agents';
import { agent } from './hostedAgent';

async function main() {
  const result = await run(
    agent,
    'Which language is the repo I pointed in the MCP tool settings written in?',
    { stream: true },
  );

  for await (const event of result) {
    if (
      event.type === 'raw_model_stream_event' &&
      event.data.type === 'model' &&
      event.data.event.type !== 'response.mcp_call_arguments.delta' &&
      event.data.event.type !== 'response.output_text.delta'
    ) {
      console.log(`Got event of type ${JSON.stringify(event.data)}`);
    }
  }
  console.log(`Done streaming; final result: ${result.finalOutput}`);
}

main().catch(console.error);



================================================
FILE: examples/docs/mcp/stdio.ts
================================================
import { Agent, run, MCPServerStdio } from '@openai/agents';
import * as path from 'node:path';

async function main() {
  const samplesDir = path.join(__dirname, 'sample_files');
  const mcpServer = new MCPServerStdio({
    name: 'Filesystem MCP Server, via npx',
    fullCommand: `npx -y @modelcontextprotocol/server-filesystem ${samplesDir}`,
  });
  await mcpServer.connect();
  try {
    const agent = new Agent({
      name: 'FS MCP Assistant',
      instructions:
        'Use the tools to read the filesystem and answer questions based on those files. If you are unable to find any files, you can say so instead of assuming they exist.',
      mcpServers: [mcpServer],
    });
    const result = await run(agent, 'Read the files and list them.');
    console.log(result.finalOutput);
  } finally {
    await mcpServer.close();
  }
}

main().catch(console.error);



================================================
FILE: examples/docs/mcp/streamableHttp.ts
================================================
import { Agent, run, MCPServerStreamableHttp } from '@openai/agents';

async function main() {
  const mcpServer = new MCPServerStreamableHttp({
    url: 'https://gitmcp.io/openai/codex',
    name: 'GitMCP Documentation Server',
  });
  const agent = new Agent({
    name: 'GitMCP Assistant',
    instructions: 'Use the tools to respond to user requests.',
    mcpServers: [mcpServer],
  });

  try {
    await mcpServer.connect();
    const result = await run(agent, 'Which language is this repo written in?');
    console.log(result.finalOutput);
  } finally {
    await mcpServer.close();
  }
}

main().catch(console.error);



================================================
FILE: examples/docs/models/agentWithModel.ts
================================================
import { Agent } from '@openai/agents';

const agent = new Agent({
  name: 'Creative writer',
  model: 'gpt-4.1',
});



================================================
FILE: examples/docs/models/customProviders.ts
================================================
import {
  ModelProvider,
  Model,
  ModelRequest,
  ModelResponse,
  ResponseStreamEvent,
} from '@openai/agents-core';

import { Agent, Runner } from '@openai/agents';

class EchoModel implements Model {
  name: string;
  constructor() {
    this.name = 'Echo';
  }
  async getResponse(request: ModelRequest): Promise<ModelResponse> {
    return {
      usage: {},
      output: [{ role: 'assistant', content: request.input as string }],
    } as any;
  }
  async *getStreamedResponse(
    _request: ModelRequest,
  ): AsyncIterable<ResponseStreamEvent> {
    yield {
      type: 'response.completed',
      response: { output: [], usage: {} },
    } as any;
  }
}

class EchoProvider implements ModelProvider {
  getModel(_modelName?: string): Promise<Model> | Model {
    return new EchoModel();
  }
}

const runner = new Runner({ modelProvider: new EchoProvider() });
console.log(runner.config.modelProvider.getModel());
const agent = new Agent({
  name: 'Test Agent',
  instructions: 'You are a helpful assistant.',
  model: new EchoModel(),
  modelSettings: { temperature: 0.7, toolChoice: 'auto' },
});
console.log(agent.model);



================================================
FILE: examples/docs/models/modelSettings.ts
================================================
import { Runner, Agent } from '@openai/agents';

const agent = new Agent({
  name: 'Creative writer',
  // ...
  modelSettings: { temperature: 0.7, toolChoice: 'auto' },
});

// or globally
new Runner({ modelSettings: { temperature: 0.3 } });



================================================
FILE: examples/docs/models/openaiProvider.ts
================================================
import {
  Agent,
  Runner,
  setDefaultOpenAIKey,
  setDefaultOpenAIClient,
  setTracingExportApiKey,
} from '@openai/agents';
import { OpenAI } from 'openai';

setDefaultOpenAIKey(process.env.OPENAI_API_KEY!);

setDefaultOpenAIClient(new OpenAI({ apiKey: process.env.OPENAI_API_KEY! }));

const runner = new Runner({ model: 'gpt‑4o-mini' });
const agent = new Agent({
  name: 'Test Agent',
  instructions: 'You are a helpful assistant.',
  modelSettings: { temperature: 0.7, toolChoice: 'auto' },
});

async function main() {
  const result = await runner.run(agent, 'Hey, I need your help!');
  console.log(result.finalOutput);
}

if (require.main === module) {
  main().catch((err) => {
    console.error(err);
    process.exit(1);
  });
}

setTracingExportApiKey(process.env.OPENAI_API_KEY!);



================================================
FILE: examples/docs/models/runnerWithModel.ts
================================================
import { Runner } from '@openai/agents';

const runner = new Runner({ model: 'gpt‑4.1-mini' });



================================================
FILE: examples/docs/quickstart/index.ts
================================================
import { Agent, run } from '@openai/agents';

const historyTutorAgent = new Agent({
  name: 'History Tutor',
  instructions:
    'You provide assistance with historical queries. Explain important events and context clearly.',
});

const mathTutorAgent = new Agent({
  name: 'Math Tutor',
  instructions:
    'You provide help with math problems. Explain your reasoning at each step and include examples',
});

const triageAgent = new Agent({
  name: 'Triage Agent',
  instructions:
    "You determine which agent to use based on the user's homework question",
  handoffs: [historyTutorAgent, mathTutorAgent],
});

async function main() {
  const result = await run(triageAgent, 'What is the capital of France?');
  console.log(result.finalOutput);
}

main().catch((err) => console.error(err));



================================================
FILE: examples/docs/readme/readme-functions.ts
================================================
import { z } from 'zod';
import { Agent, run, tool } from '@openai/agents';

const getWeatherTool = tool({
  name: 'get_weather',
  description: 'Get the weather for a given city',
  parameters: z.object({ city: z.string() }),
  execute: async (input) => {
    return `The weather in ${input.city} is sunny`;
  },
});

const agent = new Agent({
  name: 'Data agent',
  instructions: 'You are a data agent',
  tools: [getWeatherTool],
});

async function main() {
  const result = await run(agent, 'What is the weather in Tokyo?');
  console.log(result.finalOutput);
}

main().catch(console.error);



================================================
FILE: examples/docs/readme/readme-handoffs.ts
================================================
import { z } from 'zod';
import { Agent, run, tool } from '@openai/agents';

const getWeatherTool = tool({
  name: 'get_weather',
  description: 'Get the weather for a given city',
  parameters: z.object({ city: z.string() }),
  execute: async (input) => {
    return `The weather in ${input.city} is sunny`;
  },
});

const dataAgent = new Agent({
  name: 'Data agent',
  instructions: 'You are a data agent',
  handoffDescription: 'You know everything about the weather',
  tools: [getWeatherTool],
});

// Use Agent.create method to ensure the finalOutput type considers handoffs
const agent = Agent.create({
  name: 'Basic test agent',
  instructions: 'You are a basic agent',
  handoffs: [dataAgent],
});

async function main() {
  const result = await run(agent, 'What is the weather in San Francisco?');
  console.log(result.finalOutput);
}

main().catch(console.error);



================================================
FILE: examples/docs/readme/readme-hello-world.ts
================================================
import { Agent, run } from '@openai/agents';

async function main() {
  const agent = new Agent({
    name: 'Assistant',
    instructions: 'You are a helpful assistant',
  });
  const result = await run(
    agent,
    'Write a haiku about recursion in programming.',
  );
  console.log(result.finalOutput);
  // Code within the code,
  // Functions calling themselves,
  // Infinite loop's dance.
}

main().catch(console.error);



================================================
FILE: examples/docs/readme/readme-voice-agent.ts
================================================
import { z } from 'zod';
import { RealtimeAgent, RealtimeSession, tool } from '@openai/agents-realtime';

const getWeatherTool = tool({
  name: 'get_weather',
  description: 'Get the weather for a given city',
  parameters: z.object({ city: z.string() }),
  execute: async (input) => {
    return `The weather in ${input.city} is sunny`;
  },
});

const agent = new RealtimeAgent({
  name: 'Data agent',
  instructions: 'You are a data agent',
  tools: [getWeatherTool],
});

async function main() {
  // Intended to be run the browser
  const { apiKey } = await fetch('/path/to/ephemerial/key/generation').then(
    (resp) => resp.json(),
  );
  // automatically configures audio input/output so start talking
  const session = new RealtimeSession(agent);
  await session.connect({ apiKey });
}

main().catch(console.error);



================================================
FILE: examples/docs/results/handoffFinalOutputTypes.ts
================================================
import { Agent, run } from '@openai/agents';
import { z } from 'zod';

const refundAgent = new Agent({
  name: 'Refund Agent',
  instructions:
    'You are a refund agent. You are responsible for refunding customers.',
  outputType: z.object({
    refundApproved: z.boolean(),
  }),
});

const orderAgent = new Agent({
  name: 'Order Agent',
  instructions:
    'You are an order agent. You are responsible for processing orders.',
  outputType: z.object({
    orderId: z.string(),
  }),
});

const triageAgent = Agent.create({
  name: 'Triage Agent',
  instructions:
    'You are a triage agent. You are responsible for triaging customer issues.',
  handoffs: [refundAgent, orderAgent],
});

const result = await run(triageAgent, 'I need to a refund for my order');

const output = result.finalOutput;
// ^? { refundApproved: boolean } | { orderId: string } | string | undefined



================================================
FILE: examples/docs/results/historyLoop.ts
================================================
import { AgentInputItem, Agent, user, run } from '@openai/agents';

const agent = new Agent({
  name: 'Assistant',
  instructions:
    'You are a helpful assistant knowledgeable about recent AGI research.',
});

let history: AgentInputItem[] = [
  // intial message
  user('Are we there yet?'),
];

for (let i = 0; i < 10; i++) {
  // run 10 times
  const result = await run(agent, history);

  // update the history to the new output
  history = result.history;

  history.push(user('How about now?'));
}



================================================
FILE: examples/docs/running-agents/chatLoop.ts
================================================
import { Agent, AgentInputItem, run } from '@openai/agents';

let thread: AgentInputItem[] = [];

const agent = new Agent({
  name: 'Assistant',
});

async function userSays(text: string) {
  const result = await run(
    agent,
    thread.concat({ role: 'user', content: text }),
  );

  thread = result.history; // Carry over history + newly generated items
  return result.finalOutput;
}

await userSays('What city is the Golden Gate Bridge in?');
// -> "San Francisco"

await userSays('What state is it in?');
// -> "California"



================================================
FILE: examples/docs/running-agents/exceptions1.ts
================================================
import {
  Agent,
  run,
  GuardrailExecutionError,
  InputGuardrail,
  InputGuardrailTripwireTriggered,
} from '@openai/agents';
import { z } from 'zod';

const guardrailAgent = new Agent({
  name: 'Guardrail check',
  instructions: 'Check if the user is asking you to do their math homework.',
  outputType: z.object({
    isMathHomework: z.boolean(),
    reasoning: z.string(),
  }),
});

const unstableGuardrail: InputGuardrail = {
  name: 'Math Homework Guardrail (unstable)',
  execute: async () => {
    throw new Error('Something is wrong!');
  },
};

const fallbackGuardrail: InputGuardrail = {
  name: 'Math Homework Guardrail (fallback)',
  execute: async ({ input, context }) => {
    const result = await run(guardrailAgent, input, { context });
    return {
      outputInfo: result.finalOutput,
      tripwireTriggered: result.finalOutput?.isMathHomework ?? false,
    };
  },
};

const agent = new Agent({
  name: 'Customer support agent',
  instructions:
    'You are a customer support agent. You help customers with their questions.',
  inputGuardrails: [unstableGuardrail],
});

async function main() {
  try {
    const input = 'Hello, can you help me solve for x: 2x + 3 = 11?';
    const result = await run(agent, input);
    console.log(result.finalOutput);
  } catch (e) {
    if (e instanceof GuardrailExecutionError) {
      console.error(`Guardrail execution failed: ${e}`);
      // If you want to retry the execution with different settings,
      // you can reuse the runner's latest state this way:
      if (e.state) {
        try {
          agent.inputGuardrails = [fallbackGuardrail]; // fallback
          const result = await run(agent, e.state);
          console.log(result.finalOutput);
        } catch (ee) {
          if (ee instanceof InputGuardrailTripwireTriggered) {
            console.log('Math homework guardrail tripped');
          }
        }
      }
    } else {
      throw e;
    }
  }
}

main().catch(console.error);



================================================
FILE: examples/docs/running-agents/exceptions2.ts
================================================
import { z } from 'zod';
import { Agent, run, tool, ToolCallError } from '@openai/agents';

const unstableTool = tool({
  name: 'get_weather (unstable)',
  description: 'Get the weather for a given city',
  parameters: z.object({ city: z.string() }),
  errorFunction: (_, error) => {
    throw error; // the built-in error handler returns string instead
  },
  execute: async () => {
    throw new Error('Failed to get weather');
  },
});

const stableTool = tool({
  name: 'get_weather (stable)',
  description: 'Get the weather for a given city',
  parameters: z.object({ city: z.string() }),
  execute: async (input) => {
    return `The weather in ${input.city} is sunny`;
  },
});

const agent = new Agent({
  name: 'Data agent',
  instructions: 'You are a data agent',
  tools: [unstableTool],
});

async function main() {
  try {
    const result = await run(agent, 'What is the weather in Tokyo?');
    console.log(result.finalOutput);
  } catch (e) {
    if (e instanceof ToolCallError) {
      console.error(`Tool call failed: ${e}`);
      // If you want to retry the execution with different settings,
      // you can reuse the runner's latest state this way:
      if (e.state) {
        agent.tools = [stableTool]; // fallback
        const result = await run(agent, e.state);
        console.log(result.finalOutput);
      }
    } else {
      throw e;
    }
  }
}

main().catch(console.error);



================================================
FILE: examples/docs/streaming/basicStreaming.ts
================================================
import { Agent, run } from '@openai/agents';

const agent = new Agent({
  name: 'Storyteller',
  instructions:
    'You are a storyteller. You will be given a topic and you will tell a story about it.',
});

const result = await run(agent, 'Tell me a story about a cat.', {
  stream: true,
});



================================================
FILE: examples/docs/streaming/handleAllEvents.ts
================================================
import { Agent, run } from '@openai/agents';

const agent = new Agent({
  name: 'Storyteller',
  instructions:
    'You are a storyteller. You will be given a topic and you will tell a story about it.',
});

const result = await run(agent, 'Tell me a story about a cat.', {
  stream: true,
});

for await (const event of result) {
  // these are the raw events from the model
  if (event.type === 'raw_model_stream_event') {
    console.log(`${event.type} %o`, event.data);
  }
  // agent updated events
  if (event.type == 'agent_updated_stream_event') {
    console.log(`${event.type} %s`, event.agent.name);
  }
  // Agent SDK specific events
  if (event.type === 'run_item_stream_event') {
    console.log(`${event.type} %o`, event.item);
  }
}



================================================
FILE: examples/docs/streaming/nodeTextStream.ts
================================================
import { Agent, run } from '@openai/agents';

const agent = new Agent({
  name: 'Storyteller',
  instructions:
    'You are a storyteller. You will be given a topic and you will tell a story about it.',
});

const result = await run(agent, 'Tell me a story about a cat.', {
  stream: true,
});

result
  .toTextStream({
    compatibleWithNodeStreams: true,
  })
  .pipe(process.stdout);



================================================
FILE: examples/docs/streaming/streamedHITL.ts
================================================
import { Agent, run } from '@openai/agents';

const agent = new Agent({
  name: 'Storyteller',
  instructions:
    'You are a storyteller. You will be given a topic and you will tell a story about it.',
});

let stream = await run(
  agent,
  'What is the weather in San Francisco and Oakland?',
  { stream: true },
);
stream.toTextStream({ compatibleWithNodeStreams: true }).pipe(process.stdout);
await stream.completed;

while (stream.interruptions?.length) {
  console.log(
    'Human-in-the-loop: approval required for the following tool calls:',
  );
  const state = stream.state;
  for (const interruption of stream.interruptions) {
    const approved = confirm(
      `Agent ${interruption.agent.name} would like to use the tool ${interruption.rawItem.name} with "${interruption.rawItem.arguments}". Do you approve?`,
    );
    if (approved) {
      state.approve(interruption);
    } else {
      state.reject(interruption);
    }
  }

  // Resume execution with streaming output
  stream = await run(agent, state, { stream: true });
  const textStream = stream.toTextStream({ compatibleWithNodeStreams: true });
  textStream.pipe(process.stdout);
  await stream.completed;
}



================================================
FILE: examples/docs/tools/agentsAsTools.ts
================================================
import { Agent } from '@openai/agents';

const summarizer = new Agent({
  name: 'Summarizer',
  instructions: 'Generate a concise summary of the supplied text.',
});

const summarizerTool = summarizer.asTool({
  toolName: 'summarize_text',
  toolDescription: 'Generate a concise summary of the supplied text.',
});

const mainAgent = new Agent({
  name: 'Research assistant',
  tools: [summarizerTool],
});



================================================
FILE: examples/docs/tools/functionTools.ts
================================================
import { tool } from '@openai/agents';
import { z } from 'zod';

const getWeatherTool = tool({
  name: 'get_weather',
  description: 'Get the weather for a given city',
  parameters: z.object({ city: z.string() }),
  async execute({ city }) {
    return `The weather in ${city} is sunny.`;
  },
});



================================================
FILE: examples/docs/tools/hostedTools.ts
================================================
import { Agent, webSearchTool, fileSearchTool } from '@openai/agents';

const agent = new Agent({
  name: 'Travel assistant',
  tools: [webSearchTool(), fileSearchTool('VS_ID')],
});



================================================
FILE: examples/docs/tools/mcpLocalServer.ts
================================================
import { Agent, MCPServerStdio } from '@openai/agents';

const server = new MCPServerStdio({
  fullCommand: 'npx -y @modelcontextprotocol/server-filesystem ./sample_files',
});

await server.connect();

const agent = new Agent({
  name: 'Assistant',
  mcpServers: [server],
});



================================================
FILE: examples/docs/tools/nonStrictSchemaTools.ts
================================================
import { tool } from '@openai/agents';

interface LooseToolInput {
  text: string;
}

const looseTool = tool({
  description: 'Echo input; be forgiving about typos',
  strict: false,
  parameters: {
    type: 'object',
    properties: { text: { type: 'string' } },
    required: ['text'],
    additionalProperties: true,
  },
  execute: async (input) => {
    // because strict is false we need to do our own verification
    if (typeof input !== 'object' || input === null || !('text' in input)) {
      return 'Invalid input. Please try again';
    }
    return (input as LooseToolInput).text;
  },
});



================================================
FILE: examples/docs/toppage/textAgent.ts
================================================
import { Agent, run } from '@openai/agents';

const agent = new Agent({
  name: 'Assistant',
  instructions: 'You are a helpful assistant.',
});

const result = await run(
  agent,
  'Write a haiku about recursion in programming.',
);

console.log(result.finalOutput);



================================================
FILE: examples/docs/toppage/voiceAgent.ts
================================================
import { RealtimeAgent, RealtimeSession } from '@openai/agents/realtime';

const agent = new RealtimeAgent({
  name: 'Assistant',
  instructions: 'You are a helpful assistant.',
});

// Automatically connects your microphone and audio output in the browser via WebRTC.
const session = new RealtimeSession(agent);
await session.connect({
  apiKey: '<client-api-key>',
});



================================================
FILE: examples/docs/tracing/cloudflareWorkers.ts
================================================
import { getGlobalTraceProvider } from '@openai/agents';

export default {
  // @ts-expect-error - Cloudflare Workers types are not typed
  async fetch(request, env, ctx): Promise<Response> {
    try {
      // your agent code here
      return new Response(`success`);
    } catch (error) {
      console.error(error);
      return new Response(String(error), { status: 500 });
    } finally {
      // make sure to flush any remaining traces before exiting
      ctx.waitUntil(getGlobalTraceProvider().forceFlush());
    }
  },
};



================================================
FILE: examples/docs/voice-agents/agent.ts
================================================
import { RealtimeAgent, RealtimeSession } from '@openai/agents/realtime';

export const agent = new RealtimeAgent({
  name: 'Assistant',
});

export const session = new RealtimeSession(agent, {
  model: 'gpt-4o-realtime-preview-2025-06-03',
});



================================================
FILE: examples/docs/voice-agents/audioInterrupted.ts
================================================
import { session } from './agent';

session.on('audio_interrupted', () => {
  // handle local playback interruption
});



================================================
FILE: examples/docs/voice-agents/configureSession.ts
================================================
import { RealtimeAgent, RealtimeSession } from '@openai/agents/realtime';

const agent = new RealtimeAgent({
  name: 'Greeter',
  instructions: 'Greet the user with cheer and answer questions.',
});

const session = new RealtimeSession(agent, {
  model: 'gpt-4o-realtime-preview-2025-06-03',
  config: {
    inputAudioFormat: 'pcm16',
    outputAudioFormat: 'pcm16',
    inputAudioTranscription: {
      model: 'gpt-4o-mini-transcribe',
    },
  },
});



================================================
FILE: examples/docs/voice-agents/createAgent.ts
================================================
import { RealtimeAgent } from '@openai/agents/realtime';

const agent = new RealtimeAgent({
  name: 'Greeter',
  instructions: 'Greet the user with cheer and answer questions.',
});



================================================
FILE: examples/docs/voice-agents/createSession.ts
================================================
import { RealtimeAgent, RealtimeSession } from '@openai/agents/realtime';

const agent = new RealtimeAgent({
  name: 'Greeter',
  instructions: 'Greet the user with cheer and answer questions.',
});

async function main() {
  // define which agent you want to start your session with
  const session = new RealtimeSession(agent, {
    model: 'gpt-4o-realtime-preview-2025-06-03',
  });
  // start your session
  await session.connect({ apiKey: '<your api key>' });
}



================================================
FILE: examples/docs/voice-agents/customWebRTCTransport.ts
================================================
import { RealtimeAgent, RealtimeSession, OpenAIRealtimeWebRTC } from '@openai/agents/realtime';

const agent = new RealtimeAgent({
  name: 'Greeter',
  instructions: 'Greet the user with cheer and answer questions.',
});

async function main() {
  const transport = new OpenAIRealtimeWebRTC({
    mediaStream: await navigator.mediaDevices.getUserMedia({ audio: true }),
    audioElement: document.createElement('audio'),
  });

  const customSession = new RealtimeSession(agent, { transport });
}



================================================
FILE: examples/docs/voice-agents/defineTool.ts
================================================
import { tool, RealtimeAgent } from '@openai/agents/realtime';
import { z } from 'zod';

const getWeather = tool({
  name: 'get_weather',
  description: 'Return the weather for a city.',
  parameters: z.object({ city: z.string() }),
  async execute({ city }) {
    return `The weather in ${city} is sunny.`;
  },
});

const weatherAgent = new RealtimeAgent({
  name: 'Weather assistant',
  instructions: 'Answer weather questions.',
  tools: [getWeather],
});



================================================
FILE: examples/docs/voice-agents/delegationAgent.ts
================================================
import {
  RealtimeAgent,
  RealtimeContextData,
  tool,
} from '@openai/agents/realtime';
import { handleRefundRequest } from './serverAgent';
import z from 'zod';

const refundSupervisorParameters = z.object({
  request: z.string(),
});

const refundSupervisor = tool<
  typeof refundSupervisorParameters,
  RealtimeContextData
>({
  name: 'escalateToRefundSupervisor',
  description: 'Escalate a refund request to the refund supervisor',
  parameters: refundSupervisorParameters,
  execute: async ({ request }, details) => {
    // This will execute on the server
    return handleRefundRequest(request, details?.context?.history ?? []);
  },
});

const agent = new RealtimeAgent({
  name: 'Customer Support',
  instructions:
    'You are a customer support agent. If you receive any requests for refunds, you need to delegate to your supervisor.',
  tools: [refundSupervisor],
});



================================================
FILE: examples/docs/voice-agents/guardrails.ts
================================================
import { RealtimeOutputGuardrail, RealtimeAgent, RealtimeSession } from '@openai/agents/realtime';

const agent = new RealtimeAgent({
  name: 'Greeter',
  instructions: 'Greet the user with cheer and answer questions.',
});

const guardrails: RealtimeOutputGuardrail[] = [
  {
    name: 'No mention of Dom',
    async execute({ agentOutput }) {
      const domInOutput = agentOutput.includes('Dom');
      return {
        tripwireTriggered: domInOutput,
        outputInfo: { domInOutput },
      };
    },
  },
];

const guardedSession = new RealtimeSession(agent, {
  outputGuardrails: guardrails,
});



================================================
FILE: examples/docs/voice-agents/guardrailSettings.ts
================================================
import { RealtimeAgent, RealtimeSession } from '@openai/agents/realtime';

const agent = new RealtimeAgent({
  name: 'Greeter',
  instructions: 'Greet the user with cheer and answer questions.',
});

const guardedSession = new RealtimeSession(agent, {
  outputGuardrails: [
    /*...*/
  ],
  outputGuardrailSettings: {
    debounceTextLength: 500, // run guardrail every 500 characters or set it to -1 to run it only at the end
  },
});



================================================
FILE: examples/docs/voice-agents/handleAudio.ts
================================================
import {
  RealtimeAgent,
  RealtimeSession,
  TransportLayerAudio,
} from '@openai/agents/realtime';

const agent = new RealtimeAgent({ name: 'My agent' });
const session = new RealtimeSession(agent);
const newlyRecordedAudio = new ArrayBuffer(0);

session.on('audio', (event: TransportLayerAudio) => {
  // play your audio
});

// send new audio to the agent
session.sendAudio(newlyRecordedAudio);



================================================
FILE: examples/docs/voice-agents/helloWorld.ts
================================================
import { RealtimeAgent, RealtimeSession } from '@openai/agents/realtime';

const agent = new RealtimeAgent({
  name: 'Assistant',
  instructions: 'You are a helpful assistant.',
});

const session = new RealtimeSession(agent);

// Automatically connects your microphone and audio output
// in the browser via WebRTC.
await session.connect({
  apiKey: '<client-api-key>',
});



================================================
FILE: examples/docs/voice-agents/historyUpdated.ts
================================================
import { session } from './agent';

session.on('history_updated', (newHistory) => {
  // save the new history
});



================================================
FILE: examples/docs/voice-agents/multiAgents.ts
================================================
import { RealtimeAgent } from '@openai/agents/realtime';

const mathTutorAgent = new RealtimeAgent({
  name: 'Math Tutor',
  handoffDescription: 'Specialist agent for math questions',
  instructions:
    'You provide help with math problems. Explain your reasoning at each step and include examples',
});

const agent = new RealtimeAgent({
  name: 'Greeter',
  instructions: 'Greet the user with cheer and answer questions.',
  handoffs: [mathTutorAgent],
});



================================================
FILE: examples/docs/voice-agents/sendMessage.ts
================================================
import { RealtimeSession, RealtimeAgent } from '@openai/agents/realtime';

const agent = new RealtimeAgent({
  name: 'Assistant',
});

const session = new RealtimeSession(agent, {
  model: 'gpt-4o-realtime-preview-2025-06-03',
});

session.sendMessage('Hello, how are you?');



================================================
FILE: examples/docs/voice-agents/serverAgent.ts
================================================
// This runs on the server
import 'server-only';

import { Agent, run } from '@openai/agents';
import type { RealtimeItem } from '@openai/agents/realtime';
import z from 'zod';

const agent = new Agent({
  name: 'Refund Expert',
  instructions:
    'You are a refund expert. You are given a request to process a refund and you need to determine if the request is valid.',
  model: 'o4-mini',
  outputType: z.object({
    reasong: z.string(),
    refundApproved: z.boolean(),
  }),
});

export async function handleRefundRequest(
  request: string,
  history: RealtimeItem[],
) {
  const input = `
The user has requested a refund.

The request is: ${request}

Current conversation history: 
${JSON.stringify(history, null, 2)}
`.trim();

  const result = await run(agent, input);

  return JSON.stringify(result.finalOutput, null, 2);
}



================================================
FILE: examples/docs/voice-agents/sessionHistory.ts
================================================
import { session } from './agent';

console.log(session.history);



================================================
FILE: examples/docs/voice-agents/sessionInterrupt.ts
================================================
import { session } from './agent';

session.interrupt();
// this will still trigger the `audio_interrupted` event for you
// to cut off the audio playback when using WebSockets



================================================
FILE: examples/docs/voice-agents/thinClient.ts
================================================
import { OpenAIRealtimeWebRTC } from '@openai/agents/realtime';

const client = new OpenAIRealtimeWebRTC();
const audioBuffer = new ArrayBuffer(0);

await client.connect({
  apiKey: '<api key>',
  model: 'gpt-4o-mini-realtime-preview',
  initialSessionConfig: {
    instructions: 'Speak like a pirate',
    voice: 'ash',
    modalities: ['text', 'audio'],
    inputAudioFormat: 'pcm16',
    outputAudioFormat: 'pcm16',
  },
});

// optionally for WebSockets
client.on('audio', (newAudio) => {});

client.sendAudio(audioBuffer);



================================================
FILE: examples/docs/voice-agents/toolApprovalEvent.ts
================================================
import { session } from './agent';

session.on('tool_approval_requested', (_context, _agent, request) => {
  // show a UI to the user to approve or reject the tool call
  // you can use the `session.approve(...)` or `session.reject(...)` methods to approve or reject the tool call

  session.approve(request.approvalItem); // or session.reject(request.rawItem);
});



================================================
FILE: examples/docs/voice-agents/toolHistory.ts
================================================
import {
  tool,
  RealtimeContextData,
  RealtimeItem,
} from '@openai/agents/realtime';
import { z } from 'zod';

const parameters = z.object({
  request: z.string(),
});

const refundTool = tool<typeof parameters, RealtimeContextData>({
  name: 'Refund Expert',
  description: 'Evaluate a refund',
  parameters,
  execute: async ({ request }, details) => {
    // The history might not be available
    const history: RealtimeItem[] = details?.context?.history ?? [];
    // making your call to process the refund request
  },
});



================================================
FILE: examples/docs/voice-agents/transportEvents.ts
================================================
import { RealtimeAgent, RealtimeSession } from '@openai/agents/realtime';

const agent = new RealtimeAgent({
  name: 'Greeter',
  instructions: 'Greet the user with cheer and answer questions.',
});

const session = new RealtimeSession(agent, {
  model: 'gpt-4o-realtime-preview-2025-06-03',
});

session.transport.on('*', (event) => {
  // JSON parsed version of the event received on the connection
});

// Send any valid event as JSON. For example triggering a new response
session.transport.sendEvent({
  type: 'response.create',
  // ...
});



================================================
FILE: examples/docs/voice-agents/turnDetection.ts
================================================
import { RealtimeSession } from '@openai/agents/realtime';
import { agent } from './agent';

const session = new RealtimeSession(agent, {
  model: 'gpt-4o-realtime-preview-2025-06-03',
  config: {
    turnDetection: {
      type: 'semantic_vad',
      eagerness: 'medium',
      createResponse: true,
      interruptResponse: true,
    },
  },
});



================================================
FILE: examples/docs/voice-agents/updateHistory.ts
================================================
import { RealtimeSession, RealtimeAgent } from '@openai/agents/realtime';

const agent = new RealtimeAgent({
  name: 'Assistant',
});

const session = new RealtimeSession(agent, {
  model: 'gpt-4o-realtime-preview-2025-06-03',
});

await session.connect({ apiKey: '<client-api-key>' });

// listening to the history_updated event
session.on('history_updated', (history) => {
  // returns the full history of the session
  console.log(history);
});

// Option 1: explicit setting
session.updateHistory([
  /* specific history */
]);

// Option 2: override based on current state like removing all agent messages
session.updateHistory((currentHistory) => {
  return currentHistory.filter(
    (item) => !(item.type === 'message' && item.role === 'assistant'),
  );
});



================================================
FILE: examples/docs/voice-agents/websocketSession.ts
================================================
import { RealtimeAgent, RealtimeSession } from '@openai/agents/realtime';

const agent = new RealtimeAgent({
  name: 'Greeter',
  instructions: 'Greet the user with cheer and answer questions.',
});

const myRecordedArrayBuffer = new ArrayBuffer(0);

const wsSession = new RealtimeSession(agent, {
  transport: 'websocket',
  model: 'gpt-4o-realtime-preview-2025-06-03',
});
await wsSession.connect({ apiKey: process.env.OPENAI_API_KEY! });

wsSession.on('audio', (event) => {
  // event.data is a chunk of PCM16 audio
});

wsSession.sendAudio(myRecordedArrayBuffer);



================================================
FILE: examples/financial-research-agent/README.md
================================================
# Financial Research Agent

This example demonstrates a multi-agent workflow that produces a short financial analysis report.

The entrypoint in `main.ts` prompts for a query, then traces the run and hands control to `FinancialResearchManager`.

The manager orchestrates several specialized agents:

1. **Planner** – creates a list of search tasks for the query.
2. **Search** – runs each search in parallel and gathers summaries.
3. **Writer** – synthesizes the search results, optionally calling fundamentals and risk analyst tools.
4. **Verifier** – checks the final report for consistency and issues.

After running these steps the manager prints a short summary, the full markdown report, suggested follow-up questions, and verification results.

Run the example with:

```bash
pnpm examples:financial-research-agent
```



================================================
FILE: examples/financial-research-agent/agents.ts
================================================
import { Agent, webSearchTool } from '@openai/agents';
import { z } from 'zod';

// --- Fundamentals Analyst Agent ---
export const financialsPrompt = `You are a financial analyst focused on company fundamentals such as revenue, profit, margins and growth trajectory.
Given a collection of web (and optional file) search results about a company, write a concise analysis of its recent financial performance.
Pull out key metrics or quotes. Keep it under 2 paragraphs.`;

export const AnalysisSummary = z.object({
  summary: z
    .string()
    .describe('Short text summary for this aspect of the analysis.'),
});

export const financialsAgent = new Agent({
  name: 'FundamentalsAnalystAgent',
  instructions: financialsPrompt,
  outputType: AnalysisSummary,
});

// --- Financial Research Planner Agent ---
export const plannerPrompt = `You are a financial research planner.
Given a request for financial analysis, produce a set of web searches to gather the context needed.
Aim for recent headlines, earnings calls or 10-K snippets, analyst commentary, and industry background.
Output between 5 and 15 search terms to query for.`;

export const FinancialSearchItem = z.object({
  reason: z
    .string()
    .describe('Your reasoning for why this search is relevant.'),
  query: z
    .string()
    .describe('The search term to feed into a web (or file) search.'),
});

export type FinancialSearchItem = z.infer<typeof FinancialSearchItem>;

export const FinancialSearchPlan = z.object({
  searches: z
    .array(FinancialSearchItem)
    .describe('A list of searches to perform.'),
});

export type FinancialSearchPlan = z.infer<typeof FinancialSearchPlan>;

export const plannerAgent = new Agent({
  name: 'FinancialPlannerAgent',
  instructions: plannerPrompt,
  model: 'o3-mini',
  outputType: FinancialSearchPlan,
});

// --- Risk Analyst Agent ---
export const riskPrompt = `You are a risk analyst looking for potential red flags in a company's outlook.
Given background research, produce a short analysis of risks such as competitive threats, regulatory issues, supply chain problems, or slowing growth.
Keep it under 2 paragraphs.`;

export const riskAgent = new Agent({
  name: 'RiskAnalystAgent',
  instructions: riskPrompt,
  outputType: AnalysisSummary,
});

// --- Financial Search Agent ---
export const searchAgentPrompt = `You are a research assistant specializing in financial topics.
Given a search term, use web search to retrieve up-to-date context and produce a short summary of at most 300 words.
Focus on key numbers, events, or quotes that will be useful to a financial analyst.`;

export const searchAgent = new Agent({
  name: 'FinancialSearchAgent',
  instructions: searchAgentPrompt,
  tools: [webSearchTool()],
  modelSettings: { toolChoice: 'required' },
});

// --- Verification Agent ---
export const verifierPrompt = `You are a meticulous auditor. You have been handed a financial analysis report.
Your job is to verify the report is internally consistent, clearly sourced, and makes no unsupported claims.
Point out any issues or uncertainties.`;

export const VerificationResult = z.object({
  verified: z
    .boolean()
    .describe('Whether the report seems coherent and plausible.'),
  issues: z
    .string()
    .describe('If not verified, describe the main issues or concerns.'),
});

export type VerificationResult = z.infer<typeof VerificationResult>;

export const verifierAgent = new Agent({
  name: 'VerificationAgent',
  instructions: verifierPrompt,
  model: 'gpt-4o',
  outputType: VerificationResult,
});

// --- Financial Writer Agent ---
export const writerPrompt = `You are a senior financial analyst.
You will be provided with the original query and a set of raw search summaries.
Your task is to synthesize these into a long-form markdown report (at least several paragraphs) including a short executive summary and follow-up questions.
If needed, you can call the available analysis tools (e.g. fundamentals_analysis, risk_analysis) to get short specialist write-ups to incorporate.`;

export const FinancialReportData = z.object({
  short_summary: z.string().describe('A short 2-3 sentence executive summary.'),
  markdown_report: z.string().describe('The full markdown report.'),
  follow_up_questions: z
    .array(z.string())
    .describe('Suggested follow-up questions for further research.'),
});

export type FinancialReportData = z.infer<typeof FinancialReportData>;

export const writerAgent = new Agent({
  name: 'FinancialWriterAgent',
  instructions: writerPrompt,
  model: 'gpt-4.5-preview-2025-02-27',
  outputType: FinancialReportData,
});



================================================
FILE: examples/financial-research-agent/main.ts
================================================
import { withTrace } from '@openai/agents';
import { FinancialResearchManager } from './manager';

// Entrypoint for the financial bot example.
// Run this as `npx tsx examples/financial-research-agent/main.ts` and enter a financial research query, for example:
// "Write up an analysis of Apple Inc.'s most recent quarter."

async function main() {
  const readline = await import('readline');
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
  });
  rl.question('Enter a financial research query: ', async (query: string) => {
    rl.close();
    await withTrace('Financial research workflow', async () => {
      const manager = new FinancialResearchManager();
      await manager.run(query);
    });
  });
}

if (require.main === module) {
  main();
}



================================================
FILE: examples/financial-research-agent/manager.ts
================================================
import { Agent, run, RunResult } from '@openai/agents';
import { financialsAgent } from './agents';
import {
  plannerAgent,
  FinancialSearchItem,
  FinancialSearchPlan,
} from './agents';
import { riskAgent } from './agents';
import { searchAgent } from './agents';
import { verifierAgent, VerificationResult } from './agents';
import { writerAgent, FinancialReportData } from './agents';

// Custom output extractor for sub-agents that return an AnalysisSummary
async function summaryExtractor(
  runResult: RunResult<unknown, Agent<unknown, any>>,
): Promise<string> {
  return String(runResult.finalOutput.summary);
}

export class FinancialResearchManager {
  async run(query: string): Promise<void> {
    console.log(`[start] Starting financial research...`);
    const searchPlan = await this.planSearches(query);
    const searchResults = await this.performSearches(searchPlan);
    const report = await this.writeReport(query, searchResults);
    const verification = await this.verifyReport(report);
    const finalReport = `Report summary\n\n${report.short_summary}`;
    console.log(finalReport);
    console.log('\n\n=====REPORT=====\n\n');
    console.log(`Report:\n${report.markdown_report}`);
    console.log('\n\n=====FOLLOW UP QUESTIONS=====\n\n');
    console.log(report.follow_up_questions.join('\n'));
    console.log('\n\n=====VERIFICATION=====\n\n');
    console.log(verification);
  }

  async planSearches(query: string): Promise<FinancialSearchPlan> {
    console.log(`[planning] Planning searches...`);
    const result = await run(plannerAgent, `Query: ${query}`);
    console.log(
      `[planning] Will perform ${result.finalOutput?.searches.length} searches`,
    );
    return result.finalOutput!;
  }

  async performSearches(searchPlan: FinancialSearchPlan): Promise<string[]> {
    // Run all searches in parallel and log progress as each completes
    console.log(`[searching] Searching...`);
    let numCompleted = 0;
    const results: (string | null)[] = new Array(searchPlan.searches.length);
    await Promise.all(
      searchPlan.searches.map(async (item, i) => {
        const result = await this.search(item);
        results[i] = result;
        numCompleted++;
        console.log(
          `[searching] Searching... ${numCompleted}/${searchPlan.searches.length} completed`,
        );
      }),
    );
    console.log(`[searching] Done searching.`);
    // Filter out nulls and preserve order
    return results.filter((r): r is string => r !== null);
  }

  async search(item: FinancialSearchItem): Promise<string | null> {
    const inputData = `Search term: ${item.query}\nReason: ${item.reason}`;
    try {
      const result = await run(searchAgent, inputData);
      return String(result.finalOutput);
    } catch {
      return null;
    }
  }

  async writeReport(
    query: string,
    searchResults: string[],
  ): Promise<FinancialReportData> {
    // Expose the specialist analysts as tools
    const fundamentalsTool = financialsAgent.asTool({
      toolName: 'fundamentals_analysis',
      toolDescription: 'Use to get a short write-up of key financial metrics',
      customOutputExtractor: summaryExtractor,
    });
    const riskTool = riskAgent.asTool({
      toolName: 'risk_analysis',
      toolDescription: 'Use to get a short write-up of potential red flags',
      customOutputExtractor: summaryExtractor,
    });
    const writerWithTools = writerAgent.clone({
      tools: [fundamentalsTool, riskTool],
    });
    console.log(`[writing] Thinking about report...`);
    const inputData = `Original query: ${query}\nSummarized search results: ${searchResults}`;
    const result = await run(writerWithTools, inputData);
    console.log(`[writing] Done writing report.`);
    return result.finalOutput!;
  }

  async verifyReport(report: FinancialReportData): Promise<VerificationResult> {
    console.log(`[verifying] Verifying report...`);
    const result = await run(verifierAgent, report.markdown_report);
    console.log(`[verifying] Done verifying report.`);
    return result.finalOutput!;
  }
}



================================================
FILE: examples/financial-research-agent/package.json
================================================
{
  "private": true,
  "name": "financial-research-agent",
  "dependencies": {
    "@openai/agents": "workspace:*",
    "zod": "~3.25.40"
  },
  "scripts": {
    "build-check": "tsc --noEmit",
    "start": "tsx main.ts"
  }
}



================================================
FILE: examples/financial-research-agent/tsconfig.json
================================================
{
  "extends": "../../tsconfig.examples.json"
}



================================================
FILE: examples/handoffs/README.md
================================================
# Agent Handoffs

This example shows how one agent can transfer control to another. The `index.ts` script sets up two English speaking assistants and a Spanish assistant. The second agent is configured with a handoff so that if the user requests Spanish replies it hands off to the Spanish agent. A message filter strips out tool messages and the first two history items before the handoff occurs. Run it with:

```bash
pnpm -F handoffs start
```

`types.ts` demonstrates typed outputs. A triage agent inspects the message and hands off to either `firstAgent` or `secondAgent`, each with their own Zod schema for structured output. The script logs which agent produced the final result.



================================================
FILE: examples/handoffs/index.ts
================================================
import {
  Agent,
  run,
  tool,
  HandoffInputData,
  handoff,
  withTrace,
} from '@openai/agents';
import { removeAllTools } from '@openai/agents-core/extensions';
import { z } from 'zod';

// Random number tool
const randomNumberTool = tool({
  name: 'random_number_tool',
  description: 'Return a random integer between 0 and the given maximum.',
  parameters: z.object({
    max: z.number().describe('The maximum value.'),
  }),
  async execute(input: { max: number }) {
    return Math.floor(Math.random() * (input.max + 1)).toString();
  },
});

// Message filter for handoff (removes tool messages and first two history items)
function spanishHandoffMessageFilter(handoffMessageData: HandoffInputData) {
  // Remove all tool-related messages
  return removeAllTools(handoffMessageData);
}

const firstAgent = new Agent({
  name: 'First Assistant',
  instructions: 'Be extremely concise.',
  tools: [randomNumberTool],
});

const spanishAgent = new Agent({
  name: 'Spanish Assistant',
  instructions: 'You only speak Spanish and are extremely concise.',
  handoffDescription: 'A Spanish-speaking assistant.',
});

const secondAgent = new Agent({
  name: 'Second Assistant',
  instructions:
    'Be a helpful assistant. If the user speaks Spanish, handoff to the Spanish assistant.',
  handoffs: [
    handoff(spanishAgent, { inputFilter: spanishHandoffMessageFilter }),
  ],
});

async function main() {
  withTrace('Handoffs example', async () => {
    // 1. Send a regular message to the first agent
    console.log('Step 1: Send a regular message to the first agent');
    let result = await run(firstAgent, 'Hi, my name is Sora.');
    console.log('Step 1 done');

    // 2. Ask it to generate a number
    console.log('Step 2: Ask it to generate a number');
    result = await run(firstAgent, [
      ...result.history,
      {
        content: 'Can you generate a random number between 0 and 100?',
        role: 'user',
      },
    ]);
    console.log('Step 2 done');

    // 3. Call the second agent
    console.log('Step 3: Call the second agent');
    result = await run(secondAgent, [
      ...result.history,
      {
        content: 'I live in New York City. Whats the population of the city?',
        role: 'user',
      },
    ]);
    console.log('Step 3 done');

    // 4. Cause a handoff to occur
    console.log('Step 4: Cause a handoff to occur');
    result = await run(secondAgent, [
      ...result.history,
      {
        content: 'Por favor habla en español. ¿Cuál es mi nombre y dónde vivo?',
        role: 'user',
      },
    ]);
    console.log('Step 4 done');

    console.log('\n===Final messages===\n');

    for (const message of result.history) {
      console.log(JSON.stringify(message, null, 2));
    }
  });
}

if (require.main === module) {
  main().catch((err) => {
    console.error(err);
    process.exit(1);
  });
}



================================================
FILE: examples/handoffs/package.json
================================================
{
  "private": true,
  "name": "handoffs",
  "dependencies": {
    "@openai/agents": "workspace:*",
    "@openai/agents-core": "workspace:*",
    "zod": "~3.25.40"
  },
  "scripts": {
    "build-check": "tsc --noEmit",
    "start": "tsx index.ts",
    "start:types": "tsx types.ts"
  }
}



================================================
FILE: examples/handoffs/tsconfig.json
================================================
{
  "extends": "../../tsconfig.examples.json"
}



================================================
FILE: examples/handoffs/types.ts
================================================
import { Agent, run } from '@openai/agents';
import { z } from 'zod';

const FirstOutput = z.object({
  first: z.string(),
});

// Agent<unknown, typeof FirstOutput>
const firstAgent = new Agent({
  name: 'First Assistant',
  instructions: 'Be a helpful assistant.',
  outputType: FirstOutput,
});

const SecondOutput = z.object({
  second: z.string(),
});

// Agent<unknown, typeof SecondOutput>
const secondAgent = new Agent({
  name: 'Second Assistant',
  instructions: 'Be a helpful assistant.',
  outputType: SecondOutput,
});

const triageAgent = Agent.create({
  name: 'Triage Assistant',
  instructions:
    'You are a triage assistant. If the input say "first", hand off to firstAgent. It it has "Second", hand off to secondAgent.',
  handoffs: [firstAgent, secondAgent],
});

async function main() {
  for (const keyword of ['first', 'second', 'last']) {
    const result = await run(
      triageAgent,
      `Hey, how are you? This is my ${keyword} message.`,
    );
    const finalOutput = result.finalOutput;
    if (typeof finalOutput === 'string') {
      console.log(`Triage Assistant: ${finalOutput}`);
    } else if (finalOutput && 'first' in finalOutput) {
      console.log(`First Assistant: ${JSON.stringify(finalOutput)}`);
    } else if (finalOutput && 'second' in finalOutput) {
      console.log(`Second Assistant: ${JSON.stringify(finalOutput)}`);
    } else {
      console.log('No final output.');
    }
  }
}

if (require.main === module) {
  main().catch((err) => {
    console.error(err);
    process.exit(1);
  });
}



================================================
FILE: examples/mcp/README.md
================================================
# Model Context Protocol Example

This example demonstrates how to use the [Model Context Protocol](https://modelcontextprotocol.io/) with the OpenAI Agents SDK.

`filesystem-example.ts` starts a local MCP server exposing the files inside `sample_files/`. The agent reads those files through the protocol and can answer questions about them. The directory includes:

- `books.txt` – A list of favorite books.
- `favorite_songs.txt` – A list of favorite songs.

Run the example from the repository root:

```bash
pnpm -F mcp start:stdio
```



================================================
FILE: examples/mcp/filesystem-example.ts
================================================
import { Agent, run, MCPServerStdio, withTrace } from '@openai/agents';
import * as path from 'node:path';

async function main() {
  const samplesDir = path.join(__dirname, 'sample_files');
  const mcpServer = new MCPServerStdio({
    name: 'Filesystem Server, via npx',
    fullCommand: `npx -y @modelcontextprotocol/server-filesystem ${samplesDir}`,
    // Or passing command and args
    // command: 'npx',
    // args: ['-y', '@modelcontextprotocol/server-filesystem', samplesDir],
  });

  await mcpServer.connect();

  try {
    await withTrace('MCP Filesystem Example', async () => {
      const agent = new Agent({
        name: 'MCP Assistant',
        instructions:
          'Use the tools to read the filesystem and answer questions based on those files. If you are unable to find any files, you can say so instead of assuming they exist.',
        mcpServers: [mcpServer],
      });
      // List the files it can read
      let message = 'Read the files and list them.';
      console.log(`Running: ${message}`);
      let result = await run(agent, message);
      console.log(result.finalOutput);

      // Ask about books
      message = 'What is my #1 favorite book?';
      console.log(`\nRunning: ${message}\n`);
      result = await run(agent, message);
      console.log(result.finalOutput);

      // Ask a question that reads then reasons
      message =
        'Look at my favorite songs. Suggest one new song that I might like.';
      console.log(`\nRunning: ${message}\n`);
      result = await run(agent, message);
      console.log(result.finalOutput);
    });
  } finally {
    await mcpServer.close();
  }
}

main().catch((err) => {
  console.error(err);
  process.exit(1);
});



================================================
FILE: examples/mcp/hosted-mcp-human-in-the-loop.ts
================================================
import { Agent, run, hostedMcpTool, RunToolApprovalItem } from '@openai/agents';
import * as readline from 'node:readline/promises';
import { stdin, stdout } from 'node:process';

async function confirm(item: RunToolApprovalItem): Promise<boolean> {
  const rl = readline.createInterface({ input: stdin, output: stdout });
  const name = item.rawItem.name;
  const params = JSON.parse(item.rawItem.providerData?.arguments || '{}');
  const answer = await rl.question(
    `Approve running tool (mcp: ${name}, params: ${JSON.stringify(params)})? (y/n) `,
  );
  rl.close();
  return answer.toLowerCase().trim() === 'y';
}

async function main(verbose: boolean, stream: boolean): Promise<void> {
  // 'always' | 'never' | { never, always }
  const requireApproval = {
    never: { toolNames: ['search_codex_code', 'fetch_codex_documentation'] },
    always: { toolNames: ['fetch_generic_url_content'] },
  };
  const agent = new Agent({
    name: 'MCP Assistant',
    instructions: 'You must always use the MCP tools to answer questions.',
    tools: [
      hostedMcpTool({
        serverLabel: 'gitmcp',
        serverUrl: 'https://gitmcp.io/openai/codex',
        requireApproval,
        // when you don't pass onApproval, the agent loop will handle the approval process
      }),
    ],
  });

  const input = 'Which language is this repo written in?';

  if (stream) {
    // Streaming
    const result = await run(agent, input, { stream: true, maxTurns: 100 });
    for await (const event of result) {
      if (verbose) {
        console.log(JSON.stringify(event, null, 2));
      } else {
        if (
          event.type === 'raw_model_stream_event' &&
          event.data.type === 'model'
        ) {
          console.log(event.data.event.type);
        }
      }
    }
    console.log(`Done streaming; final result: ${result.finalOutput}`);
  } else {
    // Non-streaming
    let result = await run(agent, input);
    while (result.interruptions && result.interruptions.length) {
      for (const interruption of result.interruptions) {
        // Human in the loop here
        const approval = await confirm(interruption);
        if (approval) {
          result.state.approve(interruption);
        } else {
          result.state.reject(interruption);
        }
      }
      result = await run(agent, result.state);
    }
    console.log(result.finalOutput);

    if (verbose) {
      console.log('----------------------------------------------------------');
      console.log(JSON.stringify(result.newItems, null, 2));
      console.log('----------------------------------------------------------');
    }
  }
}

const args = process.argv.slice(2);
const verbose = args.includes('--verbose');
const stream = args.includes('--stream');

main(verbose, stream).catch((err) => {
  console.error(err);
  process.exit(1);
});



================================================
FILE: examples/mcp/hosted-mcp-on-approval.ts
================================================
import * as readline from 'readline/promises';
import { stdin, stdout } from 'node:process';
import { Agent, run, hostedMcpTool, RunToolApprovalItem } from '@openai/agents';

async function promptApproval(item: RunToolApprovalItem): Promise<boolean> {
  const rl = readline.createInterface({ input: stdin, output: stdout });
  const name = item.rawItem.name;
  const params = JSON.parse(item.rawItem.providerData?.arguments || '{}');
  const answer = await rl.question(
    `Approve running tool (mcp: ${name}, params: ${JSON.stringify(params)})? (y/n) `,
  );
  rl.close();
  return answer.toLowerCase().trim() === 'y';
}

async function main(verbose: boolean, stream: boolean): Promise<void> {
  // 'always' | 'never' | { never, always }
  const requireApproval = {
    never: {
      toolNames: ['fetch_codex_documentation', 'fetch_generic_url_content'],
    },
    always: {
      toolNames: ['search_codex_code'],
    },
  };
  const agent = new Agent({
    name: 'MCP Assistant',
    instructions: 'You must always use the MCP tools to answer questions.',
    tools: [
      hostedMcpTool({
        serverLabel: 'gitmcp',
        serverUrl: 'https://gitmcp.io/openai/codex',
        requireApproval,
        onApproval: async (_context, item) => {
          // Human in the loop here
          const approval = await promptApproval(item);
          return { approve: approval, reason: undefined };
        },
      }),
    ],
  });

  const input = 'Which language is this repo written in?';

  if (stream) {
    // Streaming
    const result = await run(agent, input, { stream: true });
    for await (const event of result) {
      if (verbose) {
        console.log(JSON.stringify(event, null, 2));
      } else {
        if (
          event.type === 'raw_model_stream_event' &&
          event.data.type === 'model'
        ) {
          console.log(event.data.event.type);
        }
      }
    }
    console.log(`Done streaming; final result: ${result.finalOutput}`);
  } else {
    // Non-streaming
    let result = await run(agent, input);
    while (result.interruptions && result.interruptions.length) {
      result = await run(agent, result.state);
    }
    console.log(result.finalOutput);

    if (verbose) {
      console.log('----------------------------------------------------------');
      console.log(JSON.stringify(result.newItems, null, 2));
      console.log('----------------------------------------------------------');
    }
  }
}

const args = process.argv.slice(2);
const verbose = args.includes('--verbose');
const stream = args.includes('--stream');

main(verbose, stream).catch((err) => {
  console.error(err);
  process.exit(1);
});



================================================
FILE: examples/mcp/hosted-mcp-simple.ts
================================================
import { Agent, run, hostedMcpTool, withTrace } from '@openai/agents';

async function main(verbose: boolean, stream: boolean): Promise<void> {
  withTrace('Hosted MCP Example', async () => {
    const agent = new Agent({
      name: 'MCP Assistant',
      instructions: 'You must always use the MCP tools to answer questions.',
      tools: [
        hostedMcpTool({
          serverLabel: 'gitmcp',
          serverUrl: 'https://gitmcp.io/openai/codex',
        }),
      ],
    });

    const input =
      'Which language is the repo I pointed in the MCP tool settings written in?';
    if (stream) {
      const result = await run(agent, input, { stream: true });
      for await (const event of result) {
        if (
          event.type === 'raw_model_stream_event' &&
          event.data.type === 'model' &&
          event.data.event.type !== 'response.mcp_call_arguments.delta' &&
          event.data.event.type !== 'response.output_text.delta'
        ) {
          console.log(`Got event of type ${JSON.stringify(event.data)}`);
        }
      }
      for (const item of result.newItems) {
        console.log(JSON.stringify(item, null, 2));
      }
      console.log(`Done streaming; final result: ${result.finalOutput}`);
    } else {
      const res = await run(agent, input);
      // The repository is primarily written in multiple languages, including Rust and TypeScript...
      if (verbose) {
        for (const item of res.output) {
          console.log(JSON.stringify(item, null, 2));
        }
      }
      console.log(res.finalOutput);
    }
  });
}

const args = process.argv.slice(2);
const verbose = args.includes('--verbose');
const stream = args.includes('--stream');

main(verbose, stream).catch((err) => {
  console.error(err);
  process.exit(1);
});



================================================
FILE: examples/mcp/package.json
================================================
{
  "private": true,
  "name": "mcp",
  "dependencies": {
    "@modelcontextprotocol/sdk": "^1.12.0",
    "@openai/agents": "workspace:*",
    "zod": "~3.25.40"
  },
  "scripts": {
    "build-check": "tsc --noEmit",
    "start:stdio": "tsx filesystem-example.ts",
    "start:streamable-http": "tsx streamable-http-example.ts",
    "start:hosted-mcp-on-approval": "tsx hosted-mcp-on-approval.ts",
    "start:hosted-mcp-human-in-the-loop": "tsx hosted-mcp-human-in-the-loop.ts",
    "start:hosted-mcp-simple": "tsx hosted-mcp-simple.ts"
  }
}



================================================
FILE: examples/mcp/streamable-http-example.ts
================================================
import { Agent, run, MCPServerStreamableHttp, withTrace } from '@openai/agents';

async function main() {
  const mcpServer = new MCPServerStreamableHttp({
    url: 'https://gitmcp.io/openai/codex',
    name: 'GitMCP Documentation Server',
  });
  const agent = new Agent({
    name: 'GitMCP Assistant',
    instructions: 'Use the tools to respond to user requests.',
    mcpServers: [mcpServer],
  });

  try {
    await withTrace('GitMCP Documentation Server Example', async () => {
      await mcpServer.connect();
      const result = await run(
        agent,
        'Which language is this repo written in?',
      );
      console.log(result.finalOutput);
    });
  } finally {
    await mcpServer.close();
  }
}

main().catch((err) => {
  console.error(err);
  process.exit(1);
});



================================================
FILE: examples/mcp/tsconfig.json
================================================
{
  "extends": "../../tsconfig.examples.json"
}



================================================
FILE: examples/mcp/sample_files/books.txt
================================================
1. To Kill a Mockingbird – Harper Lee
2. Pride and Prejudice – Jane Austen
3. 1984 – George Orwell
4. The Hobbit – J.R.R. Tolkien
5. Harry Potter and the Sorcerer’s Stone – J.K. Rowling
6. The Great Gatsby – F. Scott Fitzgerald
7. Charlotte’s Web – E.B. White
8. Anne of Green Gables – Lucy Maud Montgomery
9. The Alchemist – Paulo Coelho
10. Little Women – Louisa May Alcott
11. The Catcher in the Rye – J.D. Salinger
12. Animal Farm – George Orwell
13. The Chronicles of Narnia: The Lion, the Witch, and the Wardrobe – C.S. Lewis
14. The Book Thief – Markus Zusak
15. A Wrinkle in Time – Madeleine L’Engle
16. The Secret Garden – Frances Hodgson Burnett
17. Moby-Dick – Herman Melville
18. Fahrenheit 451 – Ray Bradbury
19. Jane Eyre – Charlotte Brontë
20. The Little Prince – Antoine de Saint-Exupéry


================================================
FILE: examples/mcp/sample_files/favorite_songs.txt
================================================
1. "Here Comes the Sun" – The Beatles
2. "Imagine" – John Lennon
3. "Bohemian Rhapsody" – Queen
4. "Shake It Off" – Taylor Swift
5. "Billie Jean" – Michael Jackson
6. "Uptown Funk" – Mark Ronson ft.  Bruno Mars
7. "Don’t Stop Believin’" – Journey
8. "Dancing Queen" – ABBA
9. "Happy" – Pharrell Williams
10. "Wonderwall" – Oasis



================================================
FILE: examples/model-providers/README.md
================================================
# Model Providers Examples

This directory contains small scripts showing how to integrate custom model providers. Run them with `pnpm` using the commands shown below.

- `custom-example-agent.ts` – Pass a model instance directly to an `Agent`.
  ```bash
  pnpm -F model-providers start:custom-example-agent
  ```
- `custom-example-global.ts` – Configure a global model provider. Requires environment variables `EXAMPLE_BASE_URL`, `EXAMPLE_API_KEY`, and `EXAMPLE_MODEL_NAME`.
  ```bash
  pnpm -F model-providers start:custom-example-global
  ```
- `custom-example-provider.ts` – Create a custom `ModelProvider` for a single run (same environment variables as above).
  ```bash
  pnpm -F model-providers start:custom-example-provider
  ```



================================================
FILE: examples/model-providers/custom-example-agent.ts
================================================
import { z } from 'zod';
import {
  Agent,
  run,
  withTrace,
  OpenAIChatCompletionsModel,
  tool,
} from '@openai/agents';
import { OpenAI } from 'openai';

const getWeatherTool = tool({
  name: 'get_weather',
  description: 'Get the weather for a given city',
  parameters: z.object({ city: z.string() }),
  execute: async (input) => {
    return `The weather in ${input.city} is sunny`;
  },
});

const client = new OpenAI();
const agent = new Agent({
  name: 'Assistant',
  model: new OpenAIChatCompletionsModel(client, 'gpt-4o'),
  instructions: 'You only respond in haikus.',
  tools: [getWeatherTool],
});

async function main() {
  await withTrace('ChatCompletions Assistant Example', async () => {
    const result = await run(agent, "What's the weather in Tokyo?");
    console.log(`\n\nFinal response:\n${result.finalOutput}`);
  });
}

main().catch((error) => {
  console.error('Error:', error);
});



================================================
FILE: examples/model-providers/custom-example-global.ts
================================================
import {
  Agent,
  Runner,
  setTracingDisabled,
  tool,
  OpenAIProvider,
  setDefaultOpenAIClient,
  setOpenAIAPI,
} from '@openai/agents';
import OpenAI from 'openai';
import { z } from 'zod';

// Read environment variables
const BASE_URL = process.env.EXAMPLE_BASE_URL || '';
const API_KEY = process.env.EXAMPLE_API_KEY || '';
const MODEL_NAME = process.env.EXAMPLE_MODEL_NAME || '';

if (!BASE_URL || !API_KEY || !MODEL_NAME) {
  throw new Error(
    'Please set EXAMPLE_BASE_URL, EXAMPLE_API_KEY, EXAMPLE_MODEL_NAME via env var or code.',
  );
}

/**
 * This example uses a custom provider for all requests by default. We do three things:
 * 1. Create a custom client.
 * 2. Set it as the default OpenAI client, and don't use it for tracing.
 * 3. Set the default API as Chat Completions, as most LLM providers don't yet support Responses API.
 *
 * Note that in this example, we do not set up tracing, under the assumption that you don't have an API key
 * from platform.openai.com. If you do have one, you can set the `OPENAI_API_KEY` env var for tracing.
 */

// Create a custom OpenAI client and provider
const openaiClient = new OpenAI({
  apiKey: API_KEY,
  baseURL: BASE_URL,
});
const modelProvider = new OpenAIProvider({
  openAIClient: openaiClient,
});
setDefaultOpenAIClient(openaiClient); // Pass the OpenAI client instance
setOpenAIAPI('chat_completions');
setTracingDisabled(true);

// Tool definition
const getWeather = tool({
  name: 'get_weather',
  description: 'Get the weather for a city.',
  parameters: z.object({
    city: z.string().describe('The city to get weather for'),
  }),
  async execute(input) {
    // input: { city: string }
    console.log(`[debug] getting weather for ${input.city}`);
    return `The weather in ${input.city} is sunny.`;
  },
});

async function main() {
  const agent = new Agent({
    name: 'Assistant',
    instructions: 'You only respond in haikus.',
    model: MODEL_NAME,
    tools: [getWeather],
  });

  const runner = new Runner({ modelProvider });
  const result = await runner.run(agent, "What's the weather in Tokyo?");
  console.log(result.finalOutput);
}

if (require.main === module) {
  main();
}



================================================
FILE: examples/model-providers/custom-example-provider.ts
================================================
import {
  Agent,
  Runner,
  tool,
  setTracingDisabled,
  ModelProvider,
  OpenAIChatCompletionsModel,
} from '@openai/agents';
import OpenAI from 'openai';
import { z } from 'zod';

// Read environment variables
const BASE_URL = process.env.EXAMPLE_BASE_URL || '';
const API_KEY = process.env.EXAMPLE_API_KEY || '';
const MODEL_NAME = process.env.EXAMPLE_MODEL_NAME || '';

if (!BASE_URL || !API_KEY || !MODEL_NAME) {
  throw new Error(
    'Please set EXAMPLE_BASE_URL, EXAMPLE_API_KEY, EXAMPLE_MODEL_NAME via env var or code.',
  );
}

/**
 * This example uses a custom provider for some calls to Runner.run(), and direct calls to OpenAI for others.
 * Steps:
 * 1. Create a custom OpenAI client.
 * 2. Create a ModelProvider that uses the custom client.
 * 3. Use the ModelProvider in calls to Runner.run(), only when we want to use the custom LLM provider.
 *
 * Note that in this example, we disable tracing under the assumption that you don't have an API key
 * from platform.openai.com. If you do have one, you can set the `OPENAI_API_KEY` env var for tracing.
 */

const client = new OpenAI({ apiKey: API_KEY, baseURL: BASE_URL });
setTracingDisabled(true);

class CustomModelProvider implements ModelProvider {
  async getModel(modelName?: string) {
    return new OpenAIChatCompletionsModel(client, modelName || MODEL_NAME);
  }
}

const CUSTOM_MODEL_PROVIDER = new CustomModelProvider();

const getWeather = tool({
  name: 'get_weather',
  description: 'Get the weather for a city.',
  parameters: z.object({ city: z.string() }),
  async execute(input) {
    console.log(`[debug] getting weather for ${input.city}`);
    return `The weather in ${input.city} is sunny.`;
  },
});

async function main() {
  const agent = new Agent({
    name: 'Assistant',
    instructions: 'You only respond in haikus.',
    tools: [getWeather],
  });

  // This will use the custom model provider
  const runner = new Runner({ modelProvider: CUSTOM_MODEL_PROVIDER });
  const result = await runner.run(agent, "What's the weather in Tokyo?");
  console.log(result.finalOutput);
}

if (require.main === module) {
  main();
}



================================================
FILE: examples/model-providers/package.json
================================================
{
  "private": true,
  "name": "model-providers",
  "dependencies": {
    "@openai/agents": "workspace:*",
    "zod": "~3.25.40"
  },
  "scripts": {
    "build-check": "tsc --noEmit",
    "start:custom-example-agent": "tsx custom-example-agent.ts",
    "start:custom-example-global": "tsx custom-example-global.ts",
    "start:custom-example-provider": "tsx custom-example-provider.ts"
  }
}



================================================
FILE: examples/model-providers/tsconfig.json
================================================
{
  "extends": "../../tsconfig.examples.json"
}



================================================
FILE: examples/nextjs/README.md
================================================
# Next.js Demo

This example shows a basic example of how to use human-in-the-loop in a Next.js application.

Right now it only uses a synchronous approach without streaming and storing in an in-memory DB.

Eventually we will add more examples.

## Run the example

Set the `OPENAI_API_KEY` environment variable and run:

```bash
pnpm -F nextjs dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser and ask `What is the weather in San Francisco and Oakland?`

## Endpoints

- **`/`** – The basic example that actually handles receiving the approval requests and sending messages to the API. Code in `src/app/page.tsx`.
- **`/api/basic`** – The endpoint that gets triggered to run the agent. Code in `src/app/websocket/page.tsx`.

## Other files

- `src/components/Approvals.tsx` — renders the approval dialog
- `src/agents.ts` — contains the basic Agent configuration
- `src/db.ts` — contains the mock database implementation



================================================
FILE: examples/nextjs/components.json
================================================
{
  "$schema": "https://ui.shadcn.com/schema.json",
  "style": "new-york",
  "rsc": true,
  "tsx": true,
  "tailwind": {
    "config": "",
    "css": "src/app/globals.css",
    "baseColor": "neutral",
    "cssVariables": true,
    "prefix": ""
  },
  "aliases": {
    "components": "@/components",
    "utils": "@/lib/utils",
    "ui": "@/components/ui",
    "lib": "@/lib",
    "hooks": "@/hooks"
  },
  "iconLibrary": "lucide"
}



================================================
FILE: examples/nextjs/next.config.ts
================================================
import type { NextConfig } from 'next';

const nextConfig: NextConfig = {
  /* config options here */
};

export default nextConfig;



================================================
FILE: examples/nextjs/package.json
================================================
{
  "name": "nextjs",
  "private": true,
  "scripts": {
    "dev": "next dev --turbopack",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "build-check": "tsc --noEmit"
  },
  "dependencies": {
    "@openai/agents": "workspace:*",
    "@radix-ui/react-dialog": "^1.1.14",
    "@radix-ui/react-slot": "^1.2.3",
    "@tanstack/react-query": "^5.80.7",
    "class-variance-authority": "^0.7.1",
    "clsx": "^2.1.1",
    "lucide-react": "^0.515.0",
    "next": "15.3.3",
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "tailwind-merge": "^3.3.1",
    "wavtools": "^0.1.5",
    "zod": "~3.25.40"
  },
  "devDependencies": {
    "@tailwindcss/postcss": "^4",
    "@types/node": "^20",
    "@types/react": "^19",
    "@types/react-dom": "^19",
    "tailwindcss": "^4",
    "tw-animate-css": "^1.3.4",
    "typescript": "^5"
  }
}



================================================
FILE: examples/nextjs/postcss.config.mjs
================================================
const config = {
  plugins: ['@tailwindcss/postcss'],
};

export default config;



================================================
FILE: examples/nextjs/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2017",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}



================================================
FILE: examples/nextjs/vercel.json
================================================
{
  "$schema": "https://openapi.vercel.sh/vercel.json",
  "framework": "nextjs"
}



================================================
FILE: examples/nextjs/src/agents.ts
================================================
import { Agent, tool } from '@openai/agents';
import z from 'zod';

const getWeather = tool({
  name: 'getWeather',
  description: 'Get the weather for a given city',
  parameters: z.object({
    city: z.string(),
  }),
  execute: async ({ city }) => {
    return `The weather in ${city} is sunny.`;
  },

  needsApproval: true,
});

export const agent = new Agent({
  name: 'Basic Agent',
  instructions: 'You are a basic agent.',
  tools: [getWeather],
});



================================================
FILE: examples/nextjs/src/db.ts
================================================
/**
 * This is just a super simple in-memory database for the demo.
 * In a real application, you would use a proper database that persists the data.
 */

export class Database<Value> {
  #database: Map<string, Value>;

  constructor() {
    this.#database = new Map();
  }

  async get(key: string) {
    return this.#database.get(key);
  }

  async set(key: string, value: Value) {
    this.#database.set(key, value);
  }
}

let database: Database<string> | undefined;

export function db() {
  if (!database) {
    database = new Database<string>();
  }
  return database;
}



================================================
FILE: examples/nextjs/src/app/globals.css
================================================
@import 'tailwindcss';
@import 'tw-animate-css';

@custom-variant dark (&:is(.dark *));

@theme inline {
  --color-background: var(--background);
  --color-foreground: var(--foreground);
  --font-sans: var(--font-geist-sans);
  --font-mono: var(--font-geist-mono);
  --color-sidebar-ring: var(--sidebar-ring);
  --color-sidebar-border: var(--sidebar-border);
  --color-sidebar-accent-foreground: var(--sidebar-accent-foreground);
  --color-sidebar-accent: var(--sidebar-accent);
  --color-sidebar-primary-foreground: var(--sidebar-primary-foreground);
  --color-sidebar-primary: var(--sidebar-primary);
  --color-sidebar-foreground: var(--sidebar-foreground);
  --color-sidebar: var(--sidebar);
  --color-chart-5: var(--chart-5);
  --color-chart-4: var(--chart-4);
  --color-chart-3: var(--chart-3);
  --color-chart-2: var(--chart-2);
  --color-chart-1: var(--chart-1);
  --color-ring: var(--ring);
  --color-input: var(--input);
  --color-border: var(--border);
  --color-destructive: var(--destructive);
  --color-accent-foreground: var(--accent-foreground);
  --color-accent: var(--accent);
  --color-muted-foreground: var(--muted-foreground);
  --color-muted: var(--muted);
  --color-secondary-foreground: var(--secondary-foreground);
  --color-secondary: var(--secondary);
  --color-primary-foreground: var(--primary-foreground);
  --color-primary: var(--primary);
  --color-popover-foreground: var(--popover-foreground);
  --color-popover: var(--popover);
  --color-card-foreground: var(--card-foreground);
  --color-card: var(--card);
  --radius-sm: calc(var(--radius) - 4px);
  --radius-md: calc(var(--radius) - 2px);
  --radius-lg: var(--radius);
  --radius-xl: calc(var(--radius) + 4px);
}

:root {
  --radius: 0.625rem;
  --background: oklch(1 0 0);
  --foreground: oklch(0.145 0 0);
  --card: oklch(1 0 0);
  --card-foreground: oklch(0.145 0 0);
  --popover: oklch(1 0 0);
  --popover-foreground: oklch(0.145 0 0);
  --primary: oklch(0.205 0 0);
  --primary-foreground: oklch(0.985 0 0);
  --secondary: oklch(0.97 0 0);
  --secondary-foreground: oklch(0.205 0 0);
  --muted: oklch(0.97 0 0);
  --muted-foreground: oklch(0.556 0 0);
  --accent: oklch(0.97 0 0);
  --accent-foreground: oklch(0.205 0 0);
  --destructive: oklch(0.577 0.245 27.325);
  --border: oklch(0.922 0 0);
  --input: oklch(0.922 0 0);
  --ring: oklch(0.708 0 0);
  --chart-1: oklch(0.646 0.222 41.116);
  --chart-2: oklch(0.6 0.118 184.704);
  --chart-3: oklch(0.398 0.07 227.392);
  --chart-4: oklch(0.828 0.189 84.429);
  --chart-5: oklch(0.769 0.188 70.08);
  --sidebar: oklch(0.985 0 0);
  --sidebar-foreground: oklch(0.145 0 0);
  --sidebar-primary: oklch(0.205 0 0);
  --sidebar-primary-foreground: oklch(0.985 0 0);
  --sidebar-accent: oklch(0.97 0 0);
  --sidebar-accent-foreground: oklch(0.205 0 0);
  --sidebar-border: oklch(0.922 0 0);
  --sidebar-ring: oklch(0.708 0 0);
}

.dark {
  --background: oklch(0.145 0 0);
  --foreground: oklch(0.985 0 0);
  --card: oklch(0.205 0 0);
  --card-foreground: oklch(0.985 0 0);
  --popover: oklch(0.205 0 0);
  --popover-foreground: oklch(0.985 0 0);
  --primary: oklch(0.922 0 0);
  --primary-foreground: oklch(0.205 0 0);
  --secondary: oklch(0.269 0 0);
  --secondary-foreground: oklch(0.985 0 0);
  --muted: oklch(0.269 0 0);
  --muted-foreground: oklch(0.708 0 0);
  --accent: oklch(0.269 0 0);
  --accent-foreground: oklch(0.985 0 0);
  --destructive: oklch(0.704 0.191 22.216);
  --border: oklch(1 0 0 / 10%);
  --input: oklch(1 0 0 / 15%);
  --ring: oklch(0.556 0 0);
  --chart-1: oklch(0.488 0.243 264.376);
  --chart-2: oklch(0.696 0.17 162.48);
  --chart-3: oklch(0.769 0.188 70.08);
  --chart-4: oklch(0.627 0.265 303.9);
  --chart-5: oklch(0.645 0.246 16.439);
  --sidebar: oklch(0.205 0 0);
  --sidebar-foreground: oklch(0.985 0 0);
  --sidebar-primary: oklch(0.488 0.243 264.376);
  --sidebar-primary-foreground: oklch(0.985 0 0);
  --sidebar-accent: oklch(0.269 0 0);
  --sidebar-accent-foreground: oklch(0.985 0 0);
  --sidebar-border: oklch(1 0 0 / 10%);
  --sidebar-ring: oklch(0.556 0 0);
}

@layer base {
  * {
    @apply border-border outline-ring/50;
  }
  body {
    @apply bg-background text-foreground;
  }
}



================================================
FILE: examples/nextjs/src/app/layout.tsx
================================================
import type { Metadata } from 'next';
import './globals.css';

export const metadata: Metadata = {
  title: 'Agent SDK Next.js Demo',
  description: 'A demo of the Agent SDK in Next.js',
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en">
      <body className={`antialiased`}>{children}</body>
    </html>
  );
}



================================================
FILE: examples/nextjs/src/app/page.tsx
================================================
'use client';

import type { AgentInputItem, RunToolApprovalItem } from '@openai/agents';
import { useState } from 'react';
import { App } from '@/components/App';
import { Approvals } from '@/components/Approvals';

export default function Home() {
  const [history, setHistory] = useState<AgentInputItem[]>([]);
  const [conversationId, setConversationId] = useState<string | null>(null);
  const [approvals, setApprovals] = useState<
    ReturnType<RunToolApprovalItem['toJSON']>[]
  >([]);

  async function makeRequest({
    message,
    decisions,
  }: {
    message?: string;
    decisions?: Map<string, 'approved' | 'rejected'>;
  }) {
    const messages = [...history];

    if (message) {
      messages.push({ type: 'message', role: 'user', content: message });
    }

    setHistory([
      ...messages,
      // This is just a placeholder to show on the UI to show the agent is working
      {
        type: 'message',
        role: 'assistant',
        content: [],
        status: 'in_progress',
      },
    ]);

    // We will send the messages to the API route along with the conversation ID if we have one
    // and the decisions if we had any approvals in this turn
    const response = await fetch('/api/basic', {
      method: 'POST',
      body: JSON.stringify({
        messages,
        conversationId,
        decisions: Object.fromEntries(decisions ?? []),
      }),
    });

    const data = await response.json();

    if (data.conversationId) {
      setConversationId(data.conversationId);
    }

    if (data.history) {
      setHistory(data.history);
    }

    if (data.approvals) {
      setApprovals(data.approvals);
    } else {
      setApprovals([]);
    }
  }

  const handleSend = async (message: string) => {
    await makeRequest({ message });
  };

  async function handleDone(decisions: Map<string, 'approved' | 'rejected'>) {
    await makeRequest({ decisions });
  }

  return (
    <>
      <App history={history} onSend={handleSend} />
      {/**
       * If we have any approvals, we will show the approvals component to allow the user to
       * approve or reject the tool calls. If we don't have any approvals, we will just show the
       * history. Once all the approvals are done, we will call the handleDone function to continue
       * the run. What kind of UI you render to show approval requests is up to you. You could also
       * render them as part of the chat history. We are rendering them separately here to show
       * that it can be an entirely different UI.
       */}
      <Approvals approvals={approvals} onDone={handleDone} />
    </>
  );
}



================================================
FILE: examples/nextjs/src/app/api/basic/route.ts
================================================
import { NextRequest, NextResponse } from 'next/server';
import { randomUUID } from 'node:crypto';

import { agent } from '@/agents';
import {
  AgentInputItem,
  Runner,
  RunState,
  RunToolApprovalItem,
} from '@openai/agents';
import { db } from '@/db';

function generateConversationId() {
  return `conv_${randomUUID().replace(/-/g, '').slice(0, 24)}`;
}

export async function POST(req: NextRequest) {
  try {
    const data = await req.json();
    let { messages, conversationId, decisions } = data;

    if (!messages) {
      messages = [];
    }

    if (!conversationId) {
      // we will generate a conversation ID so we can keep track of the state in case of conversations
      // this is just a key that we can use to store information in the database
      conversationId = generateConversationId();
    }

    if (!decisions) {
      decisions = null;
    }

    const runner = new Runner({
      groupId: conversationId,
    });

    let input: AgentInputItem[] | RunState<any, any>;
    if (
      Object.keys(decisions).length > 0 &&
      data.conversationId /* original conversationId */
    ) {
      // If we receive a new request with decisions, we will look up the current state in the database
      const stateString = await db().get(data.conversationId);

      if (!stateString) {
        return NextResponse.json(
          { error: 'Conversation not found' },
          { status: 404 },
        );
      }

      // We then deserialize the state so we can manipulate it and continue the run
      const state = await RunState.fromString(agent, stateString);

      const interruptions = state.getInterruptions();

      interruptions.forEach((item: RunToolApprovalItem) => {
        // For each interruption, we will then check if the decision is to approve or reject the tool call
        if (item.type === 'tool_approval_item' && 'callId' in item.rawItem) {
          const callId = item.rawItem.callId;

          if (decisions[callId] === 'approved') {
            state.approve(item);
          } else if (decisions[callId] === 'rejected') {
            state.reject(item);
          }
        }
      });

      // We will use the new updated state to continue the run
      input = state;
    } else {
      // If we don't have any decisions, we will just assume this is a regular chat and use the messages
      // as input for the next run
      input = messages;
    }

    const result = await runner.run(agent, input);

    if (result.interruptions.length > 0) {
      // If the run resulted in one or more interruptions, we will store the current state in the database

      // store the state in the database
      await db().set(conversationId, JSON.stringify(result.state));

      // We will return all the interruptions as approval requests to the UI/client so it can generate
      // the UI for approvals
      // We will also still return the history that contains the tool calls and potentially any interim
      // text response the agent might have generated (like announcing that it's calling a function)
      return NextResponse.json({
        conversationId,
        approvals: result.interruptions
          .filter((item) => item.type === 'tool_approval_item')
          .map((item) => item.toJSON()),
        history: result.history,
      });
    }

    return NextResponse.json({
      response: result.finalOutput,
      history: result.history,
      conversationId,
    });
  } catch (error) {
    console.error(error);
    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 },
    );
  }
}



================================================
FILE: examples/nextjs/src/components/App.tsx
================================================
import type { AgentInputItem } from '@openai/agents';
import { History } from '@/components/History';
import { Button } from '@/components/ui/Button';
import { useState, useRef, useEffect } from 'react';
import ArrowUpIcon from './icons/ArrowUpIcon';

export type AppProps = {
  title?: string;
  history?: AgentInputItem[];
  onSend: (message: string) => void;
};

export function App({ title = 'Agent Demo', history, onSend }: AppProps) {
  const [message, setMessage] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const inputRef = useRef<HTMLInputElement>(null);

  useEffect(() => {
    if (!isLoading) {
      inputRef.current?.focus();
    }
  }, [isLoading]);

  const handleSend = async () => {
    if (!message.trim()) return;
    setIsLoading(true);
    const msg = message;
    setMessage('');
    await onSend(msg);
    setIsLoading(false);
  };

  const handleSubmit = async (e: React.FormEvent<HTMLFormElement>) => {
    e.preventDefault();
    if (!message.trim()) return;
    await handleSend();
  };

  return (
    <div className="flex justify-center">
      <div className="p-4 md:max-h-screen overflow-hidden h-screen flex flex-col max-w-6xl w-full items-center">
        <header className="flex-none flex justify-between items-center pb-4 w-full max-w-6xl">
          <h1 className="text-2xl font-bold">{title}</h1>
        </header>
        <div className="flex flex-col h-full max-h-full max-w-4xl w-full">
          <div className="flex-1 overflow-y-auto">
            {history && history.length > 0 ? (
              <History history={history} />
            ) : (
              <div className="h-full flex items-center justify-center text-center text-gray-500">
                No history available
              </div>
            )}
          </div>
          <form
            className="gap-4 pt-4 flex flex-none w-full border border-gray-300 rounded-4xl p-4 focus-within:border-gray-500"
            onSubmit={handleSubmit}
          >
            <input
              type="text"
              className="flex-1 p-2 focus:outline-none"
              value={message}
              placeholder="Ask me anything..."
              onChange={(e) => setMessage(e.target.value)}
              disabled={isLoading}
              ref={inputRef}
            />
            <Button
              variant="primary"
              size="icon"
              type="submit"
              disabled={isLoading || !message.trim()}
            >
              <ArrowUpIcon />
            </Button>
          </form>
        </div>
      </div>
    </div>
  );
}



================================================
FILE: examples/nextjs/src/components/Approvals.tsx
================================================
import type { RunToolApprovalItem } from '@openai/agents';
import {
  Dialog,
  DialogClose,
  DialogContent,
  DialogDescription,
  DialogFooter,
  DialogHeader,
  DialogTitle,
} from '@/components/ui/dialog';
import { Button } from './ui/Button';
import { useEffect, useState } from 'react';

type Item = ReturnType<RunToolApprovalItem['toJSON']>;

function ToolApprovalEntry({
  approval,
  onApprove,
  onReject,
  decision,
}: {
  approval: Item;
  onApprove: () => void;
  onReject: () => void;
  decision: 'approved' | 'rejected' | undefined;
}) {
  if (approval.rawItem?.type !== 'function_call') {
    return null;
  }

  return (
    <div key={approval.rawItem?.id} className="flex flex-col gap-2">
      <h3 className="font-medium text-sm">
        Tool <code>{approval.rawItem?.name}</code>
      </h3>
      <pre className="text-sm bg-gray-50 p-4 rounded-md">
        {approval.rawItem?.arguments}
      </pre>
      {decision === undefined && (
        <div className="flex gap-2">
          <Button size="smRounded" variant="primary" onClick={onApprove}>
            Approve
          </Button>
          <Button size="smRounded" variant="secondary" onClick={onReject}>
            Reject
          </Button>
        </div>
      )}
      {decision === 'approved' && (
        <p className="text-sm text-green-700">✔︎ Approved</p>
      )}
      {decision === 'rejected' && (
        <p className="text-sm text-red-500">✖︎ Rejected</p>
      )}
    </div>
  );
}

/**
 * This component just renders all of the approval requests and tracks whether they were approved
 * or not by storing the callId in a decision Map with `approved` or `rejected` as the value.
 * Once all the approvals are done, we will call the onDone function to let the parent component
 * trigger the next run.
 */
export function Approvals({
  approvals,
  onDone,
}: {
  approvals: ReturnType<RunToolApprovalItem['toJSON']>[];
  onDone: (decisions: Map<string, 'approved' | 'rejected'>) => void;
}) {
  const [decisions, setDecisions] = useState<
    Map<string, 'approved' | 'rejected'>
  >(new Map());
  const [isOpen, setIsOpen] = useState(approvals.length > 0);

  useEffect(() => {
    setDecisions(new Map());
    if (approvals.length > 0) {
      setIsOpen(true);
    }
  }, [approvals]);

  function handleApprove(approval: Item) {
    setDecisions((prev) => {
      if (approval.rawItem?.type !== 'function_call') {
        return prev;
      }
      const newDecisions = new Map(prev);
      newDecisions.set(approval.rawItem?.callId ?? '', 'approved');
      return newDecisions;
    });
  }

  function handleReject(approval: Item) {
    setDecisions((prev) => {
      if (approval.rawItem?.type !== 'function_call') {
        return prev;
      }
      const newDecisions = new Map(prev);
      newDecisions.set(approval.rawItem?.callId ?? '', 'rejected');
      return newDecisions;
    });
  }

  function handleDone() {
    onDone(decisions);
    setIsOpen(false);
  }

  if (approvals.length === 0) {
    return null;
  }

  const agentName = approvals[0].agent.name;

  return (
    <Dialog open={isOpen}>
      <DialogContent>
        <DialogHeader>
          <DialogTitle>Approval required</DialogTitle>
          <DialogDescription>
            The agent {agentName} is requesting approval for the following
            action{approvals.length > 1 ? 's' : ''}:
          </DialogDescription>
        </DialogHeader>
        <div className="grid gap-8">
          {approvals.map((approval) =>
            approval.rawItem?.type === 'function_call' ? (
              <ToolApprovalEntry
                key={approval.rawItem?.callId}
                approval={approval}
                decision={decisions.get(approval.rawItem?.callId ?? '')}
                onApprove={() => handleApprove(approval)}
                onReject={() => handleReject(approval)}
              />
            ) : null,
          )}
        </div>
        <DialogFooter>
          <Button
            variant="primary"
            type="submit"
            disabled={decisions.size !== approvals.length}
            onClick={handleDone}
          >
            Done
          </Button>
        </DialogFooter>
      </DialogContent>
    </Dialog>
  );
}



================================================
FILE: examples/nextjs/src/components/History.tsx
================================================
import type { AgentInputItem } from '@openai/agents';
import { TextMessage } from './messages/TextMessage';
import {
  FunctionCallMessage,
  ProcessedFunctionCallItem,
} from './messages/FunctionCall';
import { useMemo } from 'react';

export type HistoryProps = {
  history: AgentInputItem[];
};

export type ProcessedMessageItem = {
  type: 'message';
  role: 'user' | 'assistant';
  content: string;
  id: string;
};

type ProcessedItem = ProcessedMessageItem | ProcessedFunctionCallItem;

function processItems(items: AgentInputItem[]): ProcessedItem[] {
  const processedItems: ProcessedItem[] = [];

  for (const item of items) {
    if (item.type === 'function_call') {
      processedItems.push({
        type: 'function_call',
        name: item.name,
        arguments: item.arguments,
        id: item.id ?? '',
        callId: item.callId ?? '',
        status: 'in_progress',
      });
    }

    if (item.type === 'function_call_result') {
      const index = processedItems.findIndex(
        (i) => i.type === 'function_call' && item.callId === i.callId,
      );

      if (index !== -1 && processedItems[index].type === 'function_call') {
        processedItems[index].output =
          item.output.type === 'text'
            ? item.output.text
            : item.output.type === 'image'
              ? item.output.data
              : '';
        processedItems[index].status = 'completed';
      }
    }

    if (item.type === 'message') {
      processedItems.push({
        type: 'message',
        role: item.role === 'system' ? 'assistant' : item.role,
        content:
          typeof item.content === 'string'
            ? item.content
            : item.content
                .map((content) => {
                  if (
                    content.type === 'input_text' ||
                    content.type === 'output_text'
                  ) {
                    return content.text;
                  }
                  if (content.type === 'audio') {
                    return content.transcript ?? '⚫︎⚫︎⚫︎';
                  }
                  if (content.type === 'refusal') {
                    return content.refusal;
                  }
                  return '';
                })
                .join('\n') || '⚫︎⚫︎⚫︎',
        id: item.id ?? JSON.stringify(item.content),
      });
    }
  }

  return processedItems;
}

export function History({ history }: HistoryProps) {
  const processedItems = useMemo(() => processItems(history), [history]);

  return (
    <div
      className="overflow-y-scroll pl-4 flex-1 rounded-lg bg-white space-y-4"
      id="chatHistory"
    >
      {processedItems.map((item, idx) => {
        if (item.type === 'function_call') {
          return <FunctionCallMessage message={item} key={item.id ?? idx} />;
        }

        if (item.type === 'message') {
          return (
            <TextMessage
              text={item.content}
              isUser={item.role === 'user'}
              key={item.id ?? idx}
            />
          );
        }

        return null;
      })}
    </div>
  );
}



================================================
FILE: examples/nextjs/src/components/icons/ArrowUpIcon.tsx
================================================
import * as React from 'react';

const ArrowUpIcon = (props: React.SVGProps<SVGSVGElement>) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    width={24}
    height={24}
    fill="currentColor"
    viewBox="0 0 24 24"
    {...props}
  >
    <path
      fillRule="evenodd"
      d="M11.293 5.293a1 1 0 0 1 1.414 0l5 5a1 1 0 0 1-1.414 1.414L13 8.414V18a1 1 0 1 1-2 0V8.414l-3.293 3.293a1 1 0 0 1-1.414-1.414l5-5Z"
      clipRule="evenodd"
    />
  </svg>
);

export default ArrowUpIcon;



================================================
FILE: examples/nextjs/src/components/icons/ClockIcon.tsx
================================================
import * as React from 'react';

const ClockIcon = (props: React.SVGProps<SVGSVGElement>) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    width={24}
    height={24}
    fill="currentColor"
    viewBox="0 0 24 24"
    {...props}
  >
    <path
      fillRule="evenodd"
      d="M4 12a8 8 0 1 1 16 0 8 8 0 0 1-16 0Zm8-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2Zm1 5a1 1 0 1 0-2 0v4.586l-2.207 2.207a1 1 0 1 0 1.414 1.414l2.5-2.5A1 1 0 0 0 13 12V7Z"
      clipRule="evenodd"
    />
  </svg>
);

export default ClockIcon;



================================================
FILE: examples/nextjs/src/components/icons/FunctionsIcon.tsx
================================================
import * as React from 'react';

const FunctionsIcon = (props: React.SVGProps<SVGSVGElement>) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    fill="currentColor"
    {...props}
    viewBox="0 0 24 24"
  >
    <path
      fillRule="evenodd"
      clipRule="evenodd"
      d="M7 3a4 4 0 0 0-4 4c0 .277.005.55.01.805l.001.038c.005.271.01.523.009.764-.003.488-.031.88-.108 1.207-.074.314-.186.54-.346.718-.16.177-.418.364-.875.517A.994.994 0 0 0 1 12a.998.998 0 0 0 .692.951c.438.147.69.328.847.503.159.176.273.402.35.717.08.327.114.722.122 1.211.005.297.001.577-.003.88C3.003 16.49 3 16.73 3 17a4 4 0 0 0 4 4 1 1 0 1 0 0-2 2 2 0 0 1-2-2c0-.204.003-.426.006-.653.004-.34.009-.69.004-.997-.009-.541-.046-1.111-.179-1.655-.136-.554-.378-1.104-.809-1.581a3.285 3.285 0 0 0-.1-.107c.044-.045.088-.09.13-.137.436-.485.676-1.04.807-1.6.128-.546.157-1.116.16-1.651a32.24 32.24 0 0 0-.008-.815v-.032C5.004 7.512 5 7.257 5 7a2 2 0 0 1 2-2 1 1 0 0 0 0-2Zm13.06 9c-.04.04-.08.08-.117.123-.44.482-.681 1.036-.811 1.594-.127.545-.154 1.115-.155 1.65 0 .269.005.544.011.812v.007c.006.273.012.542.012.814a2 2 0 0 1-2 2 1 1 0 1 0 0 2 4 4 0 0 0 4-4c0-.296-.006-.584-.012-.854v-.004c-.006-.274-.011-.527-.01-.77 0-.491.027-.88.101-1.2.072-.308.183-.528.341-.702.16-.174.421-.362.889-.519A.994.994 0 0 0 23 12a1 1 0 0 0-.692-.951c-.468-.157-.73-.345-.889-.52-.159-.173-.269-.393-.34-.7-.075-.321-.102-.71-.103-1.201 0-.243.005-.496.01-.77l.001-.004c.006-.27.012-.558.012-.854a4 4 0 0 0-4-4 1 1 0 1 0 0 2 2 2 0 0 1 2 2c0 .272-.006.54-.012.815v.006c-.006.268-.011.543-.01.811 0 .536.027 1.106.154 1.65.13.56.37 1.113.81 1.595.039.042.078.083.118.123Zm-5.084-5.217a1 1 0 0 1-.76 1.193c-.335.075-.534.22-.68.415-.166.218-.304.55-.397 1.042-.035.18-.062.37-.082.567h.443a1 1 0 1 1 0 2h-.507l.003.418c.002.27.004.547.004.832 0 1.466-.261 2.656-.882 3.5-.665.902-1.622 1.25-2.618 1.25a1 1 0 1 1 0-2c.504 0 .797-.152 1.007-.437.254-.344.493-1.029.493-2.313 0-.237-.002-.481-.004-.73l-.004-.52H10.5a1 1 0 1 1 0-2h.55c.027-.327.067-.644.124-.943.125-.653.346-1.318.767-1.873.44-.58 1.053-.985 1.842-1.16a1 1 0 0 1 1.193.759Z"
    />
  </svg>
);

export default FunctionsIcon;



================================================
FILE: examples/nextjs/src/components/messages/FunctionCall.tsx
================================================
import React from 'react';

import ClockIcon from '@/components/icons/ClockIcon';
import FunctionsIcon from '@/components/icons/FunctionsIcon';

export type ProcessedFunctionCallItem = {
  type: 'function_call';
  name: string;
  arguments: string;
  id: string;
  callId: string;
  output?: string;
  status: 'completed' | 'in_progress';
};

type FunctionCallMessageProps = {
  message: ProcessedFunctionCallItem;
};

export function FunctionCallMessage({ message }: FunctionCallMessageProps) {
  let output = message?.output;
  try {
    if (message.output) {
      output = JSON.stringify(JSON.parse(message.output), null, 2);
    }
  } catch {
    output = message.output;
  }
  return (
    <div className="flex flex-col w-[70%] relative mb-[8px]">
      <div>
        <div className="flex flex-col text-sm rounded-[16px]">
          <div className="font-semibold p-3 pl-0 text-gray-700 rounded-b-none flex gap-2">
            <div className="flex gap-2 items-center text-blue-500 ml-[-8px] fill-blue-500">
              <FunctionsIcon width={16} height={16} />
              <div className="text-sm font-medium">
                {message.status === 'completed'
                  ? `Called ${message.name}`
                  : `Calling ${message.name}...`}
              </div>
            </div>
          </div>

          <div className="bg-[#fafafa] rounded-xl py-2 ml-4 mt-2">
            <div className="max-h-96 overflow-y-scroll text-xs border-b mx-6 p-2">
              <pre>
                {JSON.stringify(JSON.parse(message.arguments), null, 2)}
              </pre>
            </div>
            <div className="max-h-80 overflow-y-scroll mx-6 p-2 text-xs">
              {output ? (
                <pre>{output}</pre>
              ) : (
                <div className="text-zinc-500 flex items-center gap-2 py-2">
                  <ClockIcon width={16} height={16} /> Waiting for result...
                </div>
              )}
            </div>
          </div>
        </div>
      </div>
    </div>
  );
}



================================================
FILE: examples/nextjs/src/components/messages/TextMessage.tsx
================================================
import clsx from 'clsx';
import React from 'react';

type TextMessageProps = {
  text: string;
  isUser: boolean;
};

export function TextMessage({ text, isUser }: TextMessageProps) {
  return (
    <div
      className={clsx('flex flex-row gap-2', {
        'justify-end py-2': isUser,
      })}
    >
      <div
        className={clsx('rounded-[16px]', {
          'px-4 py-2 max-w-[90%] ml-4 text-stone--900 bg-[#ededed]': isUser,
          'px-4 py-2 max-w-[90%] mr-4 text-black bg-white': !isUser,
        })}
      >
        {text}
      </div>
    </div>
  );
}



================================================
FILE: examples/nextjs/src/components/ui/Button.tsx
================================================
import { Slot } from '@radix-ui/react-slot';
import { cva, type VariantProps } from 'class-variance-authority';
import * as React from 'react';

import { cn } from '@/components/ui/utils';

const buttonVariants = cva(
  'inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-colors cursor-pointer focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0',
  {
    variants: {
      variant: {
        ghost:
          'text-gray-800 disabled:text-gray-300 hover:bg-gray-100 hover:text-black',
        primary: 'bg-black text-white hover:bg-gray-800 disabled:bg-gray-300',
        secondary:
          'bg-gray-100 text-gray-800 hover:bg-gray-200 disabled:bg-gray-300',
        outline:
          'border border-2 border-gray-100 text-gray-800 hover:bg-gray-100 hover:text-black',
        stop: 'bg-red-500 text-white hover:bg-red-600 disabled:bg-red-300',
      },
      size: {
        default: 'h-9 px-4 py-2',
        sm: 'h-8 rounded-md px-3 text-xs',
        smRounded: 'h-8 rounded-full px-3 text-xs',
        lg: 'h-10 rounded-md px-8',
        icon: 'h-10 w-10 rounded-full [&_svg]:size-6',
        iconSmall: 'h-8 w-8 rounded-full [&_svg]:size-6',
        iconTiny: 'h-6 w-6 rounded-full',
      },
    },
    defaultVariants: {
      variant: 'ghost',
      size: 'default',
    },
  },
);

export interface ButtonProps
  extends React.ButtonHTMLAttributes<HTMLButtonElement>,
    VariantProps<typeof buttonVariants> {
  asChild?: boolean;
}

const Button = React.forwardRef<HTMLButtonElement, ButtonProps>(
  ({ className, variant, size, asChild = false, ...props }, ref) => {
    const Comp = asChild ? Slot : 'button';
    return (
      <Comp
        className={cn(buttonVariants({ variant, size, className }))}
        ref={ref}
        {...props}
      />
    );
  },
);
Button.displayName = 'Button';

export { Button, buttonVariants };



================================================
FILE: examples/nextjs/src/components/ui/dialog.tsx
================================================
'use client';

import * as React from 'react';
import * as DialogPrimitive from '@radix-ui/react-dialog';
import { XIcon } from 'lucide-react';

import { cn } from '@/lib/utils';

function Dialog({
  ...props
}: React.ComponentProps<typeof DialogPrimitive.Root>) {
  return <DialogPrimitive.Root data-slot="dialog" {...props} />;
}

function DialogTrigger({
  ...props
}: React.ComponentProps<typeof DialogPrimitive.Trigger>) {
  return <DialogPrimitive.Trigger data-slot="dialog-trigger" {...props} />;
}

function DialogPortal({
  ...props
}: React.ComponentProps<typeof DialogPrimitive.Portal>) {
  return <DialogPrimitive.Portal data-slot="dialog-portal" {...props} />;
}

function DialogClose({
  ...props
}: React.ComponentProps<typeof DialogPrimitive.Close>) {
  return <DialogPrimitive.Close data-slot="dialog-close" {...props} />;
}

function DialogOverlay({
  className,
  ...props
}: React.ComponentProps<typeof DialogPrimitive.Overlay>) {
  return (
    <DialogPrimitive.Overlay
      data-slot="dialog-overlay"
      className={cn(
        'data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 fixed inset-0 z-50 bg-black/50',
        className,
      )}
      {...props}
    />
  );
}

function DialogContent({
  className,
  children,
  showCloseButton = true,
  ...props
}: React.ComponentProps<typeof DialogPrimitive.Content> & {
  showCloseButton?: boolean;
}) {
  return (
    <DialogPortal data-slot="dialog-portal">
      <DialogOverlay />
      <DialogPrimitive.Content
        data-slot="dialog-content"
        className={cn(
          'bg-background data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 fixed top-[50%] left-[50%] z-50 grid w-full max-w-[calc(100%-2rem)] translate-x-[-50%] translate-y-[-50%] gap-4 rounded-lg border p-6 shadow-lg duration-200 sm:max-w-lg',
          className,
        )}
        {...props}
      >
        {children}
        {showCloseButton && (
          <DialogPrimitive.Close
            data-slot="dialog-close"
            className="ring-offset-background focus:ring-ring data-[state=open]:bg-accent data-[state=open]:text-muted-foreground absolute top-4 right-4 rounded-xs opacity-70 transition-opacity hover:opacity-100 focus:ring-2 focus:ring-offset-2 focus:outline-hidden disabled:pointer-events-none [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4"
          >
            <XIcon />
            <span className="sr-only">Close</span>
          </DialogPrimitive.Close>
        )}
      </DialogPrimitive.Content>
    </DialogPortal>
  );
}

function DialogHeader({ className, ...props }: React.ComponentProps<'div'>) {
  return (
    <div
      data-slot="dialog-header"
      className={cn('flex flex-col gap-2 text-center sm:text-left', className)}
      {...props}
    />
  );
}

function DialogFooter({ className, ...props }: React.ComponentProps<'div'>) {
  return (
    <div
      data-slot="dialog-footer"
      className={cn(
        'flex flex-col-reverse gap-2 sm:flex-row sm:justify-end',
        className,
      )}
      {...props}
    />
  );
}

function DialogTitle({
  className,
  ...props
}: React.ComponentProps<typeof DialogPrimitive.Title>) {
  return (
    <DialogPrimitive.Title
      data-slot="dialog-title"
      className={cn('text-lg leading-none font-semibold', className)}
      {...props}
    />
  );
}

function DialogDescription({
  className,
  ...props
}: React.ComponentProps<typeof DialogPrimitive.Description>) {
  return (
    <DialogPrimitive.Description
      data-slot="dialog-description"
      className={cn('text-muted-foreground text-sm', className)}
      {...props}
    />
  );
}

export {
  Dialog,
  DialogClose,
  DialogContent,
  DialogDescription,
  DialogFooter,
  DialogHeader,
  DialogOverlay,
  DialogPortal,
  DialogTitle,
  DialogTrigger,
};



================================================
FILE: examples/nextjs/src/components/ui/utils.ts
================================================
import { clsx, type ClassValue } from 'clsx';
import { twMerge } from 'tailwind-merge';

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs));
}



================================================
FILE: examples/nextjs/src/lib/utils.ts
================================================
import { clsx, type ClassValue } from 'clsx';
import { twMerge } from 'tailwind-merge';

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs));
}



================================================
FILE: examples/realtime-demo/README.md
================================================
# Realtime Demo

This example is a small [Vite](https://vitejs.dev/) application showcasing the realtime agent API.

1. Install dependencies in the repo root with `pnpm install`.
2. Generate an ephemeral API key:
   ```bash
   pnpm -F realtime-demo generate-token
   ```
   Copy the printed key.
3. Start the dev server:
   ```bash
   pnpm examples:realtime-demo
   ```
4. Open the printed localhost URL and paste the key when prompted.

Use `pnpm -F realtime-demo build` to create a production build.



================================================
FILE: examples/realtime-demo/index.html
================================================
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Realtime Demo</title>
  </head>
  <body class="max-h-screen overflow-hidden h-screen flex justify-center">
    <div class="max-w-6xl w-full p-4 flex flex-col">
      <header class="flex-none flex justify-between items-center pb-4">
        <h1 class="text-2xl font-bold">Realtime Agent Demo</h1>
        <div class="flex gap-2">
          <button
            id="muteButton"
            class="h-9 px-4 py-2 border-2 border-gray-100 text-gray-800 hover:bg-gray-100 hover:text-black inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-colors cursor-pointer focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0"
            style="display: none"
          >
            Mute
          </button>
          <button
            id="connectButton"
            class="h-9 px-4 py-2 bg-black hover:bg-gray-800 text-white rounded-md text-sm font-medium transition-colors cursor-pointer focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50"
          >
            Connect
          </button>
          <button
            id="disconnectButton"
            class="h-9 px-4 py-2 bg-red-500 text-white hover:bg-red-600 disabled:bg-red-300 rounded-md text-sm font-medium transition-colors cursor-pointer focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50"
            style="display: none"
          >
            Disconnect
          </button>
        </div>
      </header>
      <h2 class="font-bold uppercase text-xs text-gray-500 mb-2">
        Raw Event Log
      </h2>
      <div
        class="overflow-scroll flex-1 p-4 border border-gray-300 rounded-lg [&_pre]:bg-gray-100 [&_pre]:p-4 [&_summary]:mb-2 [&>details]:border-b [&>details]:border-gray-200 [&>details]:py-2 text-xs"
        id="eventLog"
      ></div>
    </div>
    <script type="module" src="/src/main.ts"></script>
  </body>
</html>



================================================
FILE: examples/realtime-demo/package.json
================================================
{
  "name": "realtime-demo",
  "private": true,
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build-check": "tsc --noEmit",
    "build": "tsc && vite build",
    "preview": "vite preview",
    "generate-token": "tsx token.ts"
  },
  "devDependencies": {
    "@openai/agents-realtime": "workspace:*",
    "typescript": "~5.8.3",
    "vite": "^6.3.5"
  },
  "dependencies": {
    "@tailwindcss/vite": "^4.1.7",
    "openai": "^4.91.0",
    "tailwindcss": "^4.1.7"
  }
}



================================================
FILE: examples/realtime-demo/token.ts
================================================
import OpenAI from 'openai';

async function generateToken() {
  const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
  });

  const session = await openai.beta.realtime.sessions.create({
    model: 'gpt-4o-realtime-preview',
  });

  console.log(session.client_secret.value);
}

generateToken().catch((err) => {
  console.error('Failed to create ephemeral token', err);
  process.exit(1);
});



================================================
FILE: examples/realtime-demo/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2020",
    "useDefineForClassFields": true,
    "module": "ESNext",
    "lib": ["ES2020", "DOM", "DOM.Iterable"],
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "verbatimModuleSyntax": true,
    "moduleDetection": "force",
    "noEmit": true,

    /* Linting */
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "erasableSyntaxOnly": true,
    "noFallthroughCasesInSwitch": true,
    "noUncheckedSideEffectImports": true
  },
  "include": ["src"]
}



================================================
FILE: examples/realtime-demo/vite-env.d.ts
================================================
/// <reference types="vite/client" />



================================================
FILE: examples/realtime-demo/vite.config.ts
================================================
import { defineConfig } from 'vite';
import tailwindcss from '@tailwindcss/vite';
export default defineConfig({
  plugins: [tailwindcss()],
});



================================================
FILE: examples/realtime-demo/src/main.ts
================================================
// @ts-expect-error Typescript doesn't know about the css module
import './style.css';
import {
  connectButton,
  disconnectButton,
  log,
  muteButton,
  setButtonStates,
} from './utils';

import { z } from 'zod';
import { RealtimeAgent, RealtimeSession, tool } from '@openai/agents-realtime';

const getWeather = tool({
  name: 'getWeather',
  description: 'Get the weather for a given city',
  parameters: z.object({
    city: z.string(),
  }),
  execute: async ({ city }) => {
    return `The weather in ${city} is sunny`;
  },
});

const weatherAgent = new RealtimeAgent({
  name: 'Weather Agent',
  instructions: 'You are a weather expert.',
  handoffDescription: 'You can handoff to the weather agent if you need to.',
  tools: [getWeather],
});

const agent = new RealtimeAgent({
  name: 'Greeter',
  instructions:
    'You are a greeter. Always greet the user with a "top of the morning"',
  handoffs: [weatherAgent],
});

weatherAgent.handoffs.push(agent);

const session = new RealtimeSession(agent);

session.on('transport_event', (event) => {
  // this logs the events coming directly from the Realtime API server
  log(event);
});

connectButton.addEventListener('click', async () => {
  const apiKey = prompt(
    'Enter ephemeral API key. Run `pnpm -F realtime-demo generate-token` to get a token.',
  );
  if (!apiKey) {
    return;
  }
  await session.connect({
    apiKey,
  });
  setButtonStates('unmuted');
});

disconnectButton.addEventListener('click', () => {
  session.close();
  setButtonStates('disconnected');
});

muteButton.addEventListener('click', () => {
  const newMutedState = !session.muted;
  session.mute(newMutedState);
  setButtonStates(newMutedState ? 'muted' : 'unmuted');
});



================================================
FILE: examples/realtime-demo/src/style.css
================================================
@import "tailwindcss";



================================================
FILE: examples/realtime-demo/src/utils.ts
================================================
import type { TransportEvent } from '@openai/agents-realtime';

export function log(event: TransportEvent) {
  const log = document.querySelector<HTMLDivElement>('#eventLog')!;
  const details = document.createElement('details');
  const summary = document.createElement('summary');
  summary.innerText = event.type;
  const pre = document.createElement('pre');
  pre.textContent = JSON.stringify(event, null, 2);
  details.appendChild(summary);
  details.appendChild(pre);
  log.appendChild(details);
}

export const muteButton =
  document.querySelector<HTMLButtonElement>('#muteButton')!;
export const disconnectButton =
  document.querySelector<HTMLButtonElement>('#disconnectButton')!;
export const connectButton =
  document.querySelector<HTMLButtonElement>('#connectButton')!;

type ButtonState = 'muted' | 'unmuted' | 'disconnected';
export function setButtonStates(newState: ButtonState) {
  if (newState === 'muted') {
    disconnectButton.style.display = 'block';
    connectButton.style.display = 'none';
    muteButton.style.display = 'block';
    muteButton.classList.replace('bg-gray-500', 'bg-green-500');
    muteButton.innerText = 'Unmute';
  } else if (newState === 'unmuted') {
    disconnectButton.style.display = 'block';
    connectButton.style.display = 'none';
    muteButton.style.display = 'block';
    muteButton.classList.replace('bg-green-500', 'bg-gray-500');
    muteButton.innerText = 'Mute';
  } else if (newState === 'disconnected') {
    muteButton.style.display = 'none';
    disconnectButton.style.display = 'none';
    connectButton.style.display = 'block';
  }
}



================================================
FILE: examples/realtime-next/README.md
================================================
# Realtime Next.js Demo

This example shows how to combine Next.js with the OpenAI Agents SDK to create a realtime voice agent.

## Run the example

Set the `OPENAI_API_KEY` environment variable and run:

```bash
pnpm examples:realtime-next
```

Open [http://localhost:3000](http://localhost:3000) in your browser and start talking.

## Endpoints

- **`/`** – WebRTC voice demo using the `RealtimeSession` class. Code in `src/app/page.tsx`.
- **`/websocket`** – Same agent over WebSockets. Code in `src/app/websocket/page.tsx`.
- **`/raw-client`** – Low-level WebRTC example using `OpenAIRealtimeWebRTC`. Code in `src/app/raw-client/page.tsx`.



================================================
FILE: examples/realtime-next/next.config.ts
================================================
import type { NextConfig } from "next";

const nextConfig: NextConfig = {
  /* config options here */
};

export default nextConfig;



================================================
FILE: examples/realtime-next/package.json
================================================
{
  "name": "realtime-next",
  "private": true,
  "scripts": {
    "dev": "next dev --turbopack",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "build-check": "tsc --noEmit"
  },
  "dependencies": {
    "@openai/agents": "workspace:*",
    "@radix-ui/react-slot": "^1.2.3",
    "class-variance-authority": "^0.7.1",
    "clsx": "^2.1.1",
    "next": "15.3.3",
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "tailwind-merge": "^3.3.0",
    "wavtools": "^0.1.5",
    "zod": "~3.25.40"
  },
  "devDependencies": {
    "@tailwindcss/postcss": "^4",
    "@types/node": "^20",
    "@types/react": "^19",
    "@types/react-dom": "^19",
    "tailwindcss": "^4",
    "typescript": "^5"
  }
}



================================================
FILE: examples/realtime-next/postcss.config.mjs
================================================
const config = {
  plugins: ["@tailwindcss/postcss"],
};

export default config;



================================================
FILE: examples/realtime-next/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2017",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}



================================================
FILE: examples/realtime-next/vercel.json
================================================
{
  "$schema": "https://openapi.vercel.sh/vercel.json",
  "framework": "nextjs"
}



================================================
FILE: examples/realtime-next/src/app/globals.css
================================================
@import "tailwindcss";

:root {
  --background: #ffffff;
  --foreground: #171717;
}

@theme inline {
  --color-background: var(--background);
  --color-foreground: var(--foreground);
  --font-sans: var(--font-geist-sans);
  --font-mono: var(--font-geist-mono);
}

@media (prefers-color-scheme: dark) {
  :root {
    --background: #0a0a0a;
    --foreground: #ededed;
  }
}

body {
  background: var(--background);
  color: var(--foreground);
  font-family: Arial, Helvetica, sans-serif;
}



================================================
FILE: examples/realtime-next/src/app/layout.tsx
================================================
import type { Metadata } from 'next';
import './globals.css';

export const metadata: Metadata = {
  title: 'Realtime Agent Next.js Demo',
  description: 'A demo of the Realtime Agent framework in Next.js',
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en">
      <body className={`antialiased`}>{children}</body>
    </html>
  );
}



================================================
FILE: examples/realtime-next/src/app/page.tsx
================================================
'use client';

import {
  RealtimeAgent,
  RealtimeSession,
  tool,
  TransportEvent,
  RealtimeOutputGuardrail,
  OutputGuardrailTripwireTriggered,
  RealtimeItem,
  RealtimeContextData,
} from '@openai/agents/realtime';
import { useEffect, useRef, useState } from 'react';
import { z } from 'zod';
import { handleRefundRequest } from './server/backendAgent';
import { getToken } from './server/token';
import { App } from '@/components/App';

const params = z.object({
  request: z.string(),
});
const refundBackchannel = tool<typeof params, RealtimeContextData>({
  name: 'Refund Expert',
  description: 'Evaluate a refund',
  parameters: params,
  execute: async ({ request }, details) => {
    const history: RealtimeItem[] = details?.context?.history ?? [];
    return handleRefundRequest(request, history);
  },
});

const weatherTool = tool({
  name: 'weather',
  description: 'Get the weather in a given location',
  parameters: z.object({
    location: z.string(),
  }),
  execute: async ({ location }) => {
    return `The weather in ${location} is sunny.`;
  },
});

// To invoke this tool, you can ask a question like "What is the special number?"
const secretTool = tool({
  name: 'secret',
  description: 'A secret tool to tell the special number',
  parameters: z.object({
    question: z
      .string()
      .describe(
        'The question to ask the secret tool; mainly about the special number.',
      ),
  }),
  execute: async ({ question }) => {
    return `The answer to ${question} is 42.`;
  },
  // RealtimeAgent handles this approval process within tool_approval_requested events
  needsApproval: true,
});

const weatherExpert = new RealtimeAgent({
  name: 'Weather Expert',
  instructions:
    'You are a weather expert. You are able to answer questions about the weather.',
  tools: [weatherTool],
});

const agent = new RealtimeAgent({
  name: 'Greeter',
  instructions:
    'You are a greeter. Always greet the user with a "top of the morning" at the start of the conversation. When you use a tool always first say what you are about to do.',
  tools: [refundBackchannel, secretTool],
  handoffs: [weatherExpert],
});

const guardrails: RealtimeOutputGuardrail[] = [
  {
    name: 'No mention of Dom',
    execute: async ({ agentOutput }) => {
      const domInOutput = agentOutput.includes('Dom');
      return {
        tripwireTriggered: domInOutput,
        outputInfo: {
          domInOutput,
        },
      };
    },
  },
];

export default function Home() {
  const session = useRef<RealtimeSession<any> | null>(null);
  const [isConnected, setIsConnected] = useState(false);
  const [isMuted, setIsMuted] = useState(false);
  const [outputGuardrailResult, setOutputGuardrailResult] =
    useState<OutputGuardrailTripwireTriggered<any> | null>(null);

  const [events, setEvents] = useState<TransportEvent[]>([]);
  const [history, setHistory] = useState<RealtimeItem[]>([]);

  useEffect(() => {
    session.current = new RealtimeSession(agent, {
      outputGuardrails: guardrails,
      outputGuardrailSettings: {
        debounceTextLength: 200,
      },
    });
    session.current.on('transport_event', (event) => {
      setEvents((events) => [...events, event]);
    });
    session.current.on(
      'guardrail_tripped',
      (_context, _agent, guardrailError) => {
        setOutputGuardrailResult(guardrailError);
      },
    );
    session.current.on('history_updated', (history) => {
      setHistory(history);
    });
    session.current.on(
      'tool_approval_requested',
      (_context, _agent, approvalRequest) => {
        // You'll be prompted when making the tool call that requires approval in web browser.
        const approved = confirm(
          `Approve tool call to ${approvalRequest.tool.name} with parameters:\n ${JSON.stringify(approvalRequest.tool.parameters, null, 2)}?`,
        );
        if (approved) {
          session.current?.approve(approvalRequest.approvalItem);
        } else {
          session.current?.reject(approvalRequest.approvalItem);
        }
      },
    );
  }, []);

  async function connect() {
    if (isConnected) {
      await session.current?.close();
      setIsConnected(false);
    } else {
      const token = await getToken();
      try {
        await session.current?.connect({
          apiKey: token,
        });
        setIsConnected(true);
      } catch (error) {
        console.error('Error connecting to session', error);
      }
    }
  }

  async function toggleMute() {
    if (isMuted) {
      await session.current?.mute(false);
      setIsMuted(false);
    } else {
      await session.current?.mute(true);
      setIsMuted(true);
    }
  }

  return (
    <App
      isConnected={isConnected}
      isMuted={isMuted}
      toggleMute={toggleMute}
      connect={connect}
      history={history}
      outputGuardrailResult={outputGuardrailResult}
      events={events}
    />
  );
}



================================================
FILE: examples/realtime-next/src/app/raw-client/page.tsx
================================================
'use client';

import { TransportEvent, OpenAIRealtimeWebRTC } from '@openai/agents/realtime';
import { useEffect, useRef, useState } from 'react';
import { getToken } from '../server/token';
import { App } from '@/components/App';

export default function Home() {
  const connection = useRef<OpenAIRealtimeWebRTC | null>(null);
  const [isConnected, setIsConnected] = useState(false);
  const [isMuted, setIsMuted] = useState(false);

  const [events, setEvents] = useState<TransportEvent[]>([]);

  useEffect(() => {
    connection.current = new OpenAIRealtimeWebRTC({
      useInsecureApiKey: true,
    });
    connection.current.on('*', (event) => {
      setEvents((events) => [...events, event]);
    });
  }, []);

  async function connect() {
    if (isConnected) {
      await connection.current?.close();
      setIsConnected(false);
    } else {
      const token = await getToken();
      await connection.current?.connect({
        apiKey: token,
        model: 'gpt-4o-mini-realtime-preview',
        initialSessionConfig: {
          instructions: 'Speak like a pirate',
          voice: 'ash',
          modalities: ['text', 'audio'],
          inputAudioFormat: 'pcm16',
          outputAudioFormat: 'pcm16',
        },
      });
      setIsConnected(true);
    }
  }

  async function toggleMute() {
    if (isMuted) {
      await connection.current?.mute(false);
      setIsMuted(false);
    } else {
      await connection.current?.mute(true);
      setIsMuted(true);
    }
  }

  return (
    <App
      title="Demo Direct WebRTC Client"
      isConnected={isConnected}
      isMuted={isMuted}
      toggleMute={toggleMute}
      connect={connect}
      events={events}
    />
  );
}



================================================
FILE: examples/realtime-next/src/app/server/backendAgent.tsx
================================================
'use server';

import { Agent, Runner, user } from '@openai/agents';
import { type RealtimeItem } from '@openai/agents/realtime';
import { z } from 'zod';

const backendAgent = new Agent({
  name: 'Refund Agent',
  instructions:
    'You are a specialist on handling refund requests and detect fraud. You are given a request and you need to determine if the request is valid and if it is, you need to handle it.',
  model: 'o4-mini',
  outputType: z.object({
    refundApproved: z.boolean(),
    refundReason: z.string(),
    fraud: z.boolean(),
  }),
});

const runner = new Runner();

export async function handleRefundRequest(
  request: string,
  history: RealtimeItem[] = [],
) {
  const input = [
    user(
      `
Request: ${request}

## Past Conversation History
${JSON.stringify(history, null, 2)}
      `.trim(),
    ),
  ];
  const result = await runner.run(backendAgent, input);
  console.log(result.output);
  return JSON.stringify(result.finalOutput);
}



================================================
FILE: examples/realtime-next/src/app/server/token.tsx
================================================
'use server';

import OpenAI from 'openai';

export async function getToken() {
  const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
  });

  const session = await openai.beta.realtime.sessions.create({
    model: 'gpt-4o-realtime-preview',
    // tracing: {
    //   workflow_name: 'Realtime Next Demo',
    // },
  });

  return session.client_secret.value;
}



================================================
FILE: examples/realtime-next/src/app/websocket/page.tsx
================================================
'use client';

import {
  RealtimeAgent,
  RealtimeSession,
  tool,
  TransportEvent,
  RealtimeItem,
  OutputGuardrailTripwireTriggered,
  RealtimeOutputGuardrail,
} from '@openai/agents/realtime';
import { useEffect, useRef, useState } from 'react';
import { z } from 'zod';
import { WavRecorder, WavStreamPlayer } from 'wavtools';
import { handleRefundRequest } from '../server/backendAgent';
import { getToken } from '../server/token';
import { App } from '@/components/App';

const refundBackchannel = tool({
  name: 'refundBackchannel',
  description: 'Evaluate a refund',
  parameters: z.object({
    request: z.string(),
  }),
  execute: async ({ request }) => {
    return handleRefundRequest(request);
  },
});

const guardrails: RealtimeOutputGuardrail[] = [
  {
    name: 'No mention of Dom',
    execute: async ({ agentOutput }) => {
      const domInOutput = agentOutput.includes('Dom');
      return {
        tripwireTriggered: domInOutput,
        outputInfo: {
          domInOutput,
        },
      };
    },
  },
];

const agent = new RealtimeAgent({
  name: 'Greeter',
  instructions:
    'You are a greeter. Always greet the user with a "top of the morning". When you use a tool always first say what you are about to do.',
  tools: [refundBackchannel],
});

export default function Home() {
  const session = useRef<RealtimeSession | null>(null);
  const player = useRef<WavStreamPlayer | null>(null);
  const recorder = useRef<WavRecorder | null>(null);

  const [isConnected, setIsConnected] = useState(false);
  const [isMuted, setIsMuted] = useState(false);
  const [outputGuardrailResult, setOutputGuardrailResult] =
    useState<OutputGuardrailTripwireTriggered<any> | null>(null);
  const [events, setEvents] = useState<TransportEvent[]>([]);
  const [history, setHistory] = useState<RealtimeItem[]>([]);

  useEffect(() => {
    session.current = new RealtimeSession(agent, {
      transport: 'websocket',
      outputGuardrails: guardrails,
    });
    recorder.current = new WavRecorder({ sampleRate: 24000 });
    player.current = new WavStreamPlayer({ sampleRate: 24000 });

    session.current.on('audio', (event) => {
      player.current?.add16BitPCM(event.data, event.responseId);
    });

    session.current.on('transport_event', (event) => {
      setEvents((events) => [...events, event]);
    });

    session.current.on('audio_interrupted', () => {
      // We only need to interrupt the player if we are already playing
      // everything else is handled by the session
      player.current?.interrupt();
    });

    session.current.on('history_updated', (history) => {
      setHistory(history);
    });

    session.current.on(
      'guardrail_tripped',
      (_context, _agent, guardrailError) => {
        setOutputGuardrailResult(guardrailError);
      },
    );
  }, []);

  async function record() {
    await recorder.current?.record(async (data) => {
      await session.current?.sendAudio(data.mono as unknown as ArrayBuffer);
    });
  }

  async function connect() {
    if (isConnected) {
      await session.current?.close();
      await player.current?.interrupt();
      await recorder.current?.end();
      setIsConnected(false);
    } else {
      await player.current?.connect();
      const token = await getToken();
      await session.current?.connect({
        apiKey: token,
      });
      await recorder.current?.begin();
      await record();
      setIsConnected(true);
    }
  }

  async function toggleMute() {
    if (isMuted) {
      await record();
      setIsMuted(false);
    } else {
      await recorder.current?.pause();
      setIsMuted(true);
    }
  }

  return (
    <App
      title="Realtime Demo via WebSocket"
      isConnected={isConnected}
      isMuted={isMuted}
      toggleMute={toggleMute}
      connect={connect}
      history={history}
      outputGuardrailResult={outputGuardrailResult}
      events={events}
    />
  );
}



================================================
FILE: examples/realtime-next/src/components/App.tsx
================================================
import {
  RealtimeItem,
  OutputGuardrailTripwireTriggered,
  TransportEvent,
} from '@openai/agents/realtime';
import { History } from '@/components/History';
import { Button } from '@/components/ui/Button';

export type AppProps = {
  title?: string;
  isConnected: boolean;
  isMuted: boolean;
  toggleMute: () => void;
  connect: () => void;
  history?: RealtimeItem[];
  outputGuardrailResult?: OutputGuardrailTripwireTriggered<any> | null;
  events: TransportEvent[];
};

export function App({
  title = 'Realtime Agent Demo',
  isConnected,
  isMuted,
  toggleMute,
  connect,
  history,
  outputGuardrailResult,
  events,
}: AppProps) {
  return (
    <div className="flex justify-center">
      <div className="p-4 md:max-h-screen overflow-hidden h-screen flex flex-col max-w-6xl w-full">
        <header className="flex-none flex justify-between items-center pb-4 w-full max-w-6xl">
          <h1 className="text-2xl font-bold">{title}</h1>
          <div className="flex gap-2">
            {isConnected && (
              <Button
                onClick={toggleMute}
                variant={isMuted ? 'primary' : 'outline'}
              >
                {isMuted ? 'Unmute' : 'Mute'}
              </Button>
            )}
            <Button
              onClick={connect}
              variant={isConnected ? 'stop' : 'primary'}
            >
              {isConnected ? 'Disconnect' : 'Connect'}
            </Button>
          </div>
        </header>
        <div className="flex gap-10 flex-col md:flex-row h-full max-h-full overflow-y-hidden">
          <div className="flex-2/3 flex-grow overflow-y-scroll pb-24">
            {history ? (
              <History history={history} />
            ) : (
              <div className="h-full flex items-center justify-center text-center text-gray-500">
                No history available
              </div>
            )}
          </div>
          <div className="flex-1/3 flex flex-col flex-grow gap-4">
            {outputGuardrailResult && (
              <div className="flex-0 w-full p-2 border border-blue-300 rounded-md bg-blue-50 text-blue-900 text-xs self-end shadow-sm">
                <span className="font-semibold">Guardrail:</span>{' '}
                {outputGuardrailResult?.message ||
                  JSON.stringify(outputGuardrailResult)}
              </div>
            )}
            <div
              className="overflow-scroll w-96 max-h-64 md:h-full md:max-h-none flex-1 p-4 border border-gray-300 rounded-lg [&_pre]:bg-gray-100 [&_pre]:p-4 [&_summary]:mb-2 [&>details]:border-b [&>details]:border-gray-200 [&>details]:py-2 text-xs"
              id="eventLog"
            >
              {events.map((event, index) => (
                <details key={index}>
                  <summary>{event.type}</summary>
                  <pre>{JSON.stringify(event, null, 2)}</pre>
                </details>
              ))}
            </div>
          </div>
        </div>
      </div>
    </div>
  );
}



================================================
FILE: examples/realtime-next/src/components/History.tsx
================================================
import { RealtimeItem } from '@openai/agents/realtime';
import { TextMessage } from './messages/TextMessage';
import { FunctionCallMessage } from './messages/FunctionCall';

export type HistoryProps = {
  history: RealtimeItem[];
};

export function History({ history }: HistoryProps) {
  return (
    <div
      className="overflow-y-scroll pl-4 flex-1 rounded-lg bg-white space-y-4 max-w-2xl"
      id="chatHistory"
    >
      {history.map((item) => {
        if (item.type === 'function_call') {
          return <FunctionCallMessage message={item} key={item.itemId} />;
        }

        if (item.type === 'message') {
          return (
            <TextMessage
              text={
                item.content.length > 0
                  ? item.content
                      .map((content) => {
                        if (
                          content.type === 'text' ||
                          content.type === 'input_text'
                        ) {
                          return content.text;
                        }
                        if (
                          content.type === 'input_audio' ||
                          content.type === 'audio'
                        ) {
                          return content.transcript ?? '⚫︎⚫︎⚫︎';
                        }
                        return '';
                      })
                      .join('\n')
                  : '⚫︎⚫︎⚫︎'
              }
              isUser={item.role === 'user'}
              key={item.itemId}
            />
          );
        }

        return null;
      })}
    </div>
  );
}



================================================
FILE: examples/realtime-next/src/components/icons/ClockIcon.tsx
================================================
import * as React from 'react';

const ClockIcon = (props: React.SVGProps<SVGSVGElement>) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    width={24}
    height={24}
    fill="currentColor"
    viewBox="0 0 24 24"
    {...props}
  >
    <path
      fillRule="evenodd"
      d="M4 12a8 8 0 1 1 16 0 8 8 0 0 1-16 0Zm8-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2Zm1 5a1 1 0 1 0-2 0v4.586l-2.207 2.207a1 1 0 1 0 1.414 1.414l2.5-2.5A1 1 0 0 0 13 12V7Z"
      clipRule="evenodd"
    />
  </svg>
);

export default ClockIcon;



================================================
FILE: examples/realtime-next/src/components/icons/FunctionsIcon.tsx
================================================
import * as React from 'react';

const FunctionsIcon = (props: React.SVGProps<SVGSVGElement>) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    fill="currentColor"
    {...props}
    viewBox="0 0 24 24"
  >
    <path
      fillRule="evenodd"
      clipRule="evenodd"
      d="M7 3a4 4 0 0 0-4 4c0 .277.005.55.01.805l.001.038c.005.271.01.523.009.764-.003.488-.031.88-.108 1.207-.074.314-.186.54-.346.718-.16.177-.418.364-.875.517A.994.994 0 0 0 1 12a.998.998 0 0 0 .692.951c.438.147.69.328.847.503.159.176.273.402.35.717.08.327.114.722.122 1.211.005.297.001.577-.003.88C3.003 16.49 3 16.73 3 17a4 4 0 0 0 4 4 1 1 0 1 0 0-2 2 2 0 0 1-2-2c0-.204.003-.426.006-.653.004-.34.009-.69.004-.997-.009-.541-.046-1.111-.179-1.655-.136-.554-.378-1.104-.809-1.581a3.285 3.285 0 0 0-.1-.107c.044-.045.088-.09.13-.137.436-.485.676-1.04.807-1.6.128-.546.157-1.116.16-1.651a32.24 32.24 0 0 0-.008-.815v-.032C5.004 7.512 5 7.257 5 7a2 2 0 0 1 2-2 1 1 0 0 0 0-2Zm13.06 9c-.04.04-.08.08-.117.123-.44.482-.681 1.036-.811 1.594-.127.545-.154 1.115-.155 1.65 0 .269.005.544.011.812v.007c.006.273.012.542.012.814a2 2 0 0 1-2 2 1 1 0 1 0 0 2 4 4 0 0 0 4-4c0-.296-.006-.584-.012-.854v-.004c-.006-.274-.011-.527-.01-.77 0-.491.027-.88.101-1.2.072-.308.183-.528.341-.702.16-.174.421-.362.889-.519A.994.994 0 0 0 23 12a1 1 0 0 0-.692-.951c-.468-.157-.73-.345-.889-.52-.159-.173-.269-.393-.34-.7-.075-.321-.102-.71-.103-1.201 0-.243.005-.496.01-.77l.001-.004c.006-.27.012-.558.012-.854a4 4 0 0 0-4-4 1 1 0 1 0 0 2 2 2 0 0 1 2 2c0 .272-.006.54-.012.815v.006c-.006.268-.011.543-.01.811 0 .536.027 1.106.154 1.65.13.56.37 1.113.81 1.595.039.042.078.083.118.123Zm-5.084-5.217a1 1 0 0 1-.76 1.193c-.335.075-.534.22-.68.415-.166.218-.304.55-.397 1.042-.035.18-.062.37-.082.567h.443a1 1 0 1 1 0 2h-.507l.003.418c.002.27.004.547.004.832 0 1.466-.261 2.656-.882 3.5-.665.902-1.622 1.25-2.618 1.25a1 1 0 1 1 0-2c.504 0 .797-.152 1.007-.437.254-.344.493-1.029.493-2.313 0-.237-.002-.481-.004-.73l-.004-.52H10.5a1 1 0 1 1 0-2h.55c.027-.327.067-.644.124-.943.125-.653.346-1.318.767-1.873.44-.58 1.053-.985 1.842-1.16a1 1 0 0 1 1.193.759Z"
    />
  </svg>
);

export default FunctionsIcon;



================================================
FILE: examples/realtime-next/src/components/messages/FunctionCall.tsx
================================================
import React from 'react';

import ClockIcon from '@/components/icons/ClockIcon';
import { RealtimeToolCallItem } from '@openai/agents/realtime';
import FunctionsIcon from '@/components/icons/FunctionsIcon';

type FunctionCallMessageProps = {
  message: RealtimeToolCallItem;
};

export function FunctionCallMessage({ message }: FunctionCallMessageProps) {
  let output = message?.output;
  try {
    if (message.output) {
      output = JSON.stringify(JSON.parse(message.output), null, 2);
    }
  } catch {
    output = message.output;
  }
  return (
    <div className="flex flex-col w-[70%] relative mb-[8px]">
      <div>
        <div className="flex flex-col text-sm rounded-[16px]">
          <div className="font-semibold p-3 pl-0 text-gray-700 rounded-b-none flex gap-2">
            <div className="flex gap-2 items-center text-blue-500 ml-[-8px] fill-blue-500">
              <FunctionsIcon width={16} height={16} />
              <div className="text-sm font-medium">
                {message.status === 'completed'
                  ? `Called ${message.name}`
                  : `Calling ${message.name}...`}
              </div>
            </div>
          </div>

          <div className="bg-[#fafafa] rounded-xl py-2 ml-4 mt-2">
            <div className="max-h-96 overflow-y-scroll text-xs border-b mx-6 p-2">
              <pre>
                {JSON.stringify(JSON.parse(message.arguments), null, 2)}
              </pre>
            </div>
            <div className="max-h-80 overflow-y-scroll mx-6 p-2 text-xs">
              {output ? (
                <pre>{output}</pre>
              ) : (
                <div className="text-zinc-500 flex items-center gap-2 py-2">
                  <ClockIcon width={16} height={16} /> Waiting for result...
                </div>
              )}
            </div>
          </div>
        </div>
      </div>
    </div>
  );
}



================================================
FILE: examples/realtime-next/src/components/messages/TextMessage.tsx
================================================
import clsx from 'clsx';
import React from 'react';

type CustomLinkProps = {
  href?: string;
  children?: React.ReactNode;
};

const CustomLink = ({ href, children, ...props }: CustomLinkProps) => (
  <a
    href={href}
    {...props}
    className="bg-gray-200 rounded-full py-1 px-2 text-sm font-medium hover:text-white hover:bg-black"
  >
    {children}
  </a>
);

type TextMessageProps = {
  text: string;
  isUser: boolean;
};

export function TextMessage({ text, isUser }: TextMessageProps) {
  return (
    <div
      className={clsx('flex flex-row gap-2', {
        'justify-end py-2': isUser,
      })}
    >
      <div
        className={clsx('rounded-[16px]', {
          'px-4 py-2 max-w-[90%] ml-4 text-stone--900 bg-[#ededed]': isUser,
          'px-4 py-2 max-w-[90%] mr-4 text-black bg-white': !isUser,
        })}
      >
        {text}
      </div>
    </div>
  );
}



================================================
FILE: examples/realtime-next/src/components/ui/Button.tsx
================================================
import { Slot } from "@radix-ui/react-slot";
import { cva, type VariantProps } from "class-variance-authority";
import * as React from "react";

import { cn } from "@/components/ui/utils";

const buttonVariants = cva(
  "inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-colors cursor-pointer focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0",
  {
    variants: {
      variant: {
        ghost:
          "text-gray-800 disabled:text-gray-300 hover:bg-gray-100 hover:text-black",
        primary: "bg-black text-white hover:bg-gray-800 disabled:bg-gray-300",
        outline:
          "border border-2 border-gray-100 text-gray-800 hover:bg-gray-100 hover:text-black",
        stop: "bg-red-500 text-white hover:bg-red-600 disabled:bg-red-300",
      },
      size: {
        default: "h-9 px-4 py-2",
        sm: "h-8 rounded-md px-3 text-xs",
        lg: "h-10 rounded-md px-8",
        icon: "h-10 w-10 rounded-full [&_svg]:size-6",
        iconSmall: "h-8 w-8 rounded-full [&_svg]:size-6",
        iconTiny: "h-6 w-6 rounded-full",
      },
    },
    defaultVariants: {
      variant: "ghost",
      size: "default",
    },
  }
);

export interface ButtonProps
  extends React.ButtonHTMLAttributes<HTMLButtonElement>,
    VariantProps<typeof buttonVariants> {
  asChild?: boolean;
}

const Button = React.forwardRef<HTMLButtonElement, ButtonProps>(
  ({ className, variant, size, asChild = false, ...props }, ref) => {
    const Comp = asChild ? Slot : "button";
    return (
      <Comp
        className={cn(buttonVariants({ variant, size, className }))}
        ref={ref}
        {...props}
      />
    );
  }
);
Button.displayName = "Button";

export { Button, buttonVariants };


================================================
FILE: examples/realtime-next/src/components/ui/utils.ts
================================================
import { clsx, type ClassValue } from 'clsx';
import { twMerge } from 'tailwind-merge';

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs));
}



================================================
FILE: examples/realtime-twilio/README.md
================================================
# Realtime Twilio Integration

This example demonstrates how to connect the OpenAI Realtime API to a phone call using Twilio's Media Streams.
The script in `index.ts` starts a Fastify server that serves TwiML for incoming calls and creates a WebSocket
endpoint for streaming audio. When a call connects, the audio stream is forwarded through a
`TwilioRealtimeTransportLayer` to a `RealtimeSession` so the `RealtimeAgent` can respond in real time.

To try it out you must have a Twilio phone number.
Expose your localhost with a tunneling service such as ngrok and set the phone number's incoming call URL to `https://<your-tunnel-url>/incoming-call`.

Start the server with:

```bash
pnpm -F realtime-twilio start
```




================================================
FILE: examples/realtime-twilio/index.ts
================================================
import Fastify from 'fastify';
import dotenv from 'dotenv';
import fastifyFormBody from '@fastify/formbody';
import fastifyWs from '@fastify/websocket';
import { RealtimeAgent, RealtimeSession } from '@openai/agents/realtime';
import { TwilioRealtimeTransportLayer } from '@openai/agents-extensions';

// Load environment variables from .env file
dotenv.config();

// Retrieve the OpenAI API key from environment variables. You must have OpenAI Realtime API access.
const { OPENAI_API_KEY } = process.env;
if (!OPENAI_API_KEY) {
  console.error('Missing OpenAI API key. Please set it in the .env file.');
  process.exit(1);
}
const PORT = +(process.env.PORT || 5050);

// Initialize Fastify
const fastify = Fastify();
fastify.register(fastifyFormBody);
fastify.register(fastifyWs);

const agent = new RealtimeAgent({
  name: 'Triage Agent',
  instructions:
    'You are a helpful assistant that starts every conversation with a creative greeting.',
});

// Root Route
fastify.get('/', async (request, reply) => {
  reply.send({ message: 'Twilio Media Stream Server is running!' });
});

// Route for Twilio to handle incoming and outgoing calls
// <Say> punctuation to improve text-to-speech translation
fastify.all('/incoming-call', async (request, reply) => {
  const twimlResponse = `
<?xml version="1.0" encoding="UTF-8"?>
<Response>
    <Say>O.K. you can start talking!</Say>
    <Connect>
        <Stream url="wss://${request.headers.host}/media-stream" />
    </Connect>
</Response>`.trim();
  reply.type('text/xml').send(twimlResponse);
});

// WebSocket route for media-stream
fastify.register(async (fastify) => {
  fastify.get('/media-stream', { websocket: true }, async (connection) => {
    const twilioTransportLayer = new TwilioRealtimeTransportLayer({
      twilioWebSocket: connection,
    });

    const session = new RealtimeSession(agent, {
      transport: twilioTransportLayer,
    });

    await session.connect({
      apiKey: OPENAI_API_KEY,
    });
    console.log('Connected to the OpenAI Realtime API');
  });
});

fastify.listen({ port: PORT }, (err) => {
  if (err) {
    console.error(err);
    process.exit(1);
  }
  console.log(`Server is listening on port ${PORT}`);
});

process.on('SIGINT', () => {
  fastify.close();
  process.exit(0);
});



================================================
FILE: examples/realtime-twilio/package.json
================================================
{
  "private": true,
  "name": "realtime-twilio",
  "dependencies": {
    "@fastify/formbody": "^8.0.2",
    "@fastify/websocket": "^11.1.0",
    "@openai/agents": "workspace:*",
    "@openai/agents-extensions": "workspace:*",
    "dotenv": "^16.5.0",
    "fastify": "^5.3.3",
    "ws": "^8.18.1",
    "zod": "~3.25.40"
  },
  "scripts": {
    "build-check": "tsc --noEmit",
    "start": "tsx index.ts"
  }
}



================================================
FILE: examples/realtime-twilio/tsconfig.json
================================================
{
  "extends": "../../tsconfig.examples.json"
}



================================================
FILE: examples/research-bot/README.md
================================================
# Research Bot

This example shows how to orchestrate several agents to produce a detailed research report.

## Files

- **main.ts** – CLI entrypoint that asks for a query and runs the workflow using `ResearchManager`.
- **manager.ts** – Coordinates the planning, web searching and report writing stages.
- **agents.ts** – Contains the agents: a planner that suggests search terms, a search agent that summarizes results and a writer that generates the final report.

## Usage

From the repository root run:

```bash
pnpm examples:research-bot
```



================================================
FILE: examples/research-bot/agents.ts
================================================
import { Agent, webSearchTool } from '@openai/agents';
import { z } from 'zod';

// ---- Planner Agent ----

const plannerPrompt = `You are a helpful research assistant.
Given a query, come up with a set of web searches to perform to best answer the query.
Output between 5 and 20 terms to query for.`;

export const webSearchItem = z.object({
  reason: z
    .string()
    .describe('Your reasoning for why this search is important to the query.'),
  query: z.string().describe('The search term to use for the web search.'),
});

export type WebSearchItem = z.infer<typeof webSearchItem>;

export const webSearchPlan = z.object({
  searches: z
    .array(webSearchItem)
    .describe('A list of web searches to perform to best answer the query.'),
});

export type WebSearchPlan = z.infer<typeof webSearchPlan>;

export const plannerAgent = new Agent({
  name: 'PlannerAgent',
  instructions: plannerPrompt,
  model: 'gpt-4o',
  outputType: webSearchPlan,
});

// ---- Search Agent ----

const searchAgentInstructions = `You are a research assistant.
Given a search term, you search the web for that term and produce a concise summary of the results.
The summary must be 2-3 paragraphs and less than 300 words. Capture the main points.
Write succinctly, no need to have complete sentences or good grammar.
This will be consumed by someone synthesizing a report, so its vital you capture the essence and ignore any fluff.
Do not include any additional commentary other than the summary itself.`;

export const searchAgent = new Agent({
  name: 'Search agent',
  instructions: searchAgentInstructions,
  tools: [webSearchTool()],
  modelSettings: { toolChoice: 'required' },
});

// ---- Writer Agent ----
const writerPrompt = `You are a senior researcher tasked with writing a cohesive report for a research query.
You will be provided with the original query, and some initial research done by a research assistant.
You should first come up with an outline for the report that describes the structure and flow of the report.
Then, generate the report and return that as your final output.
The final output should be in markdown format, and it should be lengthy and detailed. Aim for 5-10 pages of content, at least 1000 words.`;

export const reportData = z.object({
  shortSummary: z
    .string()
    .describe('A short 2-3 sentence summary of the findings.'),
  markdownReport: z.string().describe('The final report'),
  followUpQuestions: z
    .array(z.string())
    .describe('Suggested topics to research further'),
});

export type ReportData = z.infer<typeof reportData>;

export const writerAgent = new Agent({
  name: 'WriterAgent',
  instructions: writerPrompt,
  model: 'o3-mini',
  outputType: reportData,
});



================================================
FILE: examples/research-bot/main.ts
================================================
import { ResearchManager } from './manager';

async function main() {
  const readline = await import('node:readline');
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
  });
  rl.question('What would you like to research? ', async (query: string) => {
    rl.close();
    const manager = new ResearchManager();
    await manager.run(query);
  });
}

if (require.main === module) {
  main();
}



================================================
FILE: examples/research-bot/manager.ts
================================================
import { withCustomSpan, withTrace } from '@openai/agents';
import {
  plannerAgent,
  webSearchPlan,
  searchAgent,
  writerAgent,
  reportData,
  WebSearchPlan,
  WebSearchItem,
  ReportData,
} from './agents';
import { Runner } from '@openai/agents';

export class ResearchManager {
  runner: Runner;
  constructor(runner: Runner = new Runner()) {
    this.runner = runner;
  }

  async run(query: string): Promise<void> {
    await withTrace('Research workflow', async (trace) => {
      console.log(
        `[trace_id] View trace: https://platform.openai.com/traces/trace?trace_id=${trace.traceId}`,
      );
      console.log(`[starting] Starting research...`);
      const searchPlan = await this._planSearches(query);
      const searchResults = await this._performSearches(searchPlan);
      const report = await this._writeReport(query, searchResults);

      const finalReport = `Report summary\n\n${report.shortSummary}`;
      console.log(`[final_report] ${finalReport}`);
      console.log('Research complete.');

      console.log('\n\n=====REPORT=====\n\n');
      console.log(`Report: ${report.markdownReport}`);
      console.log('\n\n=====FOLLOW UP QUESTIONS=====\n\n');
      const followUpQuestions = report.followUpQuestions.join('\n');
      console.log(`Follow up questions: ${followUpQuestions}`);
    });
  }

  async _planSearches(query: string) {
    console.log('[planning] Planning searches...');
    const result = await this.runner.run(plannerAgent, `Query: ${query}`);
    const parsed = webSearchPlan.parse(result.finalOutput);
    console.log(`[planning] Will perform ${parsed.searches.length} searches`);
    return parsed;
  }

  async _performSearches(searchPlan: WebSearchPlan): Promise<string[]> {
    return await withCustomSpan(
      async (_span) => {
        console.log('[searching] Searching...');
        let numCompleted = 0;
        const tasks = searchPlan.searches.map((item: WebSearchItem) =>
          this._search(item),
        );
        const results: string[] = [];
        for await (const result of tasks) {
          if (result != null) results.push(result);
          numCompleted++;
          console.log(
            `[searching] Searching... ${numCompleted}/${tasks.length} completed`,
          );
        }
        console.log('[searching] done');
        return results;
      },
      { data: { name: 'Search the web' } },
    );
  }

  async _search(item: WebSearchItem): Promise<string | null> {
    const input = `Search term: ${item.query}\nReason for searching: ${item.reason}`;
    try {
      const result = await this.runner.run(searchAgent, input);
      return String(result.finalOutput);
    } catch {
      return null;
    }
  }

  async _writeReport(
    query: string,
    searchResults: string[],
  ): Promise<ReportData> {
    console.log('[writing] Thinking about report...');
    const input = `Original query: ${query}\nSummarized search results: ${searchResults}`;
    const result = await this.runner.run(writerAgent, input);
    // Simulate streaming updates (could be implemented with events if needed)
    console.log('[writing] done');
    return reportData.parse(result.finalOutput);
  }
}



================================================
FILE: examples/research-bot/package.json
================================================
{
  "private": true,
  "name": "research-bot",
  "dependencies": {
    "@openai/agents": "workspace:*",
    "zod": "~3.25.40"
  },
  "scripts": {
    "build-check": "tsc --noEmit",
    "start": "tsx main.ts"
  }
}



================================================
FILE: examples/research-bot/tsconfig.json
================================================
{
  "extends": "../../tsconfig.examples.json"
}



================================================
FILE: examples/tools/README.md
================================================
# Tool Integrations

These examples demonstrate the hosted tools provided by the Agents SDK.

## Examples

- `computer-use.ts` – Uses the computer tool with Playwright to automate a local browser.

  ```bash
  pnpm examples:tools-computer-use
  ```

- `file-search.ts` – Shows how to run a vector search with `fileSearchTool`.

  ```bash
  pnpm examples:tools-file-search
  ```

- `web-search.ts` – Demonstrates `webSearchTool` for general web queries.

  ```bash
  pnpm examples:tools-web-search
  ```

- `code-interpreter.ts` – Demonstrates `codeInterpreterTool` for code execution.

  ```bash
  pnpm examples:tools-code-interpreter
  ```

- `image-generation.ts` – Demonstrates `imageGenerationTool` for image generation.

  ```bash
  pnpm examples:tools-image-generation
  ```


================================================
FILE: examples/tools/code-interpreter.ts
================================================
import { Agent, run, codeInterpreterTool, withTrace } from '@openai/agents';
import OpenAI from 'openai';

async function main() {
  const agent = new Agent({
    name: 'Agent Math Tutor',
    instructions:
      'You are a personal math tutor. When asked a math question, write and run code to answer the question.',
    tools: [codeInterpreterTool({ container: { type: 'auto' } })],
  });

  await withTrace('Code interpreter example', async () => {
    console.log('Solving math problem...');
    const result = await run(
      agent,
      'I need to solve the equation 3x + 11 = 14. Can you help me?',
      { stream: true },
    );
    for await (const event of result) {
      if (
        event.type === 'raw_model_stream_event' &&
        event.data.type === 'model'
      ) {
        const modelEvent = event.data.event as
          | OpenAI.Responses.ResponseStreamEvent
          | undefined;
        if (
          modelEvent &&
          modelEvent.type === 'response.output_item.done' &&
          modelEvent.item.type === 'code_interpreter_call'
        ) {
          const code = modelEvent.item.code;
          console.log(`Code interpreter code:\n\`\`\`\n${code}\n\`\`\``);
        }
      }
    }
    console.log(`Final output: ${result.finalOutput}`);
  });
}

main().catch(console.error);



================================================
FILE: examples/tools/computer-use.ts
================================================
import { chromium, Browser, Page } from 'playwright';
import { Agent, run, withTrace, Computer, computerTool } from '@openai/agents';

async function main() {
  const computer = await new LocalPlaywrightComputer().init();
  try {
    const agent = new Agent({
      name: 'Browser user',
      model: 'computer-use-preview',
      instructions: 'You are a helpful agent.',
      tools: [computerTool({ computer })],
      modelSettings: { truncation: 'auto' },
    });
    await withTrace('CUA Example', async () => {
      const result = await run(agent, "What's the weather in Tokyo?");
      console.log(`\nFinal response:\n${result.finalOutput}`);
    });
  } finally {
    await computer.dispose();
  }
}

// --- CUA KEY TO PLAYWRIGHT KEY MAP ---

const CUA_KEY_TO_PLAYWRIGHT_KEY: Record<string, string> = {
  '/': 'Divide',
  '\\': 'Backslash',
  alt: 'Alt',
  arrowdown: 'ArrowDown',
  arrowleft: 'ArrowLeft',
  arrowright: 'ArrowRight',
  arrowup: 'ArrowUp',
  backspace: 'Backspace',
  capslock: 'CapsLock',
  cmd: 'Meta',
  ctrl: 'Control',
  delete: 'Delete',
  end: 'End',
  enter: 'Enter',
  esc: 'Escape',
  home: 'Home',
  insert: 'Insert',
  option: 'Alt',
  pagedown: 'PageDown',
  pageup: 'PageUp',
  shift: 'Shift',
  space: ' ',
  super: 'Meta',
  tab: 'Tab',
  win: 'Meta',
};

// --- LocalPlaywrightComputer Implementation ---

class LocalPlaywrightComputer implements Computer {
  private _browser: Browser | null = null;
  private _page: Page | null = null;

  get dimensions(): [number, number] {
    return [1024, 768];
  }

  get environment(): 'browser' {
    return 'browser';
  }

  get browser(): Browser {
    if (!this._browser) throw new Error('Browser not initialized');
    return this._browser;
  }

  get page(): Page {
    if (!this._page) throw new Error('Page not initialized');
    return this._page;
  }

  async _get_browser_and_page(): Promise<[Browser, Page]> {
    const [width, height] = this.dimensions;
    const browser = await chromium.launch({
      headless: false,
      args: [`--window-size=${width},${height}`],
    });
    const page = await browser.newPage();
    await page.setViewportSize({ width, height });
    await page.goto('https://www.bing.com/');
    return [browser, page];
  }

  async init(): Promise<this> {
    [this._browser, this._page] = await this._get_browser_and_page();
    return this;
  }

  async dispose(): Promise<void> {
    console.log('Disposing of browser and page');
    if (this._browser) await this._browser.close();
    this._browser = null;
    this._page = null;
  }

  async screenshot(): Promise<string> {
    console.log('Taking a screenshot');
    try {
      if (!this._page) throw new Error('Page not initialized');
      if (!this._browser) throw new Error('Browser not initialized');
      if (typeof this._page.isClosed === 'function' && this._page.isClosed()) {
        throw new Error('Page is already closed');
      }
      await this._page.waitForLoadState('networkidle');
      const buf = await this._page.screenshot({ fullPage: false });
      return Buffer.from(buf).toString('base64');
    } catch (err) {
      console.error('Screenshot failed:', err);
      throw err;
    }
  }

  async click(
    x: number,
    y: number,
    button: 'left' | 'right' | 'wheel' | 'back' | 'forward' = 'left',
  ): Promise<void> {
    console.log(`Clicking at (${x}, ${y})`);
    // Playwright only supports 'left', 'right', 'middle'; others fallback to 'left'
    let playwrightButton: 'left' | 'right' | 'middle' = 'left';
    if (button === 'right') playwrightButton = 'right';
    await this.page.mouse.click(x, y, { button: playwrightButton });
  }

  async doubleClick(x: number, y: number): Promise<void> {
    console.log('doubleClick');
    await this.page.mouse.dblclick(x, y);
  }

  async scroll(
    x: number,
    y: number,
    scrollX: number,
    scrollY: number,
  ): Promise<void> {
    console.log(`Scrolling to (${x}, ${y}) by (${scrollX}, ${scrollY})`);
    await this.page.mouse.move(x, y);
    await this.page.evaluate(
      ([sx, sy]) => window.scrollBy(sx, sy),
      [scrollX, scrollY],
    );
  }

  async type(text: string): Promise<void> {
    console.log(`Typing: ${text}`);
    await this.page.keyboard.type(text);
  }

  async wait(): Promise<void> {
    console.log('Waiting');
    await new Promise((resolve) => setTimeout(resolve, 1000));
  }

  async move(x: number, y: number): Promise<void> {
    console.log(`Moving to (${x}, ${y})`);
    await this.page.mouse.move(x, y);
  }

  async keypress(keys: string[]): Promise<void> {
    console.log(`Pressing keys: ${keys}`);
    const mappedKeys = keys.map(
      (key) => CUA_KEY_TO_PLAYWRIGHT_KEY[key.toLowerCase()] || key,
    );
    for (const key of mappedKeys) {
      await this.page.keyboard.down(key);
    }
    for (const key of mappedKeys.reverse()) {
      await this.page.keyboard.up(key);
    }
  }

  async drag(path: Array<[number, number]>): Promise<void> {
    console.log(`Dragging path: ${path}`);
    if (!path.length) return;
    await this.page.mouse.move(path[0][0], path[0][1]);
    await this.page.mouse.down();
    for (const [px, py] of path.slice(1)) {
      await this.page.mouse.move(px, py);
    }
    await this.page.mouse.up();
  }
}

main().catch((err) => {
  console.error('Error:', err);
});



================================================
FILE: examples/tools/file-search.ts
================================================
import { Agent, run, fileSearchTool, withTrace } from '@openai/agents';

async function main() {
  const agent = new Agent({
    name: 'File searcher',
    instructions: 'You are a helpful agent.',
    tools: [
      fileSearchTool(['vs_67bf88953f748191be42b462090e53e7'], {
        maxNumResults: 3,
        includeSearchResults: true,
      }),
    ],
  });

  await withTrace('File search example', async () => {
    const result = await run(
      agent,
      'Be concise, and tell me 1 sentence about Arrakis I might not know.',
    );
    console.log(result.finalOutput);
    /*
    Arrakis, the desert planet in Frank Herbert's "Dune," was inspired by the scarcity of water
    as a metaphor for oil and other finite resources.
    */

    console.log(
      '\n' +
        result.newItems.map((out: unknown) => JSON.stringify(out)).join('\n'),
    );
    /*
    {"id":"...", "queries":["Arrakis"], "results":[...]}
    */
  });
}

main().catch(console.error);



================================================
FILE: examples/tools/image-generation.ts
================================================
import { Agent, run, imageGenerationTool, withTrace } from '@openai/agents';
import * as fs from 'node:fs';
import * as os from 'node:os';
import * as path from 'node:path';
import { spawnSync } from 'node:child_process';

function openFile(filePath: string): void {
  if (process.platform === 'darwin') {
    spawnSync('open', [filePath], { stdio: 'inherit' });
  } else if (process.platform === 'win32') {
    spawnSync('cmd', ['/c', 'start', '', filePath], { shell: true });
  } else {
    spawnSync('xdg-open', [filePath], { stdio: 'inherit' });
  }
}

async function main() {
  const agent = new Agent({
    name: 'Image generator',
    instructions: 'You are a helpful agent.',
    tools: [imageGenerationTool({ quality: 'low' })],
  });

  await withTrace('Image generation example', async () => {
    console.log('Generating image, this may take a while...');
    const result = await run(
      agent,
      'Create an image of a frog eating a pizza, comic book style.',
    );
    console.log(result.finalOutput);

    for (const item of result.newItems) {
      if (
        item.type === 'tool_call_item' &&
        item.rawItem.type === 'hosted_tool_call' &&
        item.rawItem.output
      ) {
        const buffer = Buffer.from(item.rawItem.output, 'base64');
        const tmpPath = path.join(os.tmpdir(), `image-${Date.now()}.png`);
        fs.writeFileSync(tmpPath, buffer);
        // console.log(`Image saved to ${tmpPath}`);
        openFile(tmpPath);
      }
    }
    // or using result.output works too
    // for (const response of result.output) {
    //   if (
    //     response.type === 'hosted_tool_call' &&
    //     response.name === 'image_generation_call' &&
    //     response.output
    //   ) {
    //     const buffer = Buffer.from(response.output, 'base64');
    //     const tmpPath = path.join(os.tmpdir(), `image-${Date.now()}.png`);
    //     fs.writeFileSync(tmpPath, buffer);
    //     // console.log(`Image saved to ${tmpPath}`);
    //     openFile(tmpPath);
    //   }
    // }
  });
}

main().catch(console.error);



================================================
FILE: examples/tools/package.json
================================================
{
  "private": true,
  "name": "tools",
  "dependencies": {
    "@openai/agents": "workspace:*",
    "playwright": "^1.52.0",
    "zod": "~3.25.40"
  },
  "scripts": {
    "build-check": "tsc --noEmit",
    "start:computer-use": "tsx computer-use.ts",
    "start:file-search": "tsx file-search.ts",
    "start:web-search": "tsx web-search.ts",
    "start:code-interpreter": "tsx code-interpreter.ts",
    "start:image-generation": "tsx image-generation.ts"
  }
}



================================================
FILE: examples/tools/tsconfig.json
================================================
{
  "extends": "../../tsconfig.examples.json"
}



================================================
FILE: examples/tools/web-search.ts
================================================
import { Agent, run, webSearchTool, withTrace } from '@openai/agents';

async function main() {
  const agent = new Agent({
    name: 'Web searcher',
    instructions: 'You are a helpful agent.',
    tools: [
      webSearchTool({
        userLocation: { type: 'approximate', city: 'New York' },
      }),
    ],
  });

  await withTrace('Web search example', async () => {
    const result = await run(
      agent,
      "search the web for 'local sports news' and give me 1 interesting update in a sentence.",
    );
    console.log(result.finalOutput);
    // The New York Giants are reportedly pursuing quarterback Aaron Rodgers after his ...

    const messages = result.history;
    messages.push({
      role: 'user',
      content: 'search the web for more details of the highlighed player.',
    });

    const result2 = await run(agent, messages);
    console.log();
    console.log(result2.finalOutput);
  });
}

main().catch(console.error);


